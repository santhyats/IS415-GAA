[
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "Myanmar has been going through civil wars and internal conflicts for decades now. These conflicts have mainly been due to ethnic tensions and general unhappiness in the governing party. Conflicts range from battles, riots, violence against civilians, strategic developments and more. In this exercise, I will be analysing the distribution of conflicts in Myanmar.\nTo do this, I will mainly be performing quarterly KDE analysis on 4 main types of conflicts: Battles, Explosions, Violence against Civilians and Strategic Developments through the years of 2021-2024. I will also be performing the second order spatial point pattern process as well as the spatio temporal point process analysis for these segments. Let’s get started.\n\n\nThese are the packages that I will be using in this exercise.\nsf: Used in spatial data wrangling\ntidyverse: Used in data wrangling for non-spatial data\nraster: For reading, writing and manipulating raster data\ntmap: For functions relating to mapping point patterns\nspatstat: Provides functions for spatial point process analysis\nsparr: Provides functions for spatio-temporal point process analysis\n\npacman::p_load(sf, tidyverse, spatstat, sparr, tmap)"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#overview",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#overview",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "Myanmar has been going through civil wars and internal conflicts for decades now. These conflicts have mainly been due to ethnic tensions and general unhappiness in the governing party. Conflicts range from battles, riots, violence against civilians, strategic developments and more. In this exercise, I will be analysing the distribution of conflicts in Myanmar.\nTo do this, I will mainly be performing quarterly KDE analysis on 4 main types of conflicts: Battles, Explosions, Violence against Civilians and Strategic Developments through the years of 2021-2024. I will also be performing the second order spatial point pattern process as well as the spatio temporal point process analysis for these segments. Let’s get started.\n\n\nThese are the packages that I will be using in this exercise.\nsf: Used in spatial data wrangling\ntidyverse: Used in data wrangling for non-spatial data\nraster: For reading, writing and manipulating raster data\ntmap: For functions relating to mapping point patterns\nspatstat: Provides functions for spatial point process analysis\nsparr: Provides functions for spatio-temporal point process analysis\n\npacman::p_load(sf, tidyverse, spatstat, sparr, tmap)"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#data-preparation",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#data-preparation",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.2 Data Preparation",
    "text": "1.2 Data Preparation\nIn this section, I will be retrieving the required data and performing the necessary data wrangling methods in order to transform the data into a form that is best suitable for our analytic needs for this exercise. The datasets used in this exercise are:\n\nMyanmar_All_2021-24.csv: A csv file downloaded from ACLED, which contains all the details of the internal conflicts in Myanmar from 2021-2024. Note that the file name has been renamed for ease of use.\nMBoundary: A shapefile downloaded from Myanmar Information Management Unit, MIMU. This shapefile maps out the boundary of Myanmar. I have also renamed this file for ease of use.\n\n\n1.2.1 Importing the Data\nFirstly, I will be importing the base map of Myanmar in shapefile format using st_read() function of the sf package. I will also transform the crs to that of Myanmar using the st_transform() function.\n\nboundary &lt;- st_read(dsn=\"data/raw\",\n                    layer = \"MBoundary\") %&gt;% \n  st_transform(crs=32646) %&gt;% \n  write_rds(\"data/rds/boundary.rds\")\n\n\nboundary&lt;-read_rds(\"data/rds/boundary.rds\")\n\nWe will make use of st_crs() function to make sure that the Coordinate Reference System has been correctly transformed to that of Myanmar.\n\nst_crs(boundary)\n\nCoordinate Reference System:\n  User input: EPSG:32646 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 46N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 46N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",93,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 90°E and 96°E, northern hemisphere between equator and 84°N, onshore and offshore. Bangladesh. Bhutan. China. Indonesia. Mongolia. Myanmar (Burma). Russian Federation.\"],\n        BBOX[0,90,84,96]],\n    ID[\"EPSG\",32646]]\n\n\nNext, I will also be Importing the regional boundaries of Myanmar and transforming the crs to that of Myanmar’s again.\n\nregions_sf &lt;- st_read(dsn=\"data/raw\",\n                      layer=\"regions\") %&gt;% \n  st_transform(crs = 32646) %&gt;% \n  write_rds(\"data/rds/regions.rds\")\n\n\nregions_sf&lt;-read_rds(\"data/rds/regions.rds\")\n\nLastly, I will be importing and reading the csv file containing the data about the conflicts into a dataframe called all_sf. This is done using the read_csv() function of the readr package. I will once again ensure that the crs of the data is transformed to that of Myanmar’s.\n\nall_sf &lt;- read_csv('data/raw/Myanmar_All_2021-24.csv') %&gt;% \n  st_as_sf(coords = c('longitude', 'latitude'),\n           crs=4326) %&gt;% \n  st_transform(crs=32646) %&gt;% \n   select(1:4, 6,19, 29, 30) \n\nst_crs(all_sf)\n\n\n\n1.2.2 Preparing the Data\nBefore we can start deriving our KDE layers, we will make sure our data is in a suitable form and is processed in a way that we need it in. I will start off by converting the date column in the aspatial data to the date format so that can be handled during computations. This is done through the as.Date() functon. I will also add in new columns called “quarters” and “num_quarters” to keep track of our quarters and its numbers. The numeric quarters column will come in handy when we are computing our Spatio Temporal KDE layers later.\n\nall_sf&lt;- all_sf %&gt;% \n  mutate(event_date = as.Date(event_date, format = \"%d %B %Y\"))\nall_sf$quarters &lt;- paste(quarters(all_sf$event_date), year(all_sf$event_date), sep=\"_\")\nall_sf$num_quarters&lt;-quarter(all_sf$event_date)\nwrite_rds(all_sf,\"data/rds/all.rds\")\n\n\nall_sf&lt;-read_rds(\"data/rds/all.rds\")\n\nBefore we can filter out the data that we need, I will be visualising the data according to the event types to observe for any patterns or similarity. To do this, I will first use tm_shape() and tm_polygons() of the tmap package to plot the base map of Myanmar, indicating all the regions. Next, I will use tm_shape() and tm_dots() together to plot out all the spatial points. Lastly, I will use tm_facets() to separate the plots according to the type of conlfict.\n\ntm_shape(boundary) + tm_polygons() + tm_shape(regions_sf) + tm_polygons() + tm_shape(all_sf) + tm_dots() + tm_facets(by='event_type', free.coords = FALSE, drop.units= TRUE)\n\n\n\n\n\n\n\n\nFrom the patterns observed above, I see that Battles, Strategic Developments, Explosions and Violence against civilians all have similar distribution of conflicts across the space. I also noted that Riots and Protests have very sparsespatial points even over the aggregated 4 year dataset. This indicates the possibility that there will be few to no spatial points available to analyse for certain quarters.\nAs such, I will be focusing my analysis on these four main categories of conflicts: Battles, Strategic Developments, Violence against Civilians and Explosions.\nI will filter out the data according to these event types using the filter() function and save them in separate sf objects.\n\nbattles_sf &lt;- all_sf %&gt;%  filter(event_type == 'Battles') %&gt;% \n  write_rds(\"data/rds/Battles/battles_sf.rds\")\n\nexp_sf &lt;- all_sf %&gt;%  filter(event_type == \"Explosions/Remote violence\") %&gt;% \n  write_rds(\"data/rds/Explosions/exp_sf.rds\")\n\ncivViolence_sf &lt;- all_sf %&gt;%  filter(event_type == \"Violence against civilians\") %&gt;% \n  write_rds(\"data/rds/Violence/civViolence_sf.rds\")\n\nstrat_dev_sf &lt;- all_sf %&gt;%  filter(event_type == 'Strategic developments') %&gt;% \n  write_rds(\"data/rds/Strat_Dev/strat_dev.rds\")\n\nI will also be creating a separate sf containing the only the timeframe and the geometry of the spatial points, to be used in our Spatio Temporal KDE layers later. This is done by using the select() functions to select only the “quarters”, “num_quarters” an d”geometry” columns from the dataframes of the respective conflict types.\n\nquart_geo_bat&lt;- battles_sf %&gt;% \n  select(3,8,10) %&gt;% \n  write_rds(\"data/rds/Battles/quart_geo_bat.rds\")\n\nquart_geo_civ &lt;- civViolence_sf %&gt;% \n  select(3,8,10) %&gt;% \n  write_rds(\"data/rds/Violence/quart_geo_civ.rds\")\n\nquart_geo_exp&lt;- exp_sf %&gt;% \n  select(3,8,10) %&gt;% \n  write_rds(\"data/rds/Explosions/quart_geo_exp.rds\")\n\nquart_geo_strat&lt;- strat_dev_sf %&gt;% \n  select(3,8,10) %&gt;% \n  write_rds(\"data/rds/Strat_Dev/quart_geo_strat.rds\")\n\nFinally, I will further split the conflict type datasets into quarterly periods. For ease of use, I will write these sf objects into rds files and save them in a compiled folder.\n\nBattlesExplosionsViolence against civilliansStrategic Developments\n\n\n\nq1_21_battles_sf &lt;- battles_sf %&gt;% \n  filter(year == '2021' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Battles/2021/q1.rds\")\n\nq2_21_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Battles/2021/q2.rds\")\n\nq3_21_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Battles/2021/q3.rds\")\n\nq4_21_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Battles/2021/q4.rds\")\n\n#2022\n\nq1_22_battles_sf &lt;- battles_sf %&gt;% \n  filter(year == '2022' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Battles/2022/q1.rds\")\n\nq2_22_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Battles/2022/q2.rds\")\n\nq3_22_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Battles/2022/q3.rds\")\n\nq4_22_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Battles/2022/q4.rds\")\n\n#2023\n\nq1_23_battles_sf &lt;- battles_sf %&gt;% \n  filter(year == '2023' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Battles/2023/q1.rds\")\n\nq2_23_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Battles/2023/q2.rds\")\n\nq3_23_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Battles/2023/q3.rds\")\n\nq4_23_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Battles/2023/q4.rds\")\n\n#2024\n\nq1_24_battles_sf &lt;- battles_sf %&gt;% \n  filter(year == '2024' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Battles/2024/q1.rds\")\n\nq2_24_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2024') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Battles/2024/q2.rds\")\n\n\n\n\nq1_21_exp_sf &lt;- exp_sf %&gt;% \n  filter(year == '2021' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Explosions/2021/q1.rds\")\n\nq2_21_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Explosions/2021/q2.rds\")\n\nq3_21_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Explosions/2021/q3.rds\")\n\nq4_21_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Explosions/2021/q4.rds\")\n\n#2022\n\nq1_22_exp_sf &lt;- exp_sf %&gt;% \n  filter(year == '2022' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Explosions/2022/q1.rds\")\n\nq2_22_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Explosions/2022/q2.rds\")\n\nq3_22_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Explosions/2022/q3.rds\")\n\nq4_22_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Explosions/2022/q4.rds\")\n\n#2023\n\nq1_23_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2023' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Explosions/2023/q1.rds\")\n\nq2_23_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Explosions/2023/q2.rds\")\n\nq3_23_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Explosions/2023/q3.rds\")\n\nq4_23_exp_sf &lt;-battles_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Explosions/2023/q4.rds\")\n\n#2024\n\nq1_24_exp_sf &lt;- exp_sf %&gt;% \n  filter(year == '2024' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Explosions/2024/q1.rds\")\n\nq2_24_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2024') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Explosions/2024/q2.rds\")\n\n\n\n\nq1_21_civViolence_sf &lt;- civViolence_sf %&gt;% \n  filter(year == '2021' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Violence/2021/q1.rds\")\n\nq2_21_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Violence/2021/q2.rds\")\n\nq3_21_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Violence/2021/q3.rds\")\n\nq4_21_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Violence/2021/q4.rds\")\n\n#2022\n\nq1_22_civViolence_sf &lt;- civViolence_sf %&gt;% \n  filter(year == '2022' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Violence/2022/q1.rds\")\n\nq2_22_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Violence/2022/q2.rds\")\n\nq3_22_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Violence/2022/q3.rds\")\n\nq4_22_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Violence/2022/q4.rds\")\n\n#2023\n\nq1_23_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2023' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Violence/2023/q1.rds\")\n\nq2_23_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Violence/2023/q2.rds\")\n\nq3_23_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Violence/2023/q3.rds\")\n\nq4_23_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Violence/2023/q4.rds\")\n\n#2024\n\nq1_24_civViolence_sf &lt;- civViolence_sf %&gt;% \n  filter(year == '2024' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Violence/2024/q1.rds\")\n\nq2_24_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2024') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Violence/2024/q2.rds\")\n\n\n\n\nq1_21_strat_dev_sf &lt;- strat_dev_sf %&gt;% \n  filter(year == '2021' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2021/q1.rds\")\n\nq2_21_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2021/q2.rds\")\n\nq3_21_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2021/q3.rds\")\n\nq4_21_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2021/q4.rds\")\n\n#2022\n\nq1_22_strat_dev_sf &lt;- strat_dev_sf %&gt;% \n  filter(year == '2022' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2022/q1.rds\")\n\nq2_22_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2022/q2.rds\")\n\nq3_22_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2022/q3.rds\")\n\nq4_22_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2022/q4.rds\")\n\n#2023\n\nq1_23_strat_dev_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2023' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2023/q1.rds\")\n\nq2_23_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2023/q2.rds\")\n\nq3_23_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2023/q3.rds\")\n\nq4_23_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2023/q4.rds\")\n\n#2024\n\nq1_24_strat_dev_sf &lt;- strat_dev_sf %&gt;% \n  filter(year == '2024' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2024/q1.rds\")\n\nq2_24_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2024') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2024/q2.rds\")\n\n\n\n\n\n\n2.2 Data Wrangling\n\n2.2.1 Converting the sf objects to ppp objects\nTo derive our KDE layers, we would firstly need the sf objects to be converted to ppp objects. This is because the function that we will be using, density() of the spatstat package, only takes in objects in the ppp form. We will do this using the as.ppp() function.\n\nBattlesExplosionsStrategic DevelopmentsViolence Against Civilians\n\n\n\nbattlesQ121_ppp &lt;- as.ppp(st_coordinates(q1_21_battles_sf), st_bbox(q1_21_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ221_ppp &lt;- as.ppp(st_coordinates(q2_21_battles_sf), st_bbox(q2_21_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ321_ppp&lt;- as.ppp(st_coordinates(q3_21_battles_sf), st_bbox(q3_21_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ421_ppp&lt;-as.ppp(st_coordinates(q4_21_battles_sf), st_bbox(q4_21_battles_sf))\n\nWarning: data contain duplicated points\n\n#2022\n\nbattlesQ122_ppp &lt;- as.ppp(st_coordinates(q1_22_battles_sf), st_bbox(q1_22_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ222_ppp &lt;- as.ppp(st_coordinates(q2_22_battles_sf), st_bbox(q2_22_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ322_ppp&lt;- as.ppp(st_coordinates(q3_22_battles_sf), st_bbox(q3_22_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ422_ppp&lt;-as.ppp(st_coordinates(q4_22_battles_sf), st_bbox(q4_22_battles_sf))\n\nWarning: data contain duplicated points\n\n#2023\nbattlesQ123_ppp &lt;- as.ppp(st_coordinates(q1_23_battles_sf), st_bbox(q1_23_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ223_ppp &lt;- as.ppp(st_coordinates(q2_23_battles_sf), st_bbox(q2_23_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ323_ppp&lt;- as.ppp(st_coordinates(q3_23_battles_sf), st_bbox(q3_23_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ423_ppp&lt;-as.ppp(st_coordinates(q4_23_battles_sf), st_bbox(q4_23_battles_sf))\n\nWarning: data contain duplicated points\n\n#2024\nbattlesQ124_ppp &lt;- as.ppp(st_coordinates(q1_24_battles_sf), st_bbox(q1_24_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ224_ppp &lt;- as.ppp(st_coordinates(q2_24_battles_sf), st_bbox(q2_24_battles_sf))\n\nWarning: data contain duplicated points\n\n\n\n\n\nexpQ121_ppp &lt;- as.ppp(st_coordinates(q1_21_exp_sf), st_bbox(q1_21_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ221_ppp &lt;- as.ppp(st_coordinates(q2_21_exp_sf), st_bbox(q2_21_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ321_ppp&lt;- as.ppp(st_coordinates(q3_21_exp_sf), st_bbox(q3_21_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ421_ppp&lt;-as.ppp(st_coordinates(q4_21_exp_sf), st_bbox(q4_21_exp_sf))\n\nWarning: data contain duplicated points\n\n#2022\n\nexpQ122_ppp &lt;- as.ppp(st_coordinates(q1_22_exp_sf), st_bbox(q1_22_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ222_ppp &lt;- as.ppp(st_coordinates(q2_22_exp_sf), st_bbox(q2_22_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ322_ppp&lt;- as.ppp(st_coordinates(q3_22_exp_sf), st_bbox(q3_22_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ422_ppp&lt;-as.ppp(st_coordinates(q4_22_exp_sf), st_bbox(q4_22_exp_sf))\n\nWarning: data contain duplicated points\n\n#2023\nexpQ123_ppp &lt;- as.ppp(st_coordinates(q1_23_exp_sf), st_bbox(q1_23_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ223_ppp &lt;- as.ppp(st_coordinates(q2_23_exp_sf), st_bbox(q2_23_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ323_ppp&lt;- as.ppp(st_coordinates(q3_23_exp_sf), st_bbox(q3_23_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ423_ppp&lt;-as.ppp(st_coordinates(q4_23_exp_sf), st_bbox(q4_23_exp_sf))\n\nWarning: data contain duplicated points\n\n#2024\nexpQ124_ppp &lt;- as.ppp(st_coordinates(q1_24_exp_sf), st_bbox(q1_24_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ224_ppp &lt;- as.ppp(st_coordinates(q2_24_exp_sf), st_bbox(q2_24_exp_sf))\n\nWarning: data contain duplicated points\n\n\n\n\n\nstrat_devQ121_ppp &lt;- as.ppp(st_coordinates(q1_21_strat_dev_sf), st_bbox(q1_21_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ221_ppp &lt;- as.ppp(st_coordinates(q2_21_strat_dev_sf), st_bbox(q2_21_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ321_ppp&lt;- as.ppp(st_coordinates(q3_21_strat_dev_sf), st_bbox(q3_21_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ421_ppp&lt;-as.ppp(st_coordinates(q4_21_strat_dev_sf), st_bbox(q4_21_strat_dev_sf))\n\nWarning: data contain duplicated points\n\n#2022\nstrat_devQ122_ppp &lt;- as.ppp(st_coordinates(q1_22_strat_dev_sf), st_bbox(q1_22_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ222_ppp &lt;- as.ppp(st_coordinates(q2_22_strat_dev_sf), st_bbox(q2_22_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ322_ppp&lt;- as.ppp(st_coordinates(q3_22_strat_dev_sf), st_bbox(q3_22_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ422_ppp&lt;-as.ppp(st_coordinates(q4_22_strat_dev_sf), st_bbox(q4_22_strat_dev_sf))\n\nWarning: data contain duplicated points\n\n#2023\nstrat_devQ123_ppp &lt;- as.ppp(st_coordinates(q1_23_strat_dev_sf), st_bbox(q1_23_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ223_ppp &lt;- as.ppp(st_coordinates(q2_23_strat_dev_sf), st_bbox(q2_23_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ323_ppp&lt;- as.ppp(st_coordinates(q3_23_strat_dev_sf), st_bbox(q3_23_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ423_ppp&lt;-as.ppp(st_coordinates(q4_23_strat_dev_sf), st_bbox(q4_23_strat_dev_sf))\n\nWarning: data contain duplicated points\n\n#2024\nstrat_devQ124_ppp &lt;- as.ppp(st_coordinates(q1_24_strat_dev_sf), st_bbox(q1_24_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ224_ppp &lt;- as.ppp(st_coordinates(q2_24_strat_dev_sf), st_bbox(q2_24_strat_dev_sf))\n\nWarning: data contain duplicated points\n\n\n\n\n\ncivViolenceQ121_ppp &lt;- as.ppp(st_coordinates(q1_21_civViolence_sf), st_bbox(q1_21_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ221_ppp &lt;- as.ppp(st_coordinates(q2_21_civViolence_sf), st_bbox(q2_21_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ321_ppp&lt;- as.ppp(st_coordinates(q3_21_civViolence_sf), st_bbox(q3_21_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ421_ppp&lt;-as.ppp(st_coordinates(q4_21_civViolence_sf), st_bbox(q4_21_civViolence_sf))\n\nWarning: data contain duplicated points\n\n#2022\n\ncivViolenceQ122_ppp &lt;- as.ppp(st_coordinates(q1_22_civViolence_sf), st_bbox(q1_22_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ222_ppp &lt;- as.ppp(st_coordinates(q2_22_civViolence_sf), st_bbox(q2_22_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ322_ppp&lt;- as.ppp(st_coordinates(q3_22_civViolence_sf), st_bbox(q3_22_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ422_ppp&lt;-as.ppp(st_coordinates(q4_22_civViolence_sf), st_bbox(q4_22_civViolence_sf))\n\nWarning: data contain duplicated points\n\n#2023\ncivViolenceQ123_ppp &lt;- as.ppp(st_coordinates(q1_23_civViolence_sf), st_bbox(q1_23_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ223_ppp &lt;- as.ppp(st_coordinates(q2_23_civViolence_sf), st_bbox(q2_23_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ323_ppp&lt;- as.ppp(st_coordinates(q3_23_civViolence_sf), st_bbox(q3_23_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ423_ppp&lt;-as.ppp(st_coordinates(q4_23_civViolence_sf), st_bbox(q4_23_civViolence_sf))\n\nWarning: data contain duplicated points\n\n#2024\ncivViolenceQ124_ppp &lt;- as.ppp(st_coordinates(q1_24_civViolence_sf), st_bbox(q1_24_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ224_ppp &lt;- as.ppp(st_coordinates(q2_24_civViolence_sf), st_bbox(q2_24_civViolence_sf))\n\nWarning: data contain duplicated points\n\n\n\n\n\n\n\n\n2.2.2 Converting the boundary to an owin object\nI will convert the regions_sf object to an owin object using the the as.owin() function.\n\nboundary_owin &lt;- as.owin(regions_sf)\n\nOnce we have our ppp objects and owin object, we can start combining them to one object which can then be passed through the density() function.\n\nBattlesExplosionsStrategic DevelopmentsViolence Against Civilians\n\n\n\nbattlesQ121_ppp_com&lt;- battlesQ121_ppp[boundary_owin]\nbattlesQ121_ppp_com&lt;- rescale(battlesQ121_ppp_com, 1000, \"km\") \n\n\nbattlesQ221_ppp_com&lt;- battlesQ221_ppp[boundary_owin]\nbattlesQ221_ppp_com&lt;- rescale(battlesQ221_ppp_com, 1000, \"km\") \n\n\nbattlesQ321_ppp_com&lt;- battlesQ321_ppp[boundary_owin]\nbattlesQ321_ppp_com&lt;- rescale(battlesQ321_ppp_com, 1000, \"km\") \n\nbattlesQ421_ppp_com&lt;- battlesQ421_ppp[boundary_owin]\nbattlesQ421_ppp_com&lt;- rescale(battlesQ421_ppp_com, 1000, \"km\")\n\n#2022\n \nbattlesQ122_ppp_com&lt;- battlesQ122_ppp[boundary_owin]\nbattlesQ122_ppp_com&lt;- rescale(battlesQ122_ppp_com, 1000, \"km\")\n\nbattlesQ222_ppp_com&lt;- battlesQ222_ppp[boundary_owin]\nbattlesQ222_ppp_com&lt;- rescale(battlesQ222_ppp_com, 1000, \"km\")\n\nbattlesQ322_ppp_com&lt;- battlesQ322_ppp[boundary_owin]\nbattlesQ322_ppp_com&lt;- rescale(battlesQ322_ppp_com, 1000, \"km\")\n\nbattlesQ422_ppp_com&lt;- battlesQ422_ppp[boundary_owin]\nbattlesQ422_ppp_com&lt;- rescale(battlesQ422_ppp_com, 1000, \"km\")                                                                                \n#2023\n                                      \nbattlesQ123_ppp_com&lt;- battlesQ123_ppp[boundary_owin]\nbattlesQ123_ppp_com&lt;- rescale(battlesQ123_ppp_com, 1000, \"km\")\n\nbattlesQ223_ppp_com&lt;- battlesQ223_ppp[boundary_owin]\nbattlesQ223_ppp_com&lt;- rescale(battlesQ223_ppp_com, 1000, \"km\")\n\nbattlesQ323_ppp_com&lt;- battlesQ323_ppp[boundary_owin]\nbattlesQ323_ppp_com&lt;- rescale(battlesQ323_ppp_com, 1000, \"km\")\n\nbattlesQ423_ppp_com&lt;- battlesQ423_ppp[boundary_owin]\nbattlesQ423_ppp_com&lt;- rescale(battlesQ423_ppp_com, 1000, \"km\")\n\n#2024\n\nbattlesQ124_ppp_com&lt;- battlesQ124_ppp[boundary_owin]\nbattlesQ124_ppp&lt;- rescale(battlesQ124_ppp_com, 1000, \"km\")\n\nbattlesQ224_ppp_com&lt;- battlesQ224_ppp[boundary_owin]\nbattlesQ224_ppp_com&lt;- rescale(battlesQ224_ppp_com, 1000, \"km\")\n\n\n\n\nexpQ121_ppp_com&lt;- expQ121_ppp[boundary_owin]\nexpQ121_ppp_com&lt;- rescale(expQ121_ppp_com, 1000, \"km\")\n\nexpQ221_ppp_com&lt;- expQ221_ppp[boundary_owin]\nexpQ221_ppp_com&lt;- rescale(expQ221_ppp_com, 1000, \"km\")\n\nexpQ321_ppp_com&lt;- expQ321_ppp[boundary_owin]\nexpQ321_ppp_com&lt;- rescale(expQ321_ppp_com, 1000, \"km\") \n\nexpQ421_ppp_com&lt;- expQ421_ppp[boundary_owin]\nexpQ421_ppp_com&lt;- rescale(expQ421_ppp_com, 1000, \"km\")\n\n#2022\n \nexpQ122_ppp_com&lt;- expQ122_ppp[boundary_owin]\nexpQ122_ppp_com&lt;- rescale(expQ122_ppp_com, 1000, \"km\")\n\nexpQ222_ppp_com&lt;- expQ222_ppp[boundary_owin]\nexpQ222_ppp_com&lt;- rescale(expQ222_ppp_com, 1000, \"km\")\n\nexpQ322_ppp_com&lt;- expQ322_ppp[boundary_owin]\nexpQ322_ppp_com&lt;- rescale(expQ322_ppp_com, 1000, \"km\")\n\nexpQ422_ppp_com&lt;- expQ422_ppp[boundary_owin]\nexpQ422_ppp_com&lt;- rescale(expQ422_ppp_com, 1000, \"km\") \n\n#2023\n                                      \n \nexpQ123_ppp_com&lt;- expQ123_ppp[boundary_owin]\nexpQ123_ppp&lt;- rescale(expQ123_ppp_com, 1000, \"km\")\n\n \nexpQ223_ppp_com&lt;- expQ223_ppp[boundary_owin]\nexpQ223_ppp_com&lt;- rescale(expQ223_ppp_com, 1000, \"km\")\n\n \nexpQ323_ppp_com&lt;- expQ323_ppp[boundary_owin]\nexpQ323_ppp_com&lt;- rescale(expQ323_ppp_com, 1000, \"km\")\n\n \nexpQ423_ppp_com&lt;- expQ423_ppp[boundary_owin]\nexpQ423_ppp_com&lt;- rescale(expQ423_ppp_com, 1000, \"km\")\n\n#2024\n\nexpQ124_ppp_com&lt;- expQ124_ppp[boundary_owin]\nexpQ124_ppp_com&lt;- rescale(expQ124_ppp_com, 1000, \"km\")\n\nexpQ224_ppp_com&lt;-expQ224_ppp[boundary_owin]\nexpQ224_ppp_com&lt;- rescale(expQ224_ppp_com, 1000, \"km\")\n\n\n\n\nstrat_devQ121_ppp_com&lt;- strat_devQ121_ppp[boundary_owin]\nstrat_devQ121_ppp_com&lt;- rescale(strat_devQ121_ppp_com, 1000, \"km\")\n\nstrat_devQ221_ppp_com&lt;- strat_devQ221_ppp[boundary_owin]\nstrat_devQ221_ppp_com&lt;- rescale(strat_devQ221_ppp_com, 1000, \"km\")\n\nstrat_devQ321_ppp_com&lt;- strat_devQ321_ppp[boundary_owin]\nstrat_devQ321_ppp_com&lt;- rescale(strat_devQ321_ppp_com, 1000, \"km\")\n\nstrat_devQ421_ppp_com&lt;- strat_devQ421_ppp[boundary_owin]\nstrat_devQ421_ppp_com&lt;- rescale(strat_devQ421_ppp_com, 1000, \"km\")\n\n#2022\n\nstrat_devQ122_ppp_com&lt;- strat_devQ122_ppp[boundary_owin]\nstrat_devQ122_ppp_com&lt;- rescale(strat_devQ122_ppp_com, 1000, \"km\")\n\nstrat_devQ222_ppp_com&lt;- strat_devQ222_ppp[boundary_owin]\nstrat_devQ222_ppp_com&lt;- rescale(strat_devQ222_ppp_com, 1000, \"km\")\n\nstrat_devQ322_ppp_com&lt;- strat_devQ322_ppp[boundary_owin]\nstrat_devQ322_ppp_com&lt;- rescale(strat_devQ322_ppp_com, 1000, \"km\")\n\nstrat_devQ422_ppp_com&lt;- strat_devQ422_ppp[boundary_owin]\nstrat_devQ422_ppp_com&lt;- rescale(strat_devQ422_ppp_com, 1000, \"km\")\n\n#2023\n                                      \n \nstrat_devQ123_ppp_com&lt;- strat_devQ123_ppp[boundary_owin]\nstrat_devQ123_ppp_com&lt;- rescale(strat_devQ123_ppp_com, 1000, \"km\")\n \nstrat_devQ223_ppp_com&lt;- strat_devQ223_ppp[boundary_owin]\nstrat_devQ223_ppp_com&lt;- rescale(strat_devQ223_ppp_com, 1000, \"km\")\n\nstrat_devQ323_ppp_com&lt;- strat_devQ323_ppp[boundary_owin]\nstrat_devQ323_ppp_com&lt;- rescale(strat_devQ323_ppp_com, 1000, \"km\")\n\nstrat_devQ423_ppp_com&lt;- strat_devQ423_ppp[boundary_owin]\nstrat_devQ423_ppp_com&lt;- rescale(strat_devQ423_ppp_com, 1000, \"km\")\n\n#2024\n\nstrat_devQ124_ppp_com&lt;- strat_devQ124_ppp[boundary_owin]\nstrat_devQ124_ppp_com&lt;- rescale(strat_devQ124_ppp_com, 1000, \"km\")\n\nstrat_devQ224_ppp_com&lt;-strat_devQ224_ppp[boundary_owin]\nstrat_devQ224_ppp_com&lt;- rescale(strat_devQ224_ppp_com, 1000, \"km\")\n\n\n\n\ncivViolenceQ121_ppp_com&lt;- civViolenceQ121_ppp[boundary_owin]\ncivViolenceQ121_ppp_com&lt;- rescale(civViolenceQ121_ppp_com, 1000, \"km\")\n\ncivViolenceQ221_ppp_com&lt;- civViolenceQ221_ppp[boundary_owin]\ncivViolenceQ221_ppp_com&lt;- rescale(civViolenceQ221_ppp_com, 1000, \"km\")\n \ncivViolenceQ321_ppp_com&lt;- civViolenceQ321_ppp[boundary_owin]\ncivViolenceQ321_ppp_com&lt;- rescale(civViolenceQ321_ppp_com, 1000, \"km\")\n\ncivViolenceQ421_ppp_com&lt;- civViolenceQ421_ppp[boundary_owin]\ncivViolenceQ421_ppp_com&lt;- rescale(civViolenceQ421_ppp_com, 1000, \"km\")\n\n#2022\n\ncivViolenceQ122_ppp_com&lt;- civViolenceQ122_ppp[boundary_owin]\ncivViolenceQ122_ppp_com&lt;- rescale(civViolenceQ122_ppp_com, 1000, \"km\")\n\ncivViolenceQ222_ppp_com&lt;- civViolenceQ222_ppp[boundary_owin]\ncivViolenceQ222_ppp_com&lt;- rescale(civViolenceQ222_ppp_com, 1000, \"km\")\n\ncivViolenceQ322_ppp_com&lt;- civViolenceQ322_ppp[boundary_owin]\ncivViolenceQ322_ppp_com&lt;- rescale(civViolenceQ322_ppp_com, 1000, \"km\")\n\ncivViolenceQ422_ppp_com&lt;- civViolenceQ422_ppp[boundary_owin]\ncivViolenceQ422_ppp_com&lt;- rescale(civViolenceQ422_ppp_com, 1000, \"km\")\n\n#2023\n                                      \ncivViolenceQ123_ppp_com&lt;- civViolenceQ123_ppp[boundary_owin]\ncivViolenceQ123_ppp_com&lt;- rescale(civViolenceQ123_ppp_com, 1000, \"km\")\n\ncivViolenceQ223_ppp_com&lt;- civViolenceQ223_ppp[boundary_owin]\ncivViolenceQ223_ppp_com&lt;- rescale(civViolenceQ223_ppp_com, 1000, \"km\")\n\ncivViolenceQ323_ppp_com&lt;- civViolenceQ323_ppp[boundary_owin]\ncivViolenceQ323_ppp_com&lt;- rescale(civViolenceQ323_ppp_com, 1000, \"km\")\n\ncivViolenceQ423_ppp_com&lt;- civViolenceQ423_ppp[boundary_owin]\ncivViolenceQ423_ppp_com&lt;- rescale(civViolenceQ423_ppp_com, 1000, \"km\")\n\n#2024\n\ncivViolenceQ124_ppp_com&lt;- civViolenceQ124_ppp[boundary_owin]\ncivViolenceQ124_ppp_com&lt;- rescale(civViolenceQ124_ppp_com, 1000, \"km\")\n\ncivViolenceQ224_ppp_com&lt;- civViolenceQ224_ppp[boundary_owin]\ncivViolenceQ224_ppp_com&lt;- rescale(civViolenceQ224_ppp_com, 1000, \"km\")"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#computing-the-quarterly-kde-layers",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#computing-the-quarterly-kde-layers",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.3 Computing the quarterly KDE Layers",
    "text": "1.3 Computing the quarterly KDE Layers\nI will now use the combined ppp object to derive the quarterly KDE layers, sorted by the different conflict types. To find the optimal method for calculation of sigma, I did a couple of test plots. I first plotted the KDE layer with the bw.diggle() method of computing the sigma value:\n\nbat_q121_kde&lt;- density(battlesQ121_ppp_com, sigma=bw.diggle(battlesQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \nplot(bat_q121_kde, main=\"Battles in 1st Quarter of 2021\")\n\n\n\n\n\n\n\n\nHowever, as seen above, the map barely showed any patterns or colouring. This was probably due to the fact that the bw.diggle() was more aptly suited for datasets that leaned towards more uniform distributions. From our base plots earlier, the points had significant clustering in some areas, which was probably why this map did not reflect anything. Next, I tried the bw.ppl() method. This method is preferred for datasets where the distribution of spatial points are less homogenous, as is the case with ours.\n\nbat_q121_kde&lt;- density(battlesQ121_ppp_com, sigma=bw.ppl(battlesQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \nplot(bat_q121_kde, main=\"Battles in 1st Quarter of 2021\")\n\n\n\n\n\n\n\n\nThe result was good and enabled me to identify where a cluster of points can be seen. I decided that the bw.ppl() method was better than the bw.diggle() method to calculate sigma for our particular dataset. However, when I began plotting the quarterly layers, I quickly realised that some of the plots were once again, appearing blank. I figured this could be due to the bandwidth set by the function being too small for the quarterly data.\n\nbat_q121_kde&lt;- density(battlesQ121_ppp_com, sigma=bw.ppl(battlesQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nbat_q221_kde&lt;-density(battlesQ221_ppp_com, sigma=bw.ppl(battlesQ221_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q321_kde&lt;-density(battlesQ321_ppp_com, sigma=bw.ppl(battlesQ321_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q421_kde&lt;-density(battlesQ421_ppp_com, sigma=bw.ppl(battlesQ421_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(bat_q121_kde, main=\"Battles in 1st Quarter of 2021\")\nplot(bat_q221_kde, main=\"Battles in 2nd Quarter of 2021\")\nplot(bat_q321_kde, main=\"Battles in 3rd Quarter of 2021\")\nplot(bat_q421_kde, main=\"Battles in 4th Quarter of 2021\")\n\n\n\n\n\n\n\n\nHence, I decided to try the bw.CvL() method, as it is similar to the bw.ppl() method, just with a minimised prediction error. When I plotted the maps, I was satisified with the result, and chose this as the method to go with.\n\nBattlesExplosionsStrategic DevelopmentsViolence against Civilians\n\n\n\n2021202220232024\n\n\n\nbat_q121_kde&lt;- density(battlesQ121_ppp_com, sigma=bw.CvL(battlesQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nbat_q221_kde&lt;-density(battlesQ221_ppp_com, sigma=bw.CvL(battlesQ221_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q321_kde&lt;-density(battlesQ321_ppp_com, sigma=bw.CvL(battlesQ321_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q421_kde&lt;-density(battlesQ421_ppp_com, sigma=bw.CvL(battlesQ421_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(bat_q121_kde, main=\"Battles in 1st Quarter of 2021\")\nplot(bat_q221_kde, main=\"Battles in 2nd Quarter of 2021\")\nplot(bat_q321_kde, main=\"Battles in 3rd Quarter of 2021\")\nplot(bat_q421_kde, main=\"Battles in 4th Quarter of 2021\")\n\n\n\n\n\n\n\n\n\n\n\nbat_q122_kde&lt;- density(battlesQ122_ppp_com, sigma=bw.CvL(battlesQ122_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nbat_q222_kde&lt;-density(battlesQ222_ppp_com, sigma=bw.CvL(battlesQ222_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q322_kde&lt;-density(battlesQ322_ppp_com, sigma=bw.CvL(battlesQ322_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q422_kde&lt;-density(battlesQ422_ppp_com, sigma=bw.CvL(battlesQ422_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(bat_q122_kde, main=\"Battles in 1st Quarter of 2022\")\nplot(bat_q222_kde, main=\"Battles in 2nd Quarter of 2022\")\nplot(bat_q322_kde, main=\"Battles in 3rd Quarter of 2022\")\nplot(bat_q422_kde, main=\"Battles in 4th Quarter of 2022\")\n\n\n\n\n\n\n\n\n\n\n\nbat_q123_kde&lt;- density(battlesQ123_ppp_com, sigma=bw.CvL(battlesQ123_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nbat_q223_kde&lt;-density(battlesQ223_ppp_com, sigma=bw.CvL(battlesQ223_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q323_kde&lt;-density(battlesQ323_ppp_com, sigma=bw.CvL(battlesQ323_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q423_kde&lt;-density(battlesQ423_ppp_com, sigma=bw.CvL(battlesQ423_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(bat_q123_kde, main=\"Battles in 1st Quarter of 2023\")\nplot(bat_q223_kde, main=\"Battles in 2nd Quarter of 2023\")\nplot(bat_q323_kde, main=\"Battles in 3rd Quarter of 2023\")\nplot(bat_q423_kde, main=\"Battles in 4th Quarter of 2023\")\n\n\n\n\n\n\n\n\n\n\n\nbat_q124_kde&lt;- density(battlesQ124_ppp_com, sigma=bw.CvL(battlesQ124_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nbat_q224_kde&lt;-density(battlesQ224_ppp_com, sigma=bw.CvL(battlesQ224_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(1,2))\nplot(bat_q124_kde, main=\"Battles in 1st Quarter of 2024\")\nplot(bat_q224_kde, main=\"Battles in 2nd Quarter of 2024\")\n\n\n\n\n\n\n\n\n\n\n\nFor Battles, we see that the conflicts have slowly travelled to the center (Mandalay, Magwe Divisions) from the North-East (Kachin and Shan states) throughout the years 2021-2023. It also spread southward (Mon and Tenesserium States). This is due to the onset of a Military coup in Myanmar, resulting in violence in various parts of the land, including the central regions of Mandalay and Yangon (Maizland, 2022). Intensity of Battles saw a sharp decline from the last quarter of 2023 to the first two quarters of 2024.\n\n\n\n2021202220232024\n\n\n\nexp_q121_kde&lt;- density(expQ121_ppp_com, sigma=bw.CvL(expQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nexp_q221_kde&lt;-density(expQ221_ppp_com, sigma=bw.CvL(expQ221_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nexp_q321_kde&lt;-density(expQ321_ppp_com, sigma=bw.CvL(expQ321_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nexp_q421_kde&lt;-density(expQ421_ppp_com, sigma=bw.CvL(expQ421_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(exp_q121_kde, main=\"Explosions in 1st Quarter of 2021\")\nplot(exp_q221_kde, main=\"Explosions in 2nd Quarter of 2021\")\nplot(exp_q321_kde, main=\"Explosions in 3rd Quarter of 2021\")\nplot(exp_q421_kde, main=\"Explosions in 4th Quarter of 2021\")\n\n\n\n\n\n\n\n\n\n\n\nexp_q122_kde&lt;- density(expQ122_ppp_com, sigma=bw.CvL(expQ122_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nexp_q222_kde&lt;-density(expQ222_ppp_com, sigma=bw.CvL(expQ222_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nexp_q322_kde&lt;-density(expQ322_ppp_com, sigma=bw.CvL(expQ322_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nexp_q422_kde&lt;-density(expQ422_ppp_com, sigma=bw.CvL(expQ422_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(exp_q122_kde, main=\"Explosions in 1st Quarter of 2022\")\nplot(exp_q222_kde, main=\"Explosions in 2nd Quarter of 2022\")\nplot(exp_q322_kde, main=\"Explosions in 3rd Quarter of 2022\")\nplot(exp_q422_kde, main=\"Explosions in 4th Quarter of 2022\")\n\n\n\n\n\n\n\n\n\n\n\nexp_q123_kde&lt;- density(expQ123_ppp_com, sigma=bw.CvL(expQ123_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nexp_q223_kde&lt;-density(expQ223_ppp_com, sigma=bw.CvL(expQ223_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nexp_q323_kde&lt;-density(expQ323_ppp_com, sigma=bw.CvL(expQ323_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nexp_q423_kde&lt;-density(expQ423_ppp_com, sigma=bw.CvL(expQ423_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(exp_q123_kde, main=\"Explosions in 1st Quarter of 2023\")\nplot(exp_q223_kde, main=\"Explosions in 2nd Quarter of 2023\")\nplot(exp_q323_kde, main=\"Explosions in 3rd Quarter of 2023\")\nplot(exp_q423_kde, main=\"Explosions in 4th Quarter of 2023\")\n\n\n\n\n\n\n\n\n\n\n\nexp_q124_kde&lt;- density(expQ124_ppp_com, sigma=bw.CvL(expQ124_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nexp_q224_kde&lt;-density(expQ224_ppp_com, sigma=bw.CvL(expQ224_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\n\npar(mfrow=c(1,2))\nplot(exp_q124_kde, main=\"Explosions in 1st Quarter of 2024\")\nplot(exp_q224_kde, main=\"Explosions in 2nd Quarter of 2024\")\n\n\n\n\n\n\n\n\n\n\n\nAs for Explosions, we see that it peaked in intensity in 2022-2023, and was also concentrated in the central regions of Myanmar.\n\n\n\n2021202220232024\n\n\n\nstrat_dev_q121_kde&lt;- density(strat_devQ121_ppp_com, sigma=bw.CvL(strat_devQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nstrat_dev_q221_kde&lt;-density(strat_devQ221_ppp_com, sigma=bw.CvL(strat_devQ221_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nstrat_dev_q321_kde&lt;-density(strat_devQ321_ppp_com, sigma=bw.CvL(strat_devQ321_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nstrat_dev_q421_kde&lt;-density(strat_devQ421_ppp_com, sigma=bw.CvL(strat_devQ421_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(strat_dev_q121_kde, main=\"Strategic Developments in 1st Quarter of 2021\")\nplot(strat_dev_q221_kde, main=\"Strategic Developments in 2nd Quarter of 2021\")\nplot(strat_dev_q321_kde, main=\"Strategic Developments in 3rd Quarter of 2021\")\nplot(strat_dev_q421_kde, main=\"Strategic Developments in 4th Quarter of 2021\")\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_q122_kde&lt;- density(strat_devQ122_ppp_com, sigma=bw.CvL(strat_devQ122_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nstrat_dev_q222_kde&lt;-density(strat_devQ222_ppp_com, sigma=bw.CvL(strat_devQ222_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nstrat_dev_q322_kde&lt;-density(strat_devQ322_ppp_com, sigma=bw.CvL(strat_devQ322_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nstrat_dev_q422_kde&lt;-density(strat_devQ422_ppp_com, sigma=bw.CvL(strat_devQ422_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(strat_dev_q122_kde, main=\"Strategic Developments in 1st Quarter of 2022\")\nplot(strat_dev_q222_kde, main=\"Strategic Developments in 2nd Quarter of 2022\")\nplot(strat_dev_q322_kde, main=\"Strategic Developments in 3rd Quarter of 2022\")\nplot(strat_dev_q422_kde, main=\"Strategic Developments in 4th Quarter of 2022\")\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_q123_kde&lt;- density(strat_devQ123_ppp_com, sigma=bw.CvL(strat_devQ123_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nstrat_dev_q223_kde&lt;-density(strat_devQ223_ppp_com, sigma=bw.CvL(strat_devQ223_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nstrat_dev_q323_kde&lt;-density(strat_devQ323_ppp_com, sigma=bw.CvL(strat_devQ323_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nstrat_dev_q423_kde&lt;-density(strat_devQ423_ppp_com, sigma=bw.CvL(strat_devQ423_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(strat_dev_q123_kde, main=\"Strategic Developments in 1st Quarter of 2023\")\nplot(strat_dev_q223_kde, main=\"Strategic Developments in 2nd Quarter of 2023\")\nplot(strat_dev_q323_kde, main=\"Strategic Developments in 3rd Quarter of 2023\")\nplot(strat_dev_q423_kde, main=\"Strategic Developments in 4th Quarter of 2023\")\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_q124_kde&lt;- density(strat_devQ124_ppp_com, sigma=bw.CvL(strat_devQ124_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nstrat_dev_q224_kde&lt;-density(strat_devQ224_ppp_com, sigma=bw.CvL(strat_devQ224_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\n\npar(mfrow=c(1,2))\nplot(strat_dev_q124_kde, main=\"Strategic Developments in 1st Quarter of 2024\")\nplot(strat_dev_q224_kde, main=\"Strategic Developments in 2nd Quarter of 2024\")\n\n\n\n\n\n\n\n\n\n\n\nStrategic Developments seem to still be ongoing even as late as the 2nd quarter of this year, after having increased in 2022. It is also to be noted that as for Strategic Developments, it is only concentrated in the central regions of Myanmar and not so much on the outskirts.\n\n\n\n2021202220232024\n\n\n\ncivViolence_q121_kde&lt;- density(civViolenceQ121_ppp_com, sigma=bw.CvL(civViolenceQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\ncivViolence_q221_kde&lt;-density(civViolenceQ221_ppp_com, sigma=bw.CvL(civViolenceQ221_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\ncivViolence_q321_kde&lt;-density(civViolenceQ321_ppp_com, sigma=bw.CvL(civViolenceQ321_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\ncivViolence_q421_kde&lt;-density(civViolenceQ421_ppp_com, sigma=bw.CvL(civViolenceQ421_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(civViolence_q121_kde, main=\"Violence Against Civilians in 1st Quarter of 2021\")\nplot(civViolence_q221_kde, main=\"Violence Against Civilians in 2nd Quarter of 2021\")\nplot(civViolence_q321_kde, main=\"Violence Against Civilians in 3rd Quarter of 2021\")\nplot(civViolence_q421_kde, main=\"Violence Against Civilians in 4th Quarter of 2021\")\n\n\n\n\n\n\n\n\n\n\n\ncivViolence_q122_kde&lt;- density(civViolenceQ122_ppp_com, sigma=bw.CvL(civViolenceQ122_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\ncivViolence_q222_kde&lt;-density(civViolenceQ222_ppp_com, sigma=bw.CvL(civViolenceQ222_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\ncivViolence_q322_kde&lt;-density(civViolenceQ322_ppp_com, sigma=bw.CvL(civViolenceQ322_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\ncivViolence_q422_kde&lt;-density(civViolenceQ422_ppp_com, sigma=bw.CvL(civViolenceQ422_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(civViolence_q122_kde, main=\"Violence Against Civilians in 1st Quarter of 2022\")\nplot(civViolence_q222_kde, main=\"Violence Against Civilians in 2nd Quarter of 2022\")\nplot(civViolence_q322_kde, main=\"Violence Against Civilians in 3rd Quarter of 2022\")\nplot(civViolence_q422_kde, main=\"Violence Against Civilians in 4th Quarter of 2022\")\n\n\n\n\n\n\n\n\n\n\n\ncivViolence_q123_kde&lt;- density(civViolenceQ123_ppp_com, sigma=bw.CvL(civViolenceQ123_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\ncivViolence_q223_kde&lt;-density(civViolenceQ223_ppp_com, sigma=bw.CvL(civViolenceQ223_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\ncivViolence_q323_kde&lt;-density(civViolenceQ323_ppp_com, sigma=bw.CvL(civViolenceQ323_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\ncivViolence_q423_kde&lt;-density(civViolenceQ423_ppp_com, sigma=bw.CvL(civViolenceQ423_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(civViolence_q123_kde, main=\"Violence Against Civilians in 1st Quarter of 2023\")\nplot(civViolence_q223_kde, main=\"Violence Against Civilians in 2nd Quarter of 2023\")\nplot(civViolence_q323_kde, main=\"Violence Against Civilians in 3rd Quarter of 2023\")\nplot(civViolence_q423_kde, main=\"Violence Against Civilians in 4th Quarter of 2023\")\n\n\n\n\n\n\n\n\n\n\n\ncivViolence_q124_kde&lt;- density(civViolenceQ124_ppp_com, sigma=bw.CvL(civViolenceQ124_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\ncivViolence_q224_kde&lt;-density(civViolenceQ224_ppp_com, sigma=bw.CvL(civViolenceQ224_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\n\n\npar(mfrow=c(1,2))\nplot(civViolence_q124_kde, main=\"Violence Against Civilians in 1st Quarter of 2024\")\nplot(civViolence_q224_kde, main=\"Violence Against Civilians in 2nd Quarter of 2024\")\n\n\n\n\n\n\n\n\n\n\n\nViolence Against the civilians can be observed in the central and southern regions of Myanmar througout all the quarters, with the concentration once again, being at the central region. There appears to be a brief reduction in the intensity of the attacks in the 3rd quarter of 2022."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#computing-second-order-spatial-point-process-analysis",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#computing-second-order-spatial-point-process-analysis",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.4 Computing Second Order Spatial point Process analysis",
    "text": "1.4 Computing Second Order Spatial point Process analysis\nIn this section, I will be computing the quarterly second order spatial point process analysis for each of the conflict types. I will be using the K- function to compute the analysis. This is because as seen from our KDE layers, density of points are on different scales for the different quarters and the K-function will allow us to analyse the spatial point with different scales.\n\nBattlesExplosions\n\n\n\n\n\n\n\n\n\n\n\nexp_ppp&lt;- as.ppp(st_coordinates(exp_sf), st_bbox(exp_sf))\n\nWarning: data contain duplicated points\n\nexp_ppp_com&lt;- exp_ppp[boundary_owin]\nexp_ppp_com&lt;-rescale(exp_ppp_com, 1000, 'km')\n\n\nexp_g = Gest(exp_ppp_com) \nexp_g.csr &lt;- envelope(exp_ppp_com, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, \n[14:11 remaining, estimate finish 2024-09-22 19:00:58]\n3, \n[14:43 remaining, estimate finish 2024-09-22 19:01:40]\n4, \n[14:26 remaining, estimate finish 2024-09-22 19:01:32]\n5, \n[14:18 remaining, estimate finish 2024-09-22 19:01:33]\n6, \n[13:59 remaining, estimate finish 2024-09-22 19:01:23]\n7, \n[13:43 remaining, estimate finish 2024-09-22 19:01:16]\n8, \n[13:30 remaining, estimate finish 2024-09-22 19:01:11]\n9, \n[13:17 remaining, estimate finish 2024-09-22 19:01:07]\n10, \n[13:06 remaining, estimate finish 2024-09-22 19:01:04]\n11, \n[12:55 remaining, estimate finish 2024-09-22 19:01:01]\n12, \n[12:46 remaining, estimate finish 2024-09-22 19:01:02]\n13, \n[12:37 remaining, estimate finish 2024-09-22 19:01:02]\n14, \n[12:27 remaining, estimate finish 2024-09-22 19:01:00]\n15, \n[12:19 remaining, estimate finish 2024-09-22 19:01:01]\n16, \n[12:11 remaining, estimate finish 2024-09-22 19:01:01]\n17, \n[12:01 remaining, estimate finish 2024-09-22 19:01:00]\n18, \n[11:52 remaining, estimate finish 2024-09-22 19:01:00]\n19, \n[11:42 remaining, estimate finish 2024-09-22 19:00:59]\n20, \n[11:33 remaining, estimate finish 2024-09-22 19:00:59]\n21, \n[11:25 remaining, estimate finish 2024-09-22 19:00:59]\n22, \n[11:16 remaining, estimate finish 2024-09-22 19:00:59]\n23, \n[11:08 remaining, estimate finish 2024-09-22 19:01:00]\n24, \n[10:59 remaining, estimate finish 2024-09-22 19:01:00]\n25, \n[10:50 remaining, estimate finish 2024-09-22 19:01:00]\n26, \n[11:09 remaining, estimate finish 2024-09-22 19:01:37]\n27, \n[11:34 remaining, estimate finish 2024-09-22 19:02:23]\n28, \n[11:31 remaining, estimate finish 2024-09-22 19:02:32]\n29, \n[11:54 remaining, estimate finish 2024-09-22 19:03:18]\n30, \n[12:12 remaining, estimate finish 2024-09-22 19:03:59]\n31, \n[12:31 remaining, estimate finish 2024-09-22 19:04:42]\n32, \n[12:29 remaining, estimate finish 2024-09-22 19:04:54]\n33, \n[12:14 remaining, estimate finish 2024-09-22 19:04:49]\n34, \n[12:00 remaining, estimate finish 2024-09-22 19:04:44]\n35, \n[11:54 remaining, estimate finish 2024-09-22 19:04:53]\n36, \n[11:47 remaining, estimate finish 2024-09-22 19:04:58]\n37, \n[11:47 remaining, estimate finish 2024-09-22 19:05:17]\n38, \n[11:48 remaining, estimate finish 2024-09-22 19:05:36]\n39, \n[11:50 remaining, estimate finish 2024-09-22 19:05:58]\n40, \n[11:36 remaining, estimate finish 2024-09-22 19:05:55]\n41, \n[11:21 remaining, estimate finish 2024-09-22 19:05:49]\n42, \n[11:06 remaining, estimate finish 2024-09-22 19:05:43]\n43, \n[10:51 remaining, estimate finish 2024-09-22 19:05:37]\n44, \n[10:35 remaining, estimate finish 2024-09-22 19:05:30]\n45, \n[10:20 remaining, estimate finish 2024-09-22 19:05:24]\n46, \n[10:07 remaining, estimate finish 2024-09-22 19:05:21]\n47, \n[10:07 remaining, estimate finish 2024-09-22 19:05:43]\n48, \n[10:07 remaining, estimate finish 2024-09-22 19:06:05]\n49, \n[10:07 remaining, estimate finish 2024-09-22 19:06:28]\n50, \n[10:05 remaining, estimate finish 2024-09-22 19:06:49]\n51,  [9:51 remaining] 52,  [9:41 remaining] 53,  [9:37 remaining] 54,  [9:33 remaining] 55,  [9:23 remaining] 56,  [9:07 remaining] 57,  [8:51 remaining] 58,  [8:41 remaining] 59,  [8:35 remaining] 60,  [8:27 remaining] 61,  [8:11 remaining] 62,  [7:55 remaining] 63,  [7:40 remaining] 64,  [7:24 remaining] 65,  [7:09 remaining] 66,  [6:55 remaining] 67,  [6:40 remaining] 68,  [6:26 remaining] 69,  [6:12 remaining] 70,\n [6:01 remaining] 71,  [5:52 remaining] 72,  [5:43 remaining] 73,  [5:35 remaining] 74,  [5:21 remaining] 75,  [5:06 remaining] 76,  [4:52 remaining] 77,  [4:39 remaining] 78,  [4:25 remaining] 79,  [4:11 remaining] 80,  [3:58 remaining] 81,  [3:45 remaining] 82,  [3:31 remaining] 83,  [3:18 remaining] 84,  [3:05 remaining] 85,  [2:52 remaining] 86,  [2:39 remaining] 87,  [2:28 remaining] 88,  [2:16 remaining] 89,  [2:03 remaining] 90,\n [1:50 remaining] 91,  [1:38 remaining] 92,  [1:25 remaining] 93,  [1:13 remaining] 94,  [1:01 remaining] 95,  [49 sec remaining] 96,  [37 sec remaining] 97,  [25 sec remaining] 98,  [13 sec remaining] \n99.\n\nDone.\n\nplot(exp_g.csr)\n\n\n\n\n\n\n\n\n\nStrategic Developments\n\nstrat_dev_ppp&lt;- as.ppp(st_coordinates(strat_dev_sf), st_bbox(strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_dev_ppp_com&lt;- strat_dev_ppp[boundary_owin]\nstrat_dev_ppp_com&lt;-rescale(strat_dev_ppp_com, 1000, 'km')\n\n\nstrat_dev_g = Gest(strat_dev_ppp_com) \nstrat_dev_g.csr &lt;- envelope(strat_dev_ppp_com, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, \n[35:55 remaining, estimate finish 2024-09-22 19:44:36]\n3, \n[38:36 remaining, estimate finish 2024-09-22 19:47:42]\n4, \n[38:31 remaining, estimate finish 2024-09-22 19:48:02]\n5, \n[38:42 remaining, estimate finish 2024-09-22 19:48:39]\n6, \n[38:18 remaining, estimate finish 2024-09-22 19:48:40]\n7, \n[38:07 remaining, estimate finish 2024-09-22 19:48:55]\n8, \n[37:14 remaining, estimate finish 2024-09-22 19:48:24]\n9, \n[37:07 remaining, estimate finish 2024-09-22 19:48:43]\n10, \n[36:50 remaining, estimate finish 2024-09-22 19:48:51]\n11, \n[36:34 remaining, estimate finish 2024-09-22 19:49:01]\n12, \n[36:16 remaining, estimate finish 2024-09-22 19:49:10]\n13, \n[35:18 remaining, estimate finish 2024-09-22 19:48:32]\n14, \n[33:10 remaining, estimate finish 2024-09-22 19:46:33]\n15, \n[31:22 remaining, estimate finish 2024-09-22 19:44:54]\n16, \n[29:48 remaining, estimate finish 2024-09-22 19:43:29]\n17, \n[28:24 remaining, estimate finish 2024-09-22 19:42:15]\n18, \n[27:06 remaining, estimate finish 2024-09-22 19:41:06]\n19, \n[25:56 remaining, estimate finish 2024-09-22 19:40:04]\n20, \n[24:52 remaining, estimate finish 2024-09-22 19:39:10]\n21, \n[23:55 remaining, estimate finish 2024-09-22 19:38:22]\n22, \n[23:02 remaining, estimate finish 2024-09-22 19:37:37]\n23, \n[22:12 remaining, estimate finish 2024-09-22 19:36:56]\n24, \n[21:27 remaining, estimate finish 2024-09-22 19:36:19]\n25, \n[20:43 remaining, estimate finish 2024-09-22 19:35:45]\n26, \n[20:03 remaining, estimate finish 2024-09-22 19:35:13]\n27, \n[19:26 remaining, estimate finish 2024-09-22 19:34:45]\n28, \n[18:51 remaining, estimate finish 2024-09-22 19:34:19]\n29, \n[18:17 remaining, estimate finish 2024-09-22 19:33:54]\n30, \n[17:44 remaining, estimate finish 2024-09-22 19:33:30]\n31, \n[17:14 remaining, estimate finish 2024-09-22 19:33:08]\n32, \n[16:45 remaining, estimate finish 2024-09-22 19:32:49]\n33, \n[16:18 remaining, estimate finish 2024-09-22 19:32:30]\n34, \n[15:53 remaining, estimate finish 2024-09-22 19:32:15]\n35, \n[15:31 remaining, estimate finish 2024-09-22 19:32:03]\n36, \n[15:08 remaining, estimate finish 2024-09-22 19:31:51]\n37, \n[14:45 remaining, estimate finish 2024-09-22 19:31:37]\n38, \n[14:23 remaining, estimate finish 2024-09-22 19:31:24]\n39, \n[14:25 remaining, estimate finish 2024-09-22 19:31:51]\n40, \n[14:27 remaining, estimate finish 2024-09-22 19:32:19]\n41, \n[14:24 remaining, estimate finish 2024-09-22 19:32:39]\n42, \n[14:23 remaining, estimate finish 2024-09-22 19:33:01]\n43, \n[14:12 remaining, estimate finish 2024-09-22 19:33:09]\n44, \n[14:00 remaining, estimate finish 2024-09-22 19:33:15]\n45, \n[13:57 remaining, estimate finish 2024-09-22 19:33:37]\n46, \n[13:53 remaining, estimate finish 2024-09-22 19:33:58]\n47, \n[13:44 remaining, estimate finish 2024-09-22 19:34:11]\n48, \n[13:21 remaining, estimate finish 2024-09-22 19:33:57]\n49, \n[13:00 remaining, estimate finish 2024-09-22 19:33:47]\n50, \n[12:55 remaining, estimate finish 2024-09-22 19:34:07]\n51, \n[12:46 remaining, estimate finish 2024-09-22 19:34:22]\n52, \n[12:37 remaining, estimate finish 2024-09-22 19:34:38]\n53, \n[12:28 remaining, estimate finish 2024-09-22 19:34:52]\n54, \n[12:13 remaining, estimate finish 2024-09-22 19:34:55]\n55, \n[11:51 remaining, estimate finish 2024-09-22 19:34:42]\n56, \n[11:29 remaining, estimate finish 2024-09-22 19:34:29]\n57, \n[11:08 remaining, estimate finish 2024-09-22 19:34:16]\n58, \n[10:47 remaining, estimate finish 2024-09-22 19:34:04]\n59, \n[10:26 remaining, estimate finish 2024-09-22 19:33:53]\n60, \n[10:06 remaining, estimate finish 2024-09-22 19:33:41]\n61,  [9:46 remaining] 62,  [9:32 remaining] 63,  [9:22 remaining] 64,  [9:06 remaining] 65,  [8:54 remaining] 66,  [8:44 remaining] 67,  [8:32 remaining] 68,  [8:18 remaining] 69,  [7:59 remaining] 70,  [7:40 remaining] 71,  [7:21 remaining] 72,  [7:09 remaining] 73,  [6:56 remaining] 74,  [6:43 remaining] 75,  [6:29 remaining] 76,  [6:16 remaining] 77,  [6:02 remaining] 78,  [5:48 remaining] 79,  [5:29 remaining] 80,\n [5:11 remaining] 81,  [4:53 remaining] 82,  [4:35 remaining] 83,  [4:17 remaining] 84,  [4:00 remaining] 85,  [3:43 remaining] 86,  [3:28 remaining] 87,  [3:13 remaining] 88,  [2:56 remaining] 89,  [2:40 remaining] 90,  [2:25 remaining] 91,  [2:09 remaining] 92,  [1:52 remaining] 93,  [1:35 remaining] 94,  [1:19 remaining] 95,  [1:03 remaining] 96,  [47 sec remaining] 97,  [31 sec remaining] 98,  [16 sec remaining] \n99.\n\nDone.\n\nplot(strat_dev_g.csr)\n\n\n\n\n\n\n\n\n\n\nCivilian Violence\n\ncivViolence_ppp&lt;- as.ppp(st_coordinates(civViolence_sf), st_bbox(civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolence_ppp_com&lt;- civViolence_ppp[boundary_owin]\ncivViolence_ppp_com&lt;-rescale(civViolence_ppp_com, 1000, 'km')\n\n\ncivViolence_g.csr &lt;- envelope(civViolence_ppp_com, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [7:54 remaining] 3,\n [7:52 remaining] 4,  [7:39 remaining] 5,  [7:34 remaining] 6,\n [7:21 remaining] 7,  [7:16 remaining] 8,  [7:55 remaining] 9,\n [7:58 remaining] 10,  [8:45 remaining] 11,  [9:46 remaining] 12,\n\n[10:28 remaining, estimate finish 2024-09-22 19:45:33]\n13, \n[10:48 remaining, estimate finish 2024-09-22 19:46:05]\n14, \n[11:21 remaining, estimate finish 2024-09-22 19:46:51]\n15, \n[10:52 remaining, estimate finish 2024-09-22 19:46:27]\n16, \n[10:26 remaining, estimate finish 2024-09-22 19:46:06]\n17, \n[10:04 remaining, estimate finish 2024-09-22 19:45:49]\n18,  [9:46 remaining] 19,  [9:27 remaining] 20,\n [9:10 remaining] 21,  [8:56 remaining] 22,  [8:42 remaining] 23,\n [8:45 remaining] 24,  [9:00 remaining] 25,  [9:08 remaining] 26,\n [8:52 remaining] 27,  [8:58 remaining] 28,  [9:06 remaining] 29,\n [9:09 remaining] 30,  [9:13 remaining] 31,  [9:16 remaining] 32,\n [9:18 remaining] 33,  [9:21 remaining] 34,  [9:21 remaining] 35,\n [9:12 remaining] 36,  [8:56 remaining] 37,  [8:41 remaining] 38,\n [8:27 remaining] 39,  [8:13 remaining] 40,  [8:00 remaining] 41,\n [7:47 remaining] 42,  [7:34 remaining] 43,  [7:22 remaining] 44,\n [7:10 remaining] 45,  [6:58 remaining] 46,  [6:47 remaining] 47,\n [6:42 remaining] 48,  [6:41 remaining] 49,  [6:39 remaining] 50,\n [6:36 remaining] 51,  [6:33 remaining] 52,  [6:30 remaining] 53,\n [6:27 remaining] 54,  [6:23 remaining] 55,  [6:18 remaining] 56,\n [6:13 remaining] 57,  [6:08 remaining] 58,  [6:03 remaining] 59,\n [5:57 remaining] 60,  [5:51 remaining] 61,  [5:45 remaining] 62,\n [5:38 remaining] 63,  [5:32 remaining] 64,  [5:25 remaining] 65,\n [5:17 remaining] 66,  [5:10 remaining] 67,  [5:03 remaining] 68,\n [4:55 remaining] 69,  [4:43 remaining] 70,  [4:32 remaining] 71,\n [4:21 remaining] 72,  [4:10 remaining] 73,  [3:59 remaining] 74,\n [3:48 remaining] 75,  [3:37 remaining] 76,  [3:27 remaining] 77,\n [3:17 remaining] 78,  [3:06 remaining] 79,  [2:56 remaining] 80,\n [2:47 remaining] 81,  [2:37 remaining] 82,  [2:27 remaining] 83,\n [2:18 remaining] 84,  [2:08 remaining] 85,  [1:59 remaining] 86,\n [1:50 remaining] 87,  [1:41 remaining] 88,  [1:32 remaining] 89,\n [1:24 remaining] 90,  [1:15 remaining] 91,  [1:06 remaining] 92,\n [58 sec remaining] 93,  [50 sec remaining] 94,  [42 sec remaining] 95,\n [33 sec remaining] 96,  [25 sec remaining] 97,  [17 sec remaining] 98,\n [9 sec remaining] \n99.\n\nDone.\n\nplot(civViolence_g.csr)\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the plots above, we can further confirm that there is significant clustering of the spatial points for all four conflict types. This is because the black line (the observed G-function of our data) is well above the red dashed line (which indicates G function under Complete Spatial Randomness). This means that the pattern observed in the dataset differs significantly from the pattern of randomly spaced points, indicating the presence of clusters."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#computing-spatio-temporal-kde-layers",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#computing-spatio-temporal-kde-layers",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.5 Computing Spatio-Temporal KDE Layers",
    "text": "1.5 Computing Spatio-Temporal KDE Layers\n\nBattlesExplosionsStrategic DevelopmentsViolence Against Civilians\n\n\n\n2021202220232024\n\n\n\nbattle_st_21&lt;- quart_geo_bat %&gt;% \n  filter(year==\"2021\") %&gt;% \n  select(2,3)\n\nbattle_21_ppp&lt;- as.ppp(battle_st_21, coordinates=battle_st_21)\nbattle_21_owin&lt;- battle_21_ppp[boundary_owin]\n\nbattles_st_21_kde&lt;- spattemp.density(battle_21_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(battle_st_21$num_quarters)\n\n\nfor (i in tims2){\n  plot(battles_st_21_kde, i,\n  main = paste('STKDE of Q', i, \" 2021\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbattle_st_22&lt;- quart_geo_bat %&gt;% \n  filter(year==\"2022\") %&gt;% \n  select(2,3)\n\nbattle_22_ppp&lt;- as.ppp(battle_st_22, coordinates=battle_st_22)\nbattle_22_owin&lt;- battle_22_ppp[boundary_owin]\n\nbattles_st_22_kde&lt;- spattemp.density(battle_22_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nfor (i in tims2){\n  plot(battles_st_22_kde, i,\n  main = paste('STKDE of Q', i, \" 2022\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbattle_st_23&lt;- quart_geo_bat %&gt;% \n  filter(year==\"2023\") %&gt;% \n  select(2,3)\n\nbattle_23_ppp&lt;- as.ppp(battle_st_23, coordinates=battle_st_23)\nbattle_23_owin&lt;- battle_23_ppp[boundary_owin]\n\nbattles_st_23_kde&lt;- spattemp.density(battle_23_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nfor (i in tims2){\n  plot(battles_st_23_kde, i,\n  main = paste('STKDE of Q', i, \" 2023\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbattle_st_24&lt;- quart_geo_bat %&gt;% \n  filter(year==\"2024\") %&gt;% \n  select(2,3)\n\nbattle_24_ppp&lt;- as.ppp(battle_st_24, coordinates=battle_st_24)\nbattle_24_owin&lt;- battle_24_ppp[boundary_owin]\n\nbattles_st_24_kde&lt;- spattemp.density(battle_24_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(battle_st_24$num_quarters)\n\nfor (i in tims2){\n  plot(battles_st_24_kde, i,\n  main = paste('STKDE of Q', i, \" 2024\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021202220232024\n\n\n\nExp_st_21&lt;- quart_geo_exp %&gt;% \n  filter(year==\"2021\") %&gt;% \n  select(2,3)\n\nExp_21_ppp&lt;- as.ppp(Exp_st_21, coordinates=Exp_st_21)\nExp_21_owin&lt;- Exp_21_ppp[boundary_owin]\n\nExp_st_21_kde&lt;- spattemp.density(Exp_21_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(Exp_st_21$num_quarters)\n\n\nfor (i in tims2){\n  plot(Exp_st_21_kde, i,\n  main = paste('STKDE of Q', i, \" 2021\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExp_st_22&lt;- quart_geo_exp %&gt;% \n  filter(year==\"2022\") %&gt;% \n  select(2,3)\n\nExp_22_ppp&lt;- as.ppp(Exp_st_22, coordinates=Exp_st_22)\nExp_22_owin&lt;- Exp_22_ppp[boundary_owin]\n\nExp_st_22_kde&lt;- spattemp.density(Exp_22_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(Exp_st_22$num_quarters)\n\n\nfor (i in tims2){\n  plot(Exp_st_22_kde, i,\n  main = paste('STKDE of Q', i, \" 2022\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExp_st_23&lt;- quart_geo_exp %&gt;% \n  filter(year==\"2023\") %&gt;% \n  select(2,3)\n\nExp_23_ppp&lt;- as.ppp(Exp_st_23, coordinates=Exp_st_23)\nExp_23_owin&lt;- Exp_23_ppp[boundary_owin]\n\nExp_st_23_kde&lt;- spattemp.density(Exp_23_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(Exp_st_23$num_quarters)\n\n\nfor (i in tims2){\n  plot(Exp_st_23_kde, i,\n  main = paste('STKDE of Q', i, \" 2023\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExp_st_24&lt;- quart_geo_exp %&gt;% \n  filter(year==\"2024\") %&gt;% \n  select(2,3)\n\nExp_24_ppp&lt;- as.ppp(Exp_st_24, coordinates=Exp_st_24)\nExp_24_owin&lt;- Exp_24_ppp[boundary_owin]\n\nExp_st_24_kde&lt;- spattemp.density(Exp_24_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(Exp_st_24$num_quarters)\n\nfor (i in tims2){\n  plot(Exp_st_24_kde, i,\n  main = paste('STKDE of Q', i, \" 2024\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021202220232024\n\n\n\nstrat_dev_st_21&lt;- quart_geo_strat %&gt;% \n  filter(year==\"2021\") %&gt;% \n  select(2,3)\n\nstrat_dev_21_ppp&lt;- as.ppp(strat_dev_st_21, coordinates=strat_dev_st_21)\nstrat_dev_21_owin&lt;- strat_dev_21_ppp[boundary_owin]\n\nstrat_dev_st_21_kde&lt;- spattemp.density(strat_dev_21_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(strat_dev_st_21$num_quarters)\n\n\nfor (i in tims2){\n  plot(strat_dev_st_21_kde, i,\n  main = paste('STKDE of Q', i, \" 2021\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_st_22&lt;- quart_geo_strat %&gt;% \n  filter(year==\"2022\") %&gt;% \n  select(2,3)\n\nstrat_dev_22_ppp&lt;- as.ppp(strat_dev_st_22, coordinates=strat_dev_st_22)\nstrat_dev_22_owin&lt;- strat_dev_22_ppp[boundary_owin]\n\nstrat_dev_st_22_kde&lt;- spattemp.density(strat_dev_22_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(strat_dev_st_22$num_quarters)\n\n\nfor (i in tims2){\n  plot(strat_dev_st_22_kde, i,\n  main = paste('STKDE of Q', i, \" 2022\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_st_23&lt;- quart_geo_strat %&gt;% \n  filter(year==\"2023\") %&gt;% \n  select(2,3)\n\nstrat_dev_23_ppp&lt;- as.ppp(strat_dev_st_23, coordinates=strat_dev_st_23)\nstrat_dev_23_owin&lt;- strat_dev_23_ppp[boundary_owin]\n\nstrat_dev_st_23_kde&lt;- spattemp.density(strat_dev_23_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(strat_dev_st_23$num_quarters)\n\n\nfor (i in tims2){\n  plot(strat_dev_st_23_kde, i,\n  main = paste('STKDE of Q', i, \" 2023\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_st_24&lt;- quart_geo_strat %&gt;% \n  filter(year==\"2024\") %&gt;% \n  select(2,3)\n\nstrat_dev_24_ppp&lt;- as.ppp(strat_dev_st_24, coordinates=strat_dev_st_24)\nstrat_dev_24_owin&lt;- strat_dev_24_ppp[boundary_owin]\n\nstrat_dev_st_24_kde&lt;- spattemp.density(strat_dev_24_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(strat_dev_st_24$num_quarters)\n\nfor (i in tims2){\n  plot(strat_dev_st_24_kde, i,\n  main = paste('STKDE of Q', i, \" 2024\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021202220232024\n\n\n\nciv_st_21&lt;- quart_geo_civ %&gt;% \n  filter(year==\"2021\") %&gt;% \n  select(2,3)\n\nciv_21_ppp&lt;- as.ppp(civ_st_21, coordinates=civ_st_21)\nciv_21_owin&lt;- civ_21_ppp[boundary_owin]\n\nciv_st_21_kde&lt;- spattemp.density(civ_21_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(civ_st_21$num_quarters)\n\n\nfor (i in tims2){\n  plot(civ_st_21_kde, i,\n  main = paste('STKDE of Q', i, \" 2021\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nciv_st_22&lt;- quart_geo_civ %&gt;% \n  filter(year==\"2022\") %&gt;% \n  select(2,3)\nciv_22_ppp&lt;- as.ppp(civ_st_22, coordinates=civ_st_22)\nciv_22_owin&lt;- civ_22_ppp[boundary_owin]\n\nciv_st_22_kde&lt;- spattemp.density(civ_22_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(civ_st_22$num_quarters)\n\n\nfor (i in tims2){\n  plot(civ_st_22_kde, i,\n  main = paste('STKDE of Q', i, \" 2022\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nciv_st_23&lt;- quart_geo_civ %&gt;% \n  filter(year==\"2023\") %&gt;% \n  select(2,3)\n\nciv_23_ppp&lt;- as.ppp(civ_st_23, coordinates=civ_st_23)\nciv_23_owin&lt;- civ_23_ppp[boundary_owin]\n\nciv_st_23_kde&lt;- spattemp.density(civ_23_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(civ_st_23$num_quarters)\n\n\nfor (i in tims2){\n  plot(civ_st_23_kde, i,\n  main = paste('STKDE of Q', i, \" 2023\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nciv_st_24&lt;- quart_geo_civ %&gt;% \n  filter(year==\"2024\") %&gt;% \n  select(2,3)\n\nciv_24_ppp&lt;- as.ppp(civ_st_24, coordinates=civ_st_24)\nciv_24_owin&lt;- civ_24_ppp[boundary_owin]\n\nciv_st_24_kde&lt;- spattemp.density(civ_24_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(civ_st_24$num_quarters)\n\n\nfor (i in tims2){\n  plot(civ_st_24_kde, i,\n  main = paste('STKDE of Q', i, \" 2024\", sep=\"\"))\n}"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#second-order-spatio-temporal-kde",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#second-order-spatio-temporal-kde",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.6 Second-Order Spatio-Temporal KDE",
    "text": "1.6 Second-Order Spatio-Temporal KDE\nIn this section, I will be computing the Second Order Spatio Temporal KDE Layers.\n\nBattlesExplosionsStrategic DevelopmentsViolence Against Civilians\n\n\n\nbattles_sost&lt;- quart_geo_bat %&gt;% \n  select(2,3)\nbattles_sost_ppp&lt;- as.ppp(battles_sost, coordinates= battles_sost)\nbattles_sost_owin&lt;- battles_sost_ppp[boundary_owin]\nbattles_sost.csr &lt;- envelope(battles_sost_owin, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, \n[14:26 remaining, estimate finish 2024-09-22 20:05:10]\n3, \n[18:01 remaining, estimate finish 2024-09-22 20:08:58]\n4, \n[21:35 remaining, estimate finish 2024-09-22 20:12:51]\n5, \n[19:57 remaining, estimate finish 2024-09-22 20:11:23]\n6, \n[18:49 remaining, estimate finish 2024-09-22 20:10:25]\n7, \n[18:08 remaining, estimate finish 2024-09-22 20:09:54]\n8, \n[17:37 remaining, estimate finish 2024-09-22 20:09:33]\n9, \n[17:06 remaining, estimate finish 2024-09-22 20:09:12]\n10, \n[16:39 remaining, estimate finish 2024-09-22 20:08:55]\n11, \n[16:21 remaining, estimate finish 2024-09-22 20:08:47]\n12, \n[15:58 remaining, estimate finish 2024-09-22 20:08:34]\n13, \n[15:43 remaining, estimate finish 2024-09-22 20:08:29]\n14, \n[15:27 remaining, estimate finish 2024-09-22 20:08:24]\n15, \n[15:12 remaining, estimate finish 2024-09-22 20:08:19]\n16, \n[16:06 remaining, estimate finish 2024-09-22 20:09:35]\n17, \n[17:13 remaining, estimate finish 2024-09-22 20:11:09]\n18, \n[17:59 remaining, estimate finish 2024-09-22 20:12:20]\n19, \n[18:48 remaining, estimate finish 2024-09-22 20:13:37]\n20, \n[19:21 remaining, estimate finish 2024-09-22 20:14:35]\n21, \n[19:51 remaining, estimate finish 2024-09-22 20:15:31]\n22, \n[20:05 remaining, estimate finish 2024-09-22 20:16:09]\n23, \n[20:23 remaining, estimate finish 2024-09-22 20:16:51]\n24, \n[20:37 remaining, estimate finish 2024-09-22 20:17:31]\n25, \n[20:45 remaining, estimate finish 2024-09-22 20:18:03]\n26, \n[20:55 remaining, estimate finish 2024-09-22 20:18:39]\n27, \n[20:58 remaining, estimate finish 2024-09-22 20:19:08]\n28, \n[20:49 remaining, estimate finish 2024-09-22 20:19:19]\n29, \n[20:09 remaining, estimate finish 2024-09-22 20:18:48]\n30, \n[19:43 remaining, estimate finish 2024-09-22 20:18:35]\n31, \n[19:43 remaining, estimate finish 2024-09-22 20:19:00]\n32, \n[19:40 remaining, estimate finish 2024-09-22 20:19:20]\n33, \n[19:33 remaining, estimate finish 2024-09-22 20:19:37]\n34, \n[19:28 remaining, estimate finish 2024-09-22 20:19:56]\n35, \n[19:23 remaining, estimate finish 2024-09-22 20:20:16]\n36, \n[19:12 remaining, estimate finish 2024-09-22 20:20:27]\n37, \n[18:58 remaining, estimate finish 2024-09-22 20:20:34]\n38, \n[18:24 remaining, estimate finish 2024-09-22 20:20:08]\n39, \n[17:58 remaining, estimate finish 2024-09-22 20:19:56]\n40, \n[17:50 remaining, estimate finish 2024-09-22 20:20:12]\n41, \n[17:31 remaining, estimate finish 2024-09-22 20:20:10]\n42, \n[16:59 remaining, estimate finish 2024-09-22 20:19:47]\n43, \n[16:29 remaining, estimate finish 2024-09-22 20:19:26]\n44, \n[16:01 remaining, estimate finish 2024-09-22 20:19:07]\n45, \n[15:33 remaining, estimate finish 2024-09-22 20:18:47]\n46, \n[15:05 remaining, estimate finish 2024-09-22 20:18:29]\n47, \n[14:39 remaining, estimate finish 2024-09-22 20:18:12]\n48, \n[14:14 remaining, estimate finish 2024-09-22 20:17:55]\n49, \n[13:48 remaining, estimate finish 2024-09-22 20:17:37]\n50, \n[13:23 remaining, estimate finish 2024-09-22 20:17:22]\n51, \n[12:59 remaining, estimate finish 2024-09-22 20:17:06]\n52, \n[12:36 remaining, estimate finish 2024-09-22 20:16:51]\n53, \n[12:13 remaining, estimate finish 2024-09-22 20:16:36]\n54, \n[11:50 remaining, estimate finish 2024-09-22 20:16:22]\n55, \n[11:28 remaining, estimate finish 2024-09-22 20:16:08]\n56, \n[11:07 remaining, estimate finish 2024-09-22 20:15:56]\n57, \n[10:47 remaining, estimate finish 2024-09-22 20:15:45]\n58, \n[10:28 remaining, estimate finish 2024-09-22 20:15:36]\n59, \n[10:09 remaining, estimate finish 2024-09-22 20:15:26]\n60,  [9:50 remaining] 61,  [9:31 remaining] 62,  [9:12 remaining] 63,  [8:54 remaining] 64,  [8:36 remaining] 65,  [8:19 remaining] 66,  [8:01 remaining] 67,  [7:44 remaining] 68,  [7:26 remaining] 69,  [7:09 remaining] 70,  [6:53 remaining] 71,  [6:36 remaining] 72,  [6:20 remaining] 73,  [6:04 remaining] 74,  [5:48 remaining] 75,  [5:32 remaining] 76,  [5:17 remaining] 77,  [5:01 remaining] 78,  [4:46 remaining] 79,\n [4:31 remaining] 80,  [4:16 remaining] 81,  [4:02 remaining] 82,  [3:48 remaining] 83,  [3:33 remaining] 84,  [3:19 remaining] 85,  [3:05 remaining] 86,  [2:51 remaining] 87,  [2:38 remaining] 88,  [2:24 remaining] 89,  [2:11 remaining] 90,  [1:57 remaining] 91,  [1:44 remaining] 92,  [1:30 remaining] 93,  [1:17 remaining] 94,  [1:04 remaining] 95,  [51 sec remaining] 96,  [38 sec remaining] 97,  [25 sec remaining] 98,  [13 sec remaining] \n99.\n\nDone.\n\nplot(battles_sost.csr)\n\n\n\n\n\n\n\n\n\n\n\nexp_sost&lt;- quart_geo_exp %&gt;% \n  select(2,3)\nexp_sost_ppp&lt;- as.ppp(exp_sost, coordinates= exp_sost)\nexp_sost_owin&lt;- exp_sost_ppp[boundary_owin]\nexp_sost.csr &lt;- envelope(exp_sost_owin, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, \n[13:57 remaining, estimate finish 2024-09-22 20:25:37]\n3, \n[14:02 remaining, estimate finish 2024-09-22 20:25:52]\n4, \n[14:14 remaining, estimate finish 2024-09-22 20:26:12]\n5, \n[14:03 remaining, estimate finish 2024-09-22 20:26:11]\n6, \n[13:48 remaining, estimate finish 2024-09-22 20:26:05]\n7, \n[13:44 remaining, estimate finish 2024-09-22 20:26:09]\n8, \n[13:39 remaining, estimate finish 2024-09-22 20:26:14]\n9, \n[13:39 remaining, estimate finish 2024-09-22 20:26:24]\n10, \n[13:37 remaining, estimate finish 2024-09-22 20:26:31]\n11, \n[13:41 remaining, estimate finish 2024-09-22 20:26:46]\n12, \n[13:43 remaining, estimate finish 2024-09-22 20:26:59]\n13, \n[13:33 remaining, estimate finish 2024-09-22 20:26:59]\n14, \n[13:27 remaining, estimate finish 2024-09-22 20:27:02]\n15, \n[13:16 remaining, estimate finish 2024-09-22 20:27:00]\n16, \n[13:07 remaining, estimate finish 2024-09-22 20:27:01]\n17, \n[12:58 remaining, estimate finish 2024-09-22 20:27:02]\n18, \n[12:48 remaining, estimate finish 2024-09-22 20:27:01]\n19, \n[12:35 remaining, estimate finish 2024-09-22 20:26:57]\n20, \n[12:25 remaining, estimate finish 2024-09-22 20:26:56]\n21, \n[12:14 remaining, estimate finish 2024-09-22 20:26:54]\n22, \n[12:06 remaining, estimate finish 2024-09-22 20:26:56]\n23, \n[11:55 remaining, estimate finish 2024-09-22 20:26:54]\n24, \n[11:46 remaining, estimate finish 2024-09-22 20:26:54]\n25, \n[11:36 remaining, estimate finish 2024-09-22 20:26:53]\n26, \n[11:27 remaining, estimate finish 2024-09-22 20:26:55]\n27, \n[11:21 remaining, estimate finish 2024-09-22 20:26:58]\n28, \n[11:13 remaining, estimate finish 2024-09-22 20:27:01]\n29, \n[11:06 remaining, estimate finish 2024-09-22 20:27:04]\n30, \n[10:58 remaining, estimate finish 2024-09-22 20:27:06]\n31, \n[10:50 remaining, estimate finish 2024-09-22 20:27:09]\n32, \n[10:40 remaining, estimate finish 2024-09-22 20:27:08]\n33, \n[10:30 remaining, estimate finish 2024-09-22 20:27:07]\n34, \n[10:21 remaining, estimate finish 2024-09-22 20:27:07]\n35, \n[10:11 remaining, estimate finish 2024-09-22 20:27:07]\n36, \n[10:30 remaining, estimate finish 2024-09-22 20:27:52]\n37, \n[10:46 remaining, estimate finish 2024-09-22 20:28:33]\n38, \n[10:37 remaining, estimate finish 2024-09-22 20:28:35]\n39, \n[10:34 remaining, estimate finish 2024-09-22 20:28:48]\n40, \n[10:21 remaining, estimate finish 2024-09-22 20:28:44]\n41, \n[10:08 remaining, estimate finish 2024-09-22 20:28:39]\n42,  [9:55 remaining] 43,  [9:55 remaining] 44, \n[10:01 remaining, estimate finish 2024-09-22 20:29:23]\n45, \n[10:04 remaining, estimate finish 2024-09-22 20:29:48]\n46,  [9:54 remaining] 47,  [9:58 remaining] 48,  [10:00 remaining] 49, \n[10:02 remaining, estimate finish 2024-09-22 20:31:11]\n50,  [9:49 remaining] 51,  [9:33 remaining] 52,  [9:21 remaining] 53,  [9:21 remaining] 54,  [9:18 remaining] 55,  [9:15 remaining] 56,  [9:10 remaining] 57,  [9:04 remaining] 58,  [8:58 remaining] 59,  [8:51 remaining] 60,  [8:44 remaining] 61,  [8:37 remaining] 62,  [8:29 remaining] 63,  [8:20 remaining] 64,  [8:11 remaining] 65,  [8:02 remaining] 66,  [7:52 remaining] 67,  [7:41 remaining] 68,  [7:29 remaining] 69,\n [7:12 remaining] 70,  [6:59 remaining] 71,  [6:49 remaining] 72,  [6:38 remaining] 73,  [6:22 remaining] 74,  [6:05 remaining] 75,  [5:48 remaining] 76,  [5:32 remaining] 77,  [5:16 remaining] 78,  [5:00 remaining] 79,  [4:44 remaining] 80,  [4:28 remaining] 81,  [4:13 remaining] 82,  [3:58 remaining] 83,  [3:43 remaining] 84,  [3:28 remaining] 85,  [3:13 remaining] 86,  [2:58 remaining] 87,  [2:44 remaining] 88,  [2:29 remaining] 89,\n [2:15 remaining] 90,  [2:01 remaining] 91,  [1:47 remaining] 92,  [1:34 remaining] 93,  [1:20 remaining] 94,  [1:06 remaining] 95,  [53 sec remaining] 96,  [39 sec remaining] 97,  [26 sec remaining] 98,  [13 sec remaining] \n99.\n\nDone.\n\nplot(exp_sost.csr)\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_sost&lt;- quart_geo_strat %&gt;% \n  select(2,3)\nstrat_dev_sost_ppp&lt;- as.ppp(strat_dev_sost, coordinates= strat_dev_sost)\nstrat_dev_sost_owin&lt;- strat_dev_sost_ppp[boundary_owin]\nstrat_dev_sost.csr &lt;- envelope(strat_dev_sost_owin, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, \n[14:24 remaining, estimate finish 2024-09-22 20:47:41]\n3, \n[13:53 remaining, estimate finish 2024-09-22 20:47:18]\n4, \n[13:46 remaining, estimate finish 2024-09-22 20:47:20]\n5, \n[13:33 remaining, estimate finish 2024-09-22 20:47:15]\n6, \n[13:26 remaining, estimate finish 2024-09-22 20:47:17]\n7, \n[13:13 remaining, estimate finish 2024-09-22 20:47:12]\n8, \n[13:04 remaining, estimate finish 2024-09-22 20:47:12]\n9, \n[12:53 remaining, estimate finish 2024-09-22 20:47:10]\n10, \n[12:45 remaining, estimate finish 2024-09-22 20:47:10]\n11, \n[12:36 remaining, estimate finish 2024-09-22 20:47:10]\n12, \n[12:30 remaining, estimate finish 2024-09-22 20:47:13]\n13, \n[13:42 remaining, estimate finish 2024-09-22 20:48:45]\n14, \n[15:12 remaining, estimate finish 2024-09-22 20:50:39]\n15, \n[16:15 remaining, estimate finish 2024-09-22 20:52:05]\n16, \n[17:06 remaining, estimate finish 2024-09-22 20:53:19]\n17, \n[17:48 remaining, estimate finish 2024-09-22 20:54:24]\n18, \n[18:20 remaining, estimate finish 2024-09-22 20:55:18]\n19, \n[18:50 remaining, estimate finish 2024-09-22 20:56:12]\n20, \n[19:22 remaining, estimate finish 2024-09-22 20:57:09]\n21, \n[19:50 remaining, estimate finish 2024-09-22 20:58:02]\n22, \n[20:09 remaining, estimate finish 2024-09-22 20:58:46]\n23, \n[19:40 remaining, estimate finish 2024-09-22 20:58:29]\n24, \n[19:52 remaining, estimate finish 2024-09-22 20:59:05]\n25, \n[20:00 remaining, estimate finish 2024-09-22 20:59:37]\n26, \n[20:07 remaining, estimate finish 2024-09-22 21:00:08]\n27, \n[20:09 remaining, estimate finish 2024-09-22 21:00:33]\n28, \n[20:01 remaining, estimate finish 2024-09-22 21:00:46]\n29, \n[19:36 remaining, estimate finish 2024-09-22 21:00:34]\n30, \n[19:34 remaining, estimate finish 2024-09-22 21:00:54]\n31, \n[19:28 remaining, estimate finish 2024-09-22 21:01:10]\n32, \n[19:27 remaining, estimate finish 2024-09-22 21:01:35]\n33, \n[19:17 remaining, estimate finish 2024-09-22 21:01:46]\n34, \n[18:42 remaining, estimate finish 2024-09-22 21:01:20]\n35, \n[18:09 remaining, estimate finish 2024-09-22 21:00:56]\n36, \n[17:38 remaining, estimate finish 2024-09-22 21:00:33]\n37, \n[17:07 remaining, estimate finish 2024-09-22 21:00:11]\n38, \n[16:37 remaining, estimate finish 2024-09-22 20:59:50]\n39, \n[16:08 remaining, estimate finish 2024-09-22 20:59:30]\n40, \n[15:41 remaining, estimate finish 2024-09-22 20:59:11]\n41, \n[15:15 remaining, estimate finish 2024-09-22 20:58:53]\n42, \n[14:50 remaining, estimate finish 2024-09-22 20:58:37]\n43, \n[14:37 remaining, estimate finish 2024-09-22 20:58:43]\n44, \n[14:31 remaining, estimate finish 2024-09-22 20:59:00]\n45, \n[14:26 remaining, estimate finish 2024-09-22 20:59:19]\n46, \n[14:14 remaining, estimate finish 2024-09-22 20:59:27]\n47, \n[13:49 remaining, estimate finish 2024-09-22 20:59:10]\n48, \n[13:25 remaining, estimate finish 2024-09-22 20:58:55]\n49, \n[13:03 remaining, estimate finish 2024-09-22 20:58:42]\n50, \n[12:55 remaining, estimate finish 2024-09-22 20:58:57]\n51, \n[12:45 remaining, estimate finish 2024-09-22 20:59:09]\n52, \n[12:35 remaining, estimate finish 2024-09-22 20:59:21]\n53, \n[12:25 remaining, estimate finish 2024-09-22 20:59:36]\n54, \n[12:16 remaining, estimate finish 2024-09-22 20:59:50]\n55, \n[12:05 remaining, estimate finish 2024-09-22 21:00:01]\n56, \n[11:53 remaining, estimate finish 2024-09-22 21:00:13]\n57, \n[11:41 remaining, estimate finish 2024-09-22 21:00:23]\n58, \n[11:28 remaining, estimate finish 2024-09-22 21:00:32]\n59, \n[11:15 remaining, estimate finish 2024-09-22 21:00:41]\n60, \n[11:03 remaining, estimate finish 2024-09-22 21:00:53]\n61, \n[10:49 remaining, estimate finish 2024-09-22 21:01:01]\n62, \n[10:35 remaining, estimate finish 2024-09-22 21:01:10]\n63, \n[10:16 remaining, estimate finish 2024-09-22 21:01:05]\n64,  [9:55 remaining] 65,  [9:34 remaining] 66,  [9:13 remaining] 67,  [8:52 remaining] 68,  [8:32 remaining] 69,  [8:12 remaining] 70,  [7:52 remaining] 71,  [7:33 remaining] 72,  [7:14 remaining] 73,  [6:55 remaining] 74,  [6:36 remaining] 75,  [6:18 remaining] 76,  [6:00 remaining] 77,  [5:42 remaining] 78,  [5:25 remaining] 79,  [5:08 remaining] 80,  [4:51 remaining] 81,  [4:34 remaining] 82,  [4:17 remaining] 83,\n [4:01 remaining] 84,  [3:45 remaining] 85,  [3:29 remaining] 86,  [3:13 remaining] 87,  [2:57 remaining] 88,  [2:42 remaining] 89,  [2:26 remaining] 90,  [2:11 remaining] 91,  [1:56 remaining] 92,  [1:41 remaining] 93,  [1:26 remaining] 94,  [1:11 remaining] 95,  [57 sec remaining] 96,  [43 sec remaining] 97,  [28 sec remaining] 98,  [14 sec remaining] \n99.\n\nDone.\n\nplot(strat_dev_sost.csr)\n\n\n\n\n\n\n\n\n\n\n\ncivViolence_sost&lt;- quart_geo_civ %&gt;% \n  select(2,3)\ncivViolence_sost_ppp&lt;- as.ppp(civViolence_sost, coordinates= civViolence_sost)\ncivViolence_sost_owin&lt;- civViolence_sost_ppp[boundary_owin]\ncivViolence_sost.csr &lt;- envelope(civViolence_sost_owin, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [7:15 remaining] 3,\n [7:10 remaining] 4,  [7:02 remaining] 5,  [7:01 remaining] 6,\n [6:57 remaining] 7,  [6:53 remaining] 8,  [6:47 remaining] 9,\n [6:44 remaining] 10,  [6:39 remaining] 11,  [6:34 remaining] 12,\n [6:30 remaining] 13,  [6:28 remaining] 14,  [6:24 remaining] 15,\n [6:19 remaining] 16,  [6:15 remaining] 17,  [6:12 remaining] 18,\n [6:07 remaining] 19,  [6:03 remaining] 20,  [5:58 remaining] 21,\n [5:54 remaining] 22,  [5:50 remaining] 23,  [5:45 remaining] 24,\n [5:41 remaining] 25,  [5:37 remaining] 26,  [5:32 remaining] 27,\n [5:27 remaining] 28,  [5:23 remaining] 29,  [5:19 remaining] 30,\n [5:14 remaining] 31,  [5:10 remaining] 32,  [5:05 remaining] 33,\n [5:01 remaining] 34,  [4:56 remaining] 35,  [4:51 remaining] 36,\n [4:47 remaining] 37,  [4:43 remaining] 38,  [4:38 remaining] 39,\n [4:33 remaining] 40,  [4:28 remaining] 41,  [4:24 remaining] 42,\n [4:21 remaining] 43,  [4:19 remaining] 44,  [4:23 remaining] 45,\n [4:18 remaining] 46,  [4:13 remaining] 47,  [4:08 remaining] 48,\n [4:03 remaining] 49,  [3:58 remaining] 50,  [3:53 remaining] 51,\n [3:49 remaining] 52,  [3:44 remaining] 53,  [3:39 remaining] 54,\n [3:35 remaining] 55,  [3:30 remaining] 56,  [3:25 remaining] 57,\n [3:20 remaining] 58,  [3:15 remaining] 59,  [3:10 remaining] 60,\n [3:06 remaining] 61,  [3:01 remaining] 62,  [2:59 remaining] 63,\n [2:59 remaining] 64,  [2:58 remaining] 65,  [2:57 remaining] 66,\n [2:56 remaining] 67,  [2:54 remaining] 68,  [2:51 remaining] 69,\n [2:49 remaining] 70,  [2:43 remaining] 71,  [2:40 remaining] 72,\n [2:37 remaining] 73,  [2:34 remaining] 74,  [2:31 remaining] 75,\n [2:27 remaining] 76,  [2:20 remaining] 77,  [2:14 remaining] 78,\n [2:07 remaining] 79,  [2:01 remaining] 80,  [1:55 remaining] 81,\n [1:48 remaining] 82,  [1:42 remaining] 83,  [1:36 remaining] 84,\n [1:30 remaining] 85,  [1:23 remaining] 86,  [1:17 remaining] 87,\n [1:11 remaining] 88,  [1:05 remaining] 89,  [59 sec remaining] 90,\n [53 sec remaining] 91,  [47 sec remaining] 92,  [41 sec remaining] 93,\n [35 sec remaining] 94,  [29 sec remaining] 95,  [23 sec remaining] 96,\n [17 sec remaining] 97,  [12 sec remaining] 98,  [6 sec remaining] \n99.\n\nDone.\n\nplot(civViolence_sost.csr)\n\n\n\n\n\n\n\n\n\n\n\nThe plots above further proves that the spatial points across the quarters reflect a clustered pattern."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "",
    "text": "In this Hands-on, I will be exploring how to compute Global Measures of Spatial Autocorrelation (GMSA) using the spdep package.\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\nFirst and foremost, I will download the necessary packages, mainly sf, tidyverse, spdep and tmap.\n\npacman:: p_load(sf, spdep, tidyverse, tmap )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "",
    "text": "In this Hands-on, I will be exploring how to compute Global Measures of Spatial Autocorrelation (GMSA) using the spdep package.\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\nFirst and foremost, I will download the necessary packages, mainly sf, tidyverse, spdep and tmap.\n\npacman:: p_load(sf, spdep, tidyverse, tmap )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#study-area-and-data",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.2 Study Area and Data",
    "text": "6.2 Study Area and Data\nFor this exercise, I will use 2 data sets:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n6.2.1 Importing the data\nFirst, I will use the st_read() function of the sf package to import the shapefiles into our R environment.\n\nhunan3 &lt;- st_read(dsn=\"data/geospatial\",\n                  layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\santhyats\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nI will also read the csv file into our environment using the read_csv() function.\n\nhunan2012_3&lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLastly, I will perform a relational join to join the attributes from the hunan2012_3 dataframe to the hunan3 dataframe. This is done by using the left_join() function of the dplyr package.\n\nhunan3 &lt;- left_join(hunan3,hunan2012_3) %&gt;% \n select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n6.2.2 Visualising Regional Development Indicators\nIn this section, we will plot a chloropeth map that will show us the distribution of GDPPC 2012. This will be done using the qtm() function of the tmap package.\n\nequal &lt;- tm_shape(hunan3) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan3) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.3 Global Measures of Spatial Autocorrelation",
    "text": "6.3 Global Measures of Spatial Autocorrelation\n\n6.3.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation, we would first need to derive the spatial weights of the study area. Spatial weights are the neighbourhood relationships between the spatial units.\nWe will derive the contiguity neighbours list using the poly2nb() function of the spdep package. By default, this function returns a matrice of neighbours of the spatial untis, derived by the Queen’s method.\n\nwm_q3 &lt;- poly2nb(hunan3, \n                queen=TRUE)\nsummary(wm_q3)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nFrom the summary above, we see that there are a total of 88 spatial regions in hunan and the most connected region has 11 links. There are also 2 least connected regions with only one neighbour each.\n\n\n6.3.2 Row-standardized Weights Matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q3 &lt;- nb2listw(wm_q3, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q3\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation--morans-test",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation--morans-test",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.4 Global Measures of Spatial Autocorrelation- Moran’s Test",
    "text": "6.4 Global Measures of Spatial Autocorrelation- Moran’s Test\n\n6.4.1 Moran’s I Test\nIn this section, we will be performing the Maron’s I statistics test using the moran.test() function of the spdep package.\n\nmoran.test(hunan3$GDPPC, \n           listw=rswm_q3, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan3$GDPPC  \nweights: rswm_q3    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nFrom the statistics derived above, we see that the p-value is extremely small and that the alternate hypothesis is greater, enabling us to reject the null hypothesis (which states that there is no correlation between the weighted spatial units) and conclude that there is significant spatial autocorrelation between the weighted spatial units. This is further corroborated by the positive value of the Moran I Statistic.\nIn context, this means that counties with similar GDPPC Values are more close to one another spatially as compared to counties that have varying levels.\n\n\n6.4.2 Computing Monte Carlo Moran’s I Statistic\nWe will now perform the Monte Carlo Simulation for the Moran’s I Statistic using the moran.mc() function, also from the spdep package.\n\nset.seed(1234)\nbperm= moran.mc(hunan3$GDPPC, \n                listw=rswm_q3, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan3$GDPPC \nweights: rswm_q3  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nFrom the statistics above, we once again see that the p-value is lower than 0.05, and we can reject the null hypothesis and accept the claim that the weighted spatial units are positively autocorrelated.\n\n\n6.4.3 Visualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\",)\nabline(v=0, \n       col=\"purple\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation--gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation--gearys-c",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.5 Global Measures of Spatial Autocorrelation- Geary’s C",
    "text": "6.5 Global Measures of Spatial Autocorrelation- Geary’s C\n\n6.5.1 Geary’s C Test\nIn this section, I will be performing the Geary’s C test using the geary.test() function, also from the spdep package.\n\ngeary.test(hunan3$GDPPC, listw=rswm_q3)\n\n\n    Geary C test under randomisation\n\ndata:  hunan3$GDPPC \nweights: rswm_q3   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nFrom the statistics above, I see that the Geary C statistic has a postivie value and the p-value is very small. This indicates that the null hypothesis (which states that the weighted spatial units are randomly distributed) is rejected and the weighted spatial units are concluded to be spatially correlated.\n\n\n6.5.2 Computing Monte Carlo Geary’s C\nWe will perform the permutations of the Monte Carlo simulation using the geary.mc() function of the spdep package.\n\nset.seed(1234)\nbperm=geary.mc(hunan3$GDPPC, \n               listw=rswm_q3, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan3$GDPPC \nweights: rswm_q3  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n6.5.3 Visualising the Monte Carlo Geary’s C\nWe will once again plot a histogram to reveal the distribution of the values in the Monte Carlo simulation.\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.6 Spatial Correlogram",
    "text": "6.6 Spatial Correlogram\nSpatial Correlograms are plots that show how correlated pairs of spatial observations are when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance. In this section, we will be plotting the coreelograms for the two tests that we have explored so far.\n\n6.6.1 Compute Moran I’s Correlogram\nTo achieve this, we will be using the sp.correlogram() function of the spdep package.\n\nMI_corr &lt;- sp.correlogram(wm_q3, \n                          hunan3$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nFrom the plot above, we see that as the distance increases, the distribution of the values of the Moran I’s test becomes more negative, indicating that with larger distances, the spatial autocorrelation of the weighted spatial units decrease.\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan3$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n6.6.2 Computing Geary C’s Correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q3, \n                          hunan3$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nSimilarly, we will derive the analysis report\n\nprint(GC_corr)\n\nSpatial correlogram for hunan3$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-measures-of-spatial-autocorrelation",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.7 Local Measures of Spatial Autocorrelation",
    "text": "6.7 Local Measures of Spatial Autocorrelation\n\n6.7.1 Computing Local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan3$County)\nlocalMI &lt;- localmoran(hunan3$GDPPC, rswm_q3)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nWe can make use of the printCoefmat() to list the contents of the local Moran matrix.\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan3$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\n6.7.2 Mapping the Local Moran’s I map\nBefore we map the Local Moran I map, we will first append the Moran I dataframe to the hunan dataframe.\n\nhunan.localMI &lt;- cbind(hunan3,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nWe will now plot the chloropeth map of local Moran I’s values\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n6.7.3 Mapping Local Moran I’s p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values. The code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Purples\", \n          title = \"Local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n6.7.4 Mapping both Moran’s I- and p- values\nFor more effective interpretation, we can plot both maps side-by-side.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.8 Creating a LISA Cluster Map",
    "text": "6.8 Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\n6.8.1 Plotting the Moran Scatter Plot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nWe will use the moran.plot() function of the spdep package to plot the scatterplot.\n\nnci &lt;- moran.plot(hunan3$GDPPC, rswm_q3,\n                  labels=as.character(hunan3$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\nThe top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. \n\n\n6.8.2 Plotting Moran Scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations. as.vector() function at the end ensures that the output will be in a vector format.\n\nhunan3$Z.GDPPC &lt;- scale(hunan3$GDPPC) %&gt;% \n  as.vector \n\nWe will now once again plot the scatterplot.\n\nnci2 &lt;- moran.plot(hunan3$Z.GDPPC, rswm_q3,\n                   labels=as.character(hunan3$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n6.8.3 Preparing LISA map classes\nBelow are the steps to prepare a LISA cluster map\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, we derive the spatially lagged variable of interest (i.e. GDPPC) and center it around its mean.\n\nhunan3$lag_GDPPC &lt;- lag.listw(rswm_q3, hunan3$GDPPC)\nDV &lt;- hunan3$lag_GDPPC - mean(hunan3$lag_GDPPC)     \n\nThis is followed by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05       \n\nThese four command lines below define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 1\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 2\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nLastly, place non-significant Moran in the category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-a-lisa-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-a-lisa-map",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.9 Plotting a LISA map",
    "text": "6.9 Plotting a LISA map\nNow, we can plot a LISA map using the code chunk below.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nWe can also plot the local Moran’s value and it’s corresponding p-values beside each other.\n\ngdppc &lt;- qtm(hunan3, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "7.0 Hot Spot and Cold Spot Area Analysis",
    "text": "7.0 Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\n\n7.0.1 Getis and Ord’s G statistic\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\n7.0.2 Deriving Distance-based Weights Matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n7.0.2.1 Deriving the centroid\nFirst, we will derive the centroid of each of the polygons found in the hunan3 dataframe so that we can construct a connectivity graph.\n\nlongitude &lt;- map_dbl(hunan3$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan3$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n7.0.2.2 Determining the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\n7.0.2.3 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the output to a spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\n7.0.3 Computing Adaptive Distance Weights Matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nWe once again convert the output to a spatial weights object\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "7.1 Computing Gi statistics",
    "text": "7.1 Computing Gi statistics\n\n7.1.1 Gi Statistics using fixed distance\n\nfips &lt;- order(hunan3$County)\ngi.fixed &lt;- localG(hunan3$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan3$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan3, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nIn fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\n7.1.2 Mapping Gi values with fixed distance weights\n\ngdppc &lt;- qtm(hunan3, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n7.1.3 Gi Statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips &lt;- order(hunan3$County)\ngi.adaptive &lt;- localG(hunan3$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan3, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n7.1.4 Mapping Gi statistics with adaptive distance weights\nIt is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc&lt;- qtm(hunan3, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#overall-learnings",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#overall-learnings",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.7 Overall Learnings",
    "text": "1.7 Overall Learnings\nThis exercise has allowed me to revisit and revise the various different concepts and functions that we had learnt in class and in the past Hands-on Exercises. Being completely on my own, it has forced me to move out of my comfort zone and learn concepts in my own way. To summarise, I would say my main takeaways are:\n\nAcquiring real-world data and being able to observe it in order to identify what needs to be handled and processed for our analytical needs (formatting of date columns, dropping of columns etc.)\nImporting datasets of different types (shapefiles, csv files) into r for analysis\nHandling real-world data and being able to convert it to desirable formats\nIdentifying the suitable formats that the input data needs to be in, in order to perform the different analysis methods (ppp and owin objects etc.)\nFiguring out the most suitable methods to derive KDE layers on a real-word dataset according to the characteristics of the dataset\nBeing able to understand and somewhat explain the first order and second-order analysis plots\n\nAnd some further non-technical learnings:\n\nNeat and efficient ways to present the data and the plots."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#references",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#references",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.8 References",
    "text": "1.8 References\n\nMaizland, L. (2022, January 31). Myanmar’s troubled history: coups, military rule, and ethnic conflict. Council on Foreign Relations. https://www.cfr.org/backgrounder/myanmar-history-coup-military-rule-ethnic-conflict-rohingya"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415: Geospatial Analytics and Applications",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics Homepage! In this website, you will find all the coursework prepared by me in this course :) :&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "In this exercise, we will be exploring a new package, sfdep.\n\npacman::p_load(sf, tidyverse, tmap, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#loading-in-the-necessary-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#loading-in-the-necessary-packages",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "In this exercise, we will be exploring a new package, sfdep.\n\npacman::p_load(sf, tidyverse, tmap, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-the-data",
    "title": "In-class Exercise 6",
    "section": "2.1 importing the data",
    "text": "2.1 importing the data\n\n2.1.1 Importing the Hunan shapefiles\n\nhunan4&lt;-st_read(dsn=\"data/geospatial\", \n                layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\santhyats\\IS415-GAA\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n2.1.2 importing the csv file\n\nhunan4_2012&lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n2.1.3 Performing a left join of the sf dataframes\n\nhunan4_GDPPC&lt;- left_join(hunan4, hunan4_2012) %&gt;% \n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#global-measures-of-spatial-association",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#global-measures-of-spatial-association",
    "title": "In-class Exercise 6",
    "section": "2.2 Global measures of spatial association",
    "text": "2.2 Global measures of spatial association\n\n2.2.1 Deriving queen contiguity weights sfdep methods\n\nwm_q4&lt;- hunan4_GDPPC %&gt;% \n  mutate(nb=st_contiguity(geometry),\n         wt= st_weights(nb, \n                        style='W'),\n         .before=1)\n\nThe st_contiguity() function of the sfdep package helps to add the neighbours to a dataframe instead of printing out the matrix. The .before attribute adds the new columns to the front of the sf table instead of the default back of the sf.\n\n\n2.2.2 Computing Global Moran’s I\n\nmoranI&lt;- global_moran(wm_q4$GDPPC,\n                      wm_q4$nb,\n                      wm_q4$wt)\n\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\n2.2.3 Performing the Global Moran’s I Test\n\nglobal_moran_test(wm_q4$GDPPC,\n                  wm_q4$nb,\n                  wm_q4$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nThe p-value is incredibly small, indictaing that we reject the null hypothesis and conclude that the relationship between the neighbours differ significantly from the values as observed under a randomly spatially distributed neighbours. Next, looking at the Moran I statistic value of 0.3007, we can see that there is clustering present among the spatial units.\n\n\n2.2.4 Performing Global Moran I’s permutation Test\n\nset.seed(1234)\nglobal_moran_perm(wm_q4$GDPPC,\n                  wm_q4$nb,\n                  wm_q4$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nSetting the seed allows us to ensure that our computations are reproducible. This allows us to get the same value every time we run the code chunk or render the document.\nFrom the results, we see that the p-value is once again really small, confirming that we will reject the null hypothesis…."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-local-morans-i",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-local-morans-i",
    "title": "In-class Exercise 6",
    "section": "2.3 Computing Local Moran’s I",
    "text": "2.3 Computing Local Moran’s I\n\nlisa&lt;- wm_q4 %&gt;% \n  mutate(local_moran = local_moran(GDPPC, nb, wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran)\n\nunnest() expands a column-list of dataframes to rows and columns.\n2.3.1 Visualising Local Moran’s I\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) + \n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I\",\n            main.title.size= 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n2.3.2 Visualising LISA map\nLISA Map helps us to visualise outliers and clusters. High-Low and Low-High categories are considered as outliers whereas High-High and Low-Low categories are considered the clusters. The LISA map is an in interpreted map by combining the local Moran I’s statistic of geographical areas and their respective p-values.\n\nlisa_sig&lt;- lisa %&gt;% \n  filter(p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-local-g-statistics",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-local-g-statistics",
    "title": "In-class Exercise 6",
    "section": "2.4 Computing Local G-statistics",
    "text": "2.4 Computing Local G-statistics\nG-statistics allow us to observe for hot and cold spots\n\nwm_idw&lt;- hunan4_GDPPC %&gt;% \n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry, scale=1, alpha=1),\n         .before=1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\nHCSA&lt;- wm_idw %&gt;% \n  mutate(local_GI = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99), \n    .before = 1) %&gt;% \n  unnest(local_GI)\n\n\n2.4.1 Visualising the Gi* statistics\n\nHCSA_sig &lt;- HCSA %&gt;% \n  filter(p_sim &lt;0.05)\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(HCSA)+\n  tm_polygons() +\n  tm_borders(alpha=0.5) +\n  tm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "",
    "text": "…."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#overview",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#overview",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "",
    "text": "…."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#getting-started",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#getting-started",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.1 Getting Started",
    "text": "2.1 Getting Started\n\n2.1.1 Loading the necessary packages\nFirst and foremost, I will load the packages that we will be using in this exercise using the p_load() function of pacman. The packages we will use in this exercise are the following:\nsf: Used in spatial data wrangling\ntidyverse: Used in data wrangling for non-spatial data\ntmap: For functions relating to mapping point patterns\nsfdep: Functions that support Exploratory Data Analysis and is compatible with the sf and tidyverse packages\n\npacman::p_load(sf, tidyverse, tmap, sfdep)\n\n\n\n2.1.2 Loading in the Datasets\nThese are the datafiles I will be using for this exercise:\n\nThai_Drug_Offences_2017-2022.csv is a csv file containing the data about the locations of drug offences in Thailand.\nThai_Admin1_2022 is a shapefile that contains the provincial boundaries of Thailand.\n\nI will first load in the csv file using the read_csv() function, and save it into the Thai_doff dataframe. After looking at the downloaded data, I will be able to select only the columns that are needed for this exercise.\nI will further group rows according to the province and total up the number of cases for each province. This is done with the help of the group_by() function to group the rows according to the province, and then using the summarise() and sum() functions to sum up the number of cases in each province and save it in a new column called ‘total_count’.\n\nThai_doff &lt;- read_csv(\"data/aspatial/Thai_Drug_Offences_2017-2022.csv\") %&gt;%\n  select(1, 2, 3, 5)\n\nRows: 7392 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): types_of_drug_offenses, province_th, province_en\ndbl (2): fiscal_year, no_cases\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nThai_doff &lt;- Thai_doff %&gt;% \n  group_by(fiscal_year, province_en) %&gt;% \n  summarise('total_count'= sum(`no_cases`))\n\n`summarise()` has grouped output by 'fiscal_year'. You can override using the\n`.groups` argument.\n\n\nNext, I will load in the shapefile and save it to Thai_bounds using the st_read() function. After observing the dataframe, I will also drop the columns that are not needed for our analysis.\n\nThai_bounds &lt;- st_read(dsn = \"data/geospatial\",\n                       layer = \"Thai_Admin1_2022\") %&gt;%\n  select(1:3, 17)\n\nReading layer `Thai_Admin1_2022' from data source \n  `C:\\santhyats\\IS415-GAA\\Take-Home_Exercises\\Take-Home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nFinally, I will perform a left join of the Thai_bounds dataframe to the Thai_doff dataframe using the province names. This will be done using the left_join() function.\n\nThai_doff&lt;- left_join(Thai_doff, Thai_bounds, by= c(\"province_en\" = \"ADM1_EN\")) %&gt;% \n  drop_na()\n\n\n\n2.1.3 Visualising the Data Over the Years\nI will now plot the layers on a chloropleth map to observe the distribution of the drug offences in Thailand. The following functions are used to achieve this:\n\ntm_shape() to plot the provincial boundaries,\ntm_fill() to map out the the variable of interest- the number of drug abuse cases\ntm_borders(), tm_layout() to format the look of the maps.\n\n\ntm_shape(Thai_doff) +\n  tm_fill(\"no_cases\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\") + \n  tm_facets(by = \"fiscal_year\")\n\nHaving encountered this error, I checked the type of object and found that it is a list! &lt;insert why it might be so&gt;.\n\ntypeof(Thai_doff)\n\n[1] \"list\"\n\n\nAs such, I will convert the object to a sf dataframe before continuing. To do this, I will use the data.frame() function.\n\nThai_doff &lt;- Thai_doff %&gt;% st_as_sf()\n\n\ntm_shape(Thai_doff) +\n  tm_fill(\"total_count\",\n          n = 5,\n          style = \"quantile\",\n          palette = \"Purples\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\") +\n  tm_facets(by = 'fiscal_year')\n\n\n\n\n\n\n\n\nBefore we can proceed, I will create new data frames by segmenting our Thai_doff by years. This will help us in our analysis the spatial autocorrelation over time later on.\n\nyears &lt;- list(17, 18, 19, 20, 21, 22)\n\nfor (i in years) {\n  \n  vars &lt;- paste('Thai_doff_', i, sep = '') \n  assign(vars, \n         Thai_doff %&gt;% \n           filter(fiscal_year == paste('20', i, sep = '')))\n         \n}"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#computing-weights-of-the-study-area",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#computing-weights-of-the-study-area",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.2 Computing Weights of the Study Area",
    "text": "2.2 Computing Weights of the Study Area\nThe first step in our analysis will be to come up with the spatial weights for our study area. Since our study area is constant over the time period and there was no change in the provincial boundaries of Thailand during the years 2017-2022, we can compute the spatial weights just once at the start of our analysis and use it for our yearly calculations.\n\n2.2.1 Computing the Contiguity Spatial Weights\nI will use the st_contiguity() method from the sfdep package to derive the spatial neighbours of the spatial units and st_weights() is used to compute their respective weights and save it as a new variable.\n\n  Thai_doff_wm&lt;- Thai_doff_17 %&gt;% \n  mutate(nb = st_contiguity(geometry),\n         wt= st_weights(nb, \n                        style='W'),\n         .before=1)\n\nWhen I tried this, I encountered an error indicating the presence of units with no neighbours. Hence, I computed the neighbours list of the spatial units by themselves to identify the exact units causing the errors.\n\nThai_doff_wm&lt;- st_contiguity(Thai_doff_17$geometry)\n\nThai_doff_wm\n\nNeighbour list object:\nNumber of regions: 75 \nNumber of nonzero links: 330 \nPercentage nonzero weights: 5.866667 \nAverage number of links: 4.4 \n1 region with no links:\n46\n2 disjoint connected subgraphs\n\n\nFrom the results above, we see that region 46 is the spatial unit with no neighbours, and that there are 2 disjoint clusters of spatial units-likely due to this unlinked region. Referring to the corresponding province name of the 46th spatial region in the geometry column of the Thai_doff_17 dataframe:\n\nThai_doff_17$province_en[46]\n\n[1] \"Phuket\"\n\n\nWe see that the region is Phuket. This corroborates with the fact that Phuket is an island off of the coast of mainland Thailand, thus falling out of the connected administrative boundaries. Since I do want to keep Phuket in the analysis, I will handle this issue by manually setting the neighbour of Phuket. I will set it to be region 37, Phang Nga, since it is geographically closest to Phuket. I will include an extra codeline to capture this, while keeping the rest of the code from earlier.\n\nThai_doff_wm &lt;- Thai_doff_17 %&gt;% \n  mutate(nb = st_contiguity(geometry), .before=1)\n\nThai_doff_wm$nb[[46]] &lt;- as.integer(37)\n\nThai_doff_wm &lt;- Thai_doff_wm %&gt;%\n  mutate(wt = st_weights(nb, style = 'W'), \n         .before = 1) %&gt;% \n  select(1,2)"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.3 Global Measures of Spatial Autocorrelation",
    "text": "2.3 Global Measures of Spatial Autocorrelation\n\n2.2.3 Performing the Moran I’s Test by Year\nFor this section, I will be conducting the Moran I’s Test and the Moran I’s Permutations test for the dataset according to each year.\n\n201720182019202020212022\n\n\n\nGlobal Moran’s I TestMoran I’s Permutation Test\n\n\n\nglobal_moran_test(Thai_doff_17$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.2891, p-value = 0.01104\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.127509970      -0.013513514       0.003795253 \n\n\n\n\n\nset.seed(1234)\nglobal_moran_perm(Thai_doff_17$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.12751, observed rank = 96, p-value = 0.08\nalternative hypothesis: two.sided\n\n\nFrom the results above, we see that the Global Moran I’s statistic is 0.128\n\n\n\n\n\n\nGlobal Moran I’s TestMoran I’s Permutation Test\n\n\n\nglobal_moran_test(Thai_doff_18$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.0134, p-value = 0.02203\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.111791008      -0.013513514       0.003873097 \n\n\n\n\n\nset.seed(1235)\nglobal_moran_perm(Thai_doff_18$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.11179, observed rank = 94, p-value = 0.12\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nGlobal Moran I’s TestMoran I’s Permutation Test\n\n\n\nglobal_moran_test(Thai_doff_19$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.3502, p-value = 0.009381\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n       0.15065681       -0.01351351        0.00487949 \n\n\n\n\n\nset.seed(1236)\nglobal_moran_perm(Thai_doff_19$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.15066, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nGlobal Moran I’s TestMoran I’s Permutation’s Test\n\n\n\nglobal_moran_test(Thai_doff_20$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 1.8872, p-value = 0.02957\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.125756486      -0.013513514       0.005446309 \n\n\n\n\n\nset.seed(1237)\nglobal_moran_perm(Thai_doff_20$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.12576, observed rank = 99, p-value = 0.02\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nGlobal Moran I’s TestMoran I’s Permutations Test\n\n\n\nglobal_moran_test(Thai_doff_21$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.7545, p-value = 0.002939\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.200458201      -0.013513514       0.006034402 \n\n\n\n\n\nset.seed(1238)\nglobal_moran_perm(Thai_doff_21$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.20046, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nGlobal Moran I’s TestMoran I’s Permutations Test\n\n\n\nglobal_moran_test(Thai_doff_22$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.922, p-value = 0.001739\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.216964758      -0.013513514       0.006221729 \n\n\n\n\n\nset.seed(1238)\nglobal_moran_perm(Thai_doff_20$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.12576, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\n\n\n2.2.4 Computing Geary C’s statistics by Year"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#local-measures-of-spatial-autocorrelation",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#local-measures-of-spatial-autocorrelation",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.4 Local Measures of Spatial Autocorrelation",
    "text": "2.4 Local Measures of Spatial Autocorrelation\n\n2.4.1 Local Moran’s I\nIn this section, I will be computing the Local Moran’s I statistics for the drug related offences and visualising them on maps. To achieve this, I will be using the local_moran() function of the sfdep package.\n\nThai_doff_17 &lt;- Thai_doff_17 %&gt;% \n mutate(local_moran = local_moran(total_count, Thai_doff_wm$nb, Thai_doff_wm$wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran, names_sep = \"_\")\n\nThai_doff_18 &lt;- Thai_doff_18 %&gt;% \n mutate(local_moran = local_moran(total_count, Thai_doff_wm$nb, Thai_doff_wm$wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran, names_sep = \"_\")\n\nThai_doff_19 &lt;- Thai_doff_19 %&gt;% \n mutate(local_moran = local_moran(total_count, Thai_doff_wm$nb, Thai_doff_wm$wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran, names_sep = \"_\")\n\nThai_doff_20 &lt;- Thai_doff_20 %&gt;% \n mutate(local_moran = local_moran(total_count, Thai_doff_wm$nb, Thai_doff_wm$wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran, names_sep = \"_\")\n\nThai_doff_21 &lt;- Thai_doff_21 %&gt;% \n mutate(local_moran = local_moran(total_count, Thai_doff_wm$nb, Thai_doff_wm$wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran, names_sep = \"_\")\n\nThai_doff_22 &lt;- Thai_doff_22 %&gt;% \n mutate(local_moran = local_moran(total_count, Thai_doff_wm$nb, Thai_doff_wm$wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran, names_sep = \"_\")\n\nWe will now plot these statistics on maps.\n\n201720182019202020212022\n\n\n\ntmap_mode(\"plot\") +\ntm_shape(Thai_doff_17) + \n  tm_fill(\"local_moran_ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"2017\",\n            main.title.size= 1)\n\ntmap mode set to plotting\n\n\nVariable(s) \"local_moran_ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")  +\ntm_shape(Thai_doff_18) + \n  tm_fill(\"local_moran_ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"2018\",\n            main.title.size= 1)\n\ntmap mode set to plotting\n\n\nVariable(s) \"local_moran_ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\") +\ntm_shape(Thai_doff_19) + \n  tm_fill(\"local_moran_ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"2019\",\n            main.title.size= 1)\n\ntmap mode set to plotting\n\n\nVariable(s) \"local_moran_ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\") +\ntm_shape(Thai_doff_20) + \n  tm_fill(\"local_moran_ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"2020\",\n            main.title.size= 1)\n\ntmap mode set to plotting\n\n\nVariable(s) \"local_moran_ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\") +\ntm_shape(Thai_doff_21) + \n  tm_fill(\"local_moran_ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"2021\",\n            main.title.size= 1)\n\ntmap mode set to plotting\n\n\nVariable(s) \"local_moran_ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\") +\ntm_shape(Thai_doff_22) + \n  tm_fill(\"local_moran_ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"2022\",\n            main.title.size= 1)\n\ntmap mode set to plotting\n\n\nVariable(s) \"local_moran_ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.2 Visualising the LISA maps by Year\n\n201720182019202020212022\n\n\n\nlisa_sig17&lt;- Thai_doff_17 %&gt;% \n  filter(local_moran_p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(Thai_doff_17) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig17) +\n  tm_fill(\"local_moran_mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig18&lt;- Thai_doff_18 %&gt;% \n  filter(local_moran_p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(Thai_doff_18) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig18) +\n  tm_fill(\"local_moran_mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig19&lt;- Thai_doff_19 %&gt;% \n  filter(local_moran_p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(Thai_doff_19) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig19) +\n  tm_fill(\"local_moran_mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig20&lt;- Thai_doff_20 %&gt;% \n  filter(local_moran_p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(Thai_doff_20) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig20) +\n  tm_fill(\"local_moran_mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig21&lt;- Thai_doff_21 %&gt;% \n  filter(local_moran_p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(Thai_doff_21) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig21) +\n  tm_fill(\"local_moran_mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig22&lt;- Thai_doff_22 %&gt;% \n  filter(local_moran_p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(Thai_doff_22) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig22) +\n  tm_fill(\"local_moran_mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#hotcold-spot-analysis",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#hotcold-spot-analysis",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.5 Hot/Cold Spot Analysis",
    "text": "2.5 Hot/Cold Spot Analysis\n\n2.5.1 Computing the Gi Stastics"
  }
]