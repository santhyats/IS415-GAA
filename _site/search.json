[
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "Myanmar has been going through civil wars and internal conflicts for decades now. These conflicts have mainly been due to ethnic tensions and general unhappiness in the governing party. Conflicts range from battles, riots, violence against civilians, strategic developments and more. In this exercise, I will be analysing the distribution of conflicts in Myanmar.\nTo do this, I will mainly be performing quarterly KDE analysis on 4 main types of conflicts: Battles, Explosions, Violence against Civilians and Strategic Developments through the years of 2021-2024. I will also be performing the second order spatial point pattern process as well as the spatio temporal point process analysis for these segments. Let’s get started.\n\n\nThese are the packages that I will be using in this exercise.\nsf: Used in spatial data wrangling\ntidyverse: Used in data wrangling for non-spatial data\nraster: For reading, writing and manipulating raster data\ntmap: For functions relating to mapping point patterns\nspatstat: Provides functions for spatial point process analysis\nsparr: Provides functions for spatio-temporal point process analysis\n\npacman::p_load(sf, tidyverse, spatstat, sparr, tmap)"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#overview",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#overview",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "Myanmar has been going through civil wars and internal conflicts for decades now. These conflicts have mainly been due to ethnic tensions and general unhappiness in the governing party. Conflicts range from battles, riots, violence against civilians, strategic developments and more. In this exercise, I will be analysing the distribution of conflicts in Myanmar.\nTo do this, I will mainly be performing quarterly KDE analysis on 4 main types of conflicts: Battles, Explosions, Violence against Civilians and Strategic Developments through the years of 2021-2024. I will also be performing the second order spatial point pattern process as well as the spatio temporal point process analysis for these segments. Let’s get started.\n\n\nThese are the packages that I will be using in this exercise.\nsf: Used in spatial data wrangling\ntidyverse: Used in data wrangling for non-spatial data\nraster: For reading, writing and manipulating raster data\ntmap: For functions relating to mapping point patterns\nspatstat: Provides functions for spatial point process analysis\nsparr: Provides functions for spatio-temporal point process analysis\n\npacman::p_load(sf, tidyverse, spatstat, sparr, tmap)"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#data-preparation",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#data-preparation",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.2 Data Preparation",
    "text": "1.2 Data Preparation\nIn this section, I will be retrieving the required data and performing the necessary data wrangling methods in order to transform the data into a form that is best suitable for our analytic needs for this exercise. The datasets used in this exercise are:\n\nMyanmar_All_2021-24.csv: A csv file downloaded from ACLED, which contains all the details of the internal conflicts in Myanmar from 2021-2024. Note that the file name has been renamed for ease of use.\nMBoundary: A shapefile downloaded from Myanmar Information Management Unit, MIMU. This shapefile maps out the boundary of Myanmar. I have also renamed this file for ease of use.\n\n\n1.2.1 Importing the Data\nFirstly, I will be importing the base map of Myanmar in shapefile format using st_read() function of the sf package. I will also transform the crs to that of Myanmar using the st_transform() function.\n\nboundary &lt;- st_read(dsn=\"data/raw\",\n                    layer = \"MBoundary\") %&gt;% \n  st_transform(crs=32646) %&gt;% \n  write_rds(\"data/rds/boundary.rds\")\n\n\nboundary&lt;-read_rds(\"data/rds/boundary.rds\")\n\nWe will make use of st_crs() function to make sure that the Coordinate Reference System has been correctly transformed to that of Myanmar.\n\nst_crs(boundary)\n\nCoordinate Reference System:\n  User input: EPSG:32646 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 46N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 46N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",93,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 90°E and 96°E, northern hemisphere between equator and 84°N, onshore and offshore. Bangladesh. Bhutan. China. Indonesia. Mongolia. Myanmar (Burma). Russian Federation.\"],\n        BBOX[0,90,84,96]],\n    ID[\"EPSG\",32646]]\n\n\nNext, I will also be Importing the regional boundaries of Myanmar and transforming the crs to that of Myanmar’s again.\n\nregions_sf &lt;- st_read(dsn=\"data/raw\",\n                      layer=\"regions\") %&gt;% \n  st_transform(crs = 32646) %&gt;% \n  write_rds(\"data/rds/regions.rds\")\n\n\nregions_sf&lt;-read_rds(\"data/rds/regions.rds\")\n\nLastly, I will be importing and reading the csv file containing the data about the conflicts into a dataframe called all_sf. This is done using the read_csv() function of the readr package. I will once again ensure that the crs of the data is transformed to that of Myanmar’s.\n\nall_sf &lt;- read_csv('data/raw/Myanmar_All_2021-24.csv') %&gt;% \n  st_as_sf(coords = c('longitude', 'latitude'),\n           crs=4326) %&gt;% \n  st_transform(crs=32646) %&gt;% \n   select(1:4, 6,19, 29, 30) \n\nst_crs(all_sf)\n\n\n\n1.2.2 Preparing the Data\nBefore we can start deriving our KDE layers, we will make sure our data is in a suitable form and is processed in a way that we need it in. I will start off by converting the date column in the aspatial data to the date format so that can be handled during computations. This is done through the as.Date() functon. I will also add in new columns called “quarters” and “num_quarters” to keep track of our quarters and its numbers. The numeric quarters column will come in handy when we are computing our Spatio Temporal KDE layers later.\n\nall_sf&lt;- all_sf %&gt;% \n  mutate(event_date = as.Date(event_date, format = \"%d %B %Y\"))\nall_sf$quarters &lt;- paste(quarters(all_sf$event_date), year(all_sf$event_date), sep=\"_\")\nall_sf$num_quarters&lt;-quarter(all_sf$event_date)\nwrite_rds(all_sf,\"data/rds/all.rds\")\n\n\nall_sf&lt;-read_rds(\"data/rds/all.rds\")\n\nBefore we can filter out the data that we need, I will be visualising the data according to the event types to observe for any patterns or similarity. To do this, I will first use tm_shape() and tm_polygons() of the tmap package to plot the base map of Myanmar, indicating all the regions. Next, I will use tm_shape() and tm_dots() together to plot out all the spatial points. Lastly, I will use tm_facets() to separate the plots according to the type of conlfict.\n\ntm_shape(boundary) + tm_polygons() + tm_shape(regions_sf) + tm_polygons() + tm_shape(all_sf) + tm_dots() + tm_facets(by='event_type', free.coords = FALSE, drop.units= TRUE)\n\n\n\n\n\n\n\n\nFrom the patterns observed above, I see that Battles, Strategic Developments, Explosions and Violence against civilians all have similar distribution of conflicts across the space. I also noted that Riots and Protests have very sparsespatial points even over the aggregated 4 year dataset. This indicates the possibility that there will be few to no spatial points available to analyse for certain quarters.\nAs such, I will be focusing my analysis on these four main categories of conflicts: Battles, Strategic Developments, Violence against Civilians and Explosions.\nI will filter out the data according to these event types using the filter() function and save them in separate sf objects.\n\nbattles_sf &lt;- all_sf %&gt;%  filter(event_type == 'Battles') %&gt;% \n  write_rds(\"data/rds/Battles/battles_sf.rds\")\n\nexp_sf &lt;- all_sf %&gt;%  filter(event_type == \"Explosions/Remote violence\") %&gt;% \n  write_rds(\"data/rds/Explosions/exp_sf.rds\")\n\ncivViolence_sf &lt;- all_sf %&gt;%  filter(event_type == \"Violence against civilians\") %&gt;% \n  write_rds(\"data/rds/Violence/civViolence_sf.rds\")\n\nstrat_dev_sf &lt;- all_sf %&gt;%  filter(event_type == 'Strategic developments') %&gt;% \n  write_rds(\"data/rds/Strat_Dev/strat_dev.rds\")\n\nI will also be creating a separate sf containing the only the timeframe and the geometry of the spatial points, to be used in our Spatio Temporal KDE layers later. This is done by using the select() functions to select only the “quarters”, “num_quarters” an d”geometry” columns from the dataframes of the respective conflict types.\n\nquart_geo_bat&lt;- battles_sf %&gt;% \n  select(3,8,10) %&gt;% \n  write_rds(\"data/rds/Battles/quart_geo_bat.rds\")\n\nquart_geo_civ &lt;- civViolence_sf %&gt;% \n  select(3,8,10) %&gt;% \n  write_rds(\"data/rds/Violence/quart_geo_civ.rds\")\n\nquart_geo_exp&lt;- exp_sf %&gt;% \n  select(3,8,10) %&gt;% \n  write_rds(\"data/rds/Explosions/quart_geo_exp.rds\")\n\nquart_geo_strat&lt;- strat_dev_sf %&gt;% \n  select(3,8,10) %&gt;% \n  write_rds(\"data/rds/Strat_Dev/quart_geo_strat.rds\")\n\nFinally, I will further split the conflict type datasets into quarterly periods. For ease of use, I will write these sf objects into rds files and save them in a compiled folder.\n\nBattlesExplosionsViolence against civilliansStrategic Developments\n\n\n\nq1_21_battles_sf &lt;- battles_sf %&gt;% \n  filter(year == '2021' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Battles/2021/q1.rds\")\n\nq2_21_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Battles/2021/q2.rds\")\n\nq3_21_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Battles/2021/q3.rds\")\n\nq4_21_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Battles/2021/q4.rds\")\n\n#2022\n\nq1_22_battles_sf &lt;- battles_sf %&gt;% \n  filter(year == '2022' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Battles/2022/q1.rds\")\n\nq2_22_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Battles/2022/q2.rds\")\n\nq3_22_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Battles/2022/q3.rds\")\n\nq4_22_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Battles/2022/q4.rds\")\n\n#2023\n\nq1_23_battles_sf &lt;- battles_sf %&gt;% \n  filter(year == '2023' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Battles/2023/q1.rds\")\n\nq2_23_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Battles/2023/q2.rds\")\n\nq3_23_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Battles/2023/q3.rds\")\n\nq4_23_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Battles/2023/q4.rds\")\n\n#2024\n\nq1_24_battles_sf &lt;- battles_sf %&gt;% \n  filter(year == '2024' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Battles/2024/q1.rds\")\n\nq2_24_battles_sf &lt;-battles_sf %&gt;% \n  filter(year == '2024') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Battles/2024/q2.rds\")\n\n\n\n\nq1_21_exp_sf &lt;- exp_sf %&gt;% \n  filter(year == '2021' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Explosions/2021/q1.rds\")\n\nq2_21_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Explosions/2021/q2.rds\")\n\nq3_21_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Explosions/2021/q3.rds\")\n\nq4_21_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Explosions/2021/q4.rds\")\n\n#2022\n\nq1_22_exp_sf &lt;- exp_sf %&gt;% \n  filter(year == '2022' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Explosions/2022/q1.rds\")\n\nq2_22_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Explosions/2022/q2.rds\")\n\nq3_22_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Explosions/2022/q3.rds\")\n\nq4_22_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Explosions/2022/q4.rds\")\n\n#2023\n\nq1_23_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2023' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Explosions/2023/q1.rds\")\n\nq2_23_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Explosions/2023/q2.rds\")\n\nq3_23_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Explosions/2023/q3.rds\")\n\nq4_23_exp_sf &lt;-battles_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Explosions/2023/q4.rds\")\n\n#2024\n\nq1_24_exp_sf &lt;- exp_sf %&gt;% \n  filter(year == '2024' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Explosions/2024/q1.rds\")\n\nq2_24_exp_sf &lt;-exp_sf %&gt;% \n  filter(year == '2024') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Explosions/2024/q2.rds\")\n\n\n\n\nq1_21_civViolence_sf &lt;- civViolence_sf %&gt;% \n  filter(year == '2021' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Violence/2021/q1.rds\")\n\nq2_21_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Violence/2021/q2.rds\")\n\nq3_21_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Violence/2021/q3.rds\")\n\nq4_21_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Violence/2021/q4.rds\")\n\n#2022\n\nq1_22_civViolence_sf &lt;- civViolence_sf %&gt;% \n  filter(year == '2022' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Violence/2022/q1.rds\")\n\nq2_22_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Violence/2022/q2.rds\")\n\nq3_22_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Violence/2022/q3.rds\")\n\nq4_22_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Violence/2022/q4.rds\")\n\n#2023\n\nq1_23_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2023' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Violence/2023/q1.rds\")\n\nq2_23_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Violence/2023/q2.rds\")\n\nq3_23_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Violence/2023/q3.rds\")\n\nq4_23_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Violence/2023/q4.rds\")\n\n#2024\n\nq1_24_civViolence_sf &lt;- civViolence_sf %&gt;% \n  filter(year == '2024' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Violence/2024/q1.rds\")\n\nq2_24_civViolence_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2024') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Violence/2024/q2.rds\")\n\n\n\n\nq1_21_strat_dev_sf &lt;- strat_dev_sf %&gt;% \n  filter(year == '2021' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2021/q1.rds\")\n\nq2_21_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2021/q2.rds\")\n\nq3_21_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2021/q3.rds\")\n\nq4_21_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2021') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2021/q4.rds\")\n\n#2022\n\nq1_22_strat_dev_sf &lt;- strat_dev_sf %&gt;% \n  filter(year == '2022' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2022/q1.rds\")\n\nq2_22_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2022/q2.rds\")\n\nq3_22_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2022/q3.rds\")\n\nq4_22_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2022') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2022/q4.rds\")\n\n#2023\n\nq1_23_strat_dev_sf &lt;-civViolence_sf %&gt;% \n  filter(year == '2023' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2023/q1.rds\")\n\nq2_23_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2023/q2.rds\")\n\nq3_23_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 3)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2023/q3.rds\")\n\nq4_23_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2023') %&gt;% \n  filter(quarter(event_date) == 4)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2023/q4.rds\")\n\n#2024\n\nq1_24_strat_dev_sf &lt;- strat_dev_sf %&gt;% \n  filter(year == '2024' ) %&gt;% \n  filter(quarter(event_date) == 1) %&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2024/q1.rds\")\n\nq2_24_strat_dev_sf &lt;-strat_dev_sf %&gt;% \n  filter(year == '2024') %&gt;% \n  filter(quarter(event_date) == 2)%&gt;%  \n  write_rds(\"data/rds/Strat_Dev/2024/q2.rds\")\n\n\n\n\n\n\n2.2 Data Wrangling\n\n2.2.1 Converting the sf objects to ppp objects\nTo derive our KDE layers, we would firstly need the sf objects to be converted to ppp objects. This is because the function that we will be using, density() of the spatstat package, only takes in objects in the ppp form. We will do this using the as.ppp() function.\n\nBattlesExplosionsStrategic DevelopmentsViolence Against Civilians\n\n\n\nbattlesQ121_ppp &lt;- as.ppp(st_coordinates(q1_21_battles_sf), st_bbox(q1_21_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ221_ppp &lt;- as.ppp(st_coordinates(q2_21_battles_sf), st_bbox(q2_21_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ321_ppp&lt;- as.ppp(st_coordinates(q3_21_battles_sf), st_bbox(q3_21_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ421_ppp&lt;-as.ppp(st_coordinates(q4_21_battles_sf), st_bbox(q4_21_battles_sf))\n\nWarning: data contain duplicated points\n\n#2022\n\nbattlesQ122_ppp &lt;- as.ppp(st_coordinates(q1_22_battles_sf), st_bbox(q1_22_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ222_ppp &lt;- as.ppp(st_coordinates(q2_22_battles_sf), st_bbox(q2_22_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ322_ppp&lt;- as.ppp(st_coordinates(q3_22_battles_sf), st_bbox(q3_22_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ422_ppp&lt;-as.ppp(st_coordinates(q4_22_battles_sf), st_bbox(q4_22_battles_sf))\n\nWarning: data contain duplicated points\n\n#2023\nbattlesQ123_ppp &lt;- as.ppp(st_coordinates(q1_23_battles_sf), st_bbox(q1_23_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ223_ppp &lt;- as.ppp(st_coordinates(q2_23_battles_sf), st_bbox(q2_23_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ323_ppp&lt;- as.ppp(st_coordinates(q3_23_battles_sf), st_bbox(q3_23_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ423_ppp&lt;-as.ppp(st_coordinates(q4_23_battles_sf), st_bbox(q4_23_battles_sf))\n\nWarning: data contain duplicated points\n\n#2024\nbattlesQ124_ppp &lt;- as.ppp(st_coordinates(q1_24_battles_sf), st_bbox(q1_24_battles_sf))\n\nWarning: data contain duplicated points\n\nbattlesQ224_ppp &lt;- as.ppp(st_coordinates(q2_24_battles_sf), st_bbox(q2_24_battles_sf))\n\nWarning: data contain duplicated points\n\n\n\n\n\nexpQ121_ppp &lt;- as.ppp(st_coordinates(q1_21_exp_sf), st_bbox(q1_21_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ221_ppp &lt;- as.ppp(st_coordinates(q2_21_exp_sf), st_bbox(q2_21_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ321_ppp&lt;- as.ppp(st_coordinates(q3_21_exp_sf), st_bbox(q3_21_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ421_ppp&lt;-as.ppp(st_coordinates(q4_21_exp_sf), st_bbox(q4_21_exp_sf))\n\nWarning: data contain duplicated points\n\n#2022\n\nexpQ122_ppp &lt;- as.ppp(st_coordinates(q1_22_exp_sf), st_bbox(q1_22_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ222_ppp &lt;- as.ppp(st_coordinates(q2_22_exp_sf), st_bbox(q2_22_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ322_ppp&lt;- as.ppp(st_coordinates(q3_22_exp_sf), st_bbox(q3_22_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ422_ppp&lt;-as.ppp(st_coordinates(q4_22_exp_sf), st_bbox(q4_22_exp_sf))\n\nWarning: data contain duplicated points\n\n#2023\nexpQ123_ppp &lt;- as.ppp(st_coordinates(q1_23_exp_sf), st_bbox(q1_23_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ223_ppp &lt;- as.ppp(st_coordinates(q2_23_exp_sf), st_bbox(q2_23_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ323_ppp&lt;- as.ppp(st_coordinates(q3_23_exp_sf), st_bbox(q3_23_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ423_ppp&lt;-as.ppp(st_coordinates(q4_23_exp_sf), st_bbox(q4_23_exp_sf))\n\nWarning: data contain duplicated points\n\n#2024\nexpQ124_ppp &lt;- as.ppp(st_coordinates(q1_24_exp_sf), st_bbox(q1_24_exp_sf))\n\nWarning: data contain duplicated points\n\nexpQ224_ppp &lt;- as.ppp(st_coordinates(q2_24_exp_sf), st_bbox(q2_24_exp_sf))\n\nWarning: data contain duplicated points\n\n\n\n\n\nstrat_devQ121_ppp &lt;- as.ppp(st_coordinates(q1_21_strat_dev_sf), st_bbox(q1_21_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ221_ppp &lt;- as.ppp(st_coordinates(q2_21_strat_dev_sf), st_bbox(q2_21_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ321_ppp&lt;- as.ppp(st_coordinates(q3_21_strat_dev_sf), st_bbox(q3_21_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ421_ppp&lt;-as.ppp(st_coordinates(q4_21_strat_dev_sf), st_bbox(q4_21_strat_dev_sf))\n\nWarning: data contain duplicated points\n\n#2022\nstrat_devQ122_ppp &lt;- as.ppp(st_coordinates(q1_22_strat_dev_sf), st_bbox(q1_22_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ222_ppp &lt;- as.ppp(st_coordinates(q2_22_strat_dev_sf), st_bbox(q2_22_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ322_ppp&lt;- as.ppp(st_coordinates(q3_22_strat_dev_sf), st_bbox(q3_22_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ422_ppp&lt;-as.ppp(st_coordinates(q4_22_strat_dev_sf), st_bbox(q4_22_strat_dev_sf))\n\nWarning: data contain duplicated points\n\n#2023\nstrat_devQ123_ppp &lt;- as.ppp(st_coordinates(q1_23_strat_dev_sf), st_bbox(q1_23_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ223_ppp &lt;- as.ppp(st_coordinates(q2_23_strat_dev_sf), st_bbox(q2_23_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ323_ppp&lt;- as.ppp(st_coordinates(q3_23_strat_dev_sf), st_bbox(q3_23_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ423_ppp&lt;-as.ppp(st_coordinates(q4_23_strat_dev_sf), st_bbox(q4_23_strat_dev_sf))\n\nWarning: data contain duplicated points\n\n#2024\nstrat_devQ124_ppp &lt;- as.ppp(st_coordinates(q1_24_strat_dev_sf), st_bbox(q1_24_strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_devQ224_ppp &lt;- as.ppp(st_coordinates(q2_24_strat_dev_sf), st_bbox(q2_24_strat_dev_sf))\n\nWarning: data contain duplicated points\n\n\n\n\n\ncivViolenceQ121_ppp &lt;- as.ppp(st_coordinates(q1_21_civViolence_sf), st_bbox(q1_21_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ221_ppp &lt;- as.ppp(st_coordinates(q2_21_civViolence_sf), st_bbox(q2_21_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ321_ppp&lt;- as.ppp(st_coordinates(q3_21_civViolence_sf), st_bbox(q3_21_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ421_ppp&lt;-as.ppp(st_coordinates(q4_21_civViolence_sf), st_bbox(q4_21_civViolence_sf))\n\nWarning: data contain duplicated points\n\n#2022\n\ncivViolenceQ122_ppp &lt;- as.ppp(st_coordinates(q1_22_civViolence_sf), st_bbox(q1_22_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ222_ppp &lt;- as.ppp(st_coordinates(q2_22_civViolence_sf), st_bbox(q2_22_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ322_ppp&lt;- as.ppp(st_coordinates(q3_22_civViolence_sf), st_bbox(q3_22_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ422_ppp&lt;-as.ppp(st_coordinates(q4_22_civViolence_sf), st_bbox(q4_22_civViolence_sf))\n\nWarning: data contain duplicated points\n\n#2023\ncivViolenceQ123_ppp &lt;- as.ppp(st_coordinates(q1_23_civViolence_sf), st_bbox(q1_23_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ223_ppp &lt;- as.ppp(st_coordinates(q2_23_civViolence_sf), st_bbox(q2_23_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ323_ppp&lt;- as.ppp(st_coordinates(q3_23_civViolence_sf), st_bbox(q3_23_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ423_ppp&lt;-as.ppp(st_coordinates(q4_23_civViolence_sf), st_bbox(q4_23_civViolence_sf))\n\nWarning: data contain duplicated points\n\n#2024\ncivViolenceQ124_ppp &lt;- as.ppp(st_coordinates(q1_24_civViolence_sf), st_bbox(q1_24_civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolenceQ224_ppp &lt;- as.ppp(st_coordinates(q2_24_civViolence_sf), st_bbox(q2_24_civViolence_sf))\n\nWarning: data contain duplicated points\n\n\n\n\n\n\n\n\n2.2.2 Converting the boundary to an owin object\nI will convert the regions_sf object to an owin object using the the as.owin() function.\n\nboundary_owin &lt;- as.owin(regions_sf)\n\nOnce we have our ppp objects and owin object, we can start combining them to one object which can then be passed through the density() function.\n\nBattlesExplosionsStrategic DevelopmentsViolence Against Civilians\n\n\n\nbattlesQ121_ppp_com&lt;- battlesQ121_ppp[boundary_owin]\nbattlesQ121_ppp_com&lt;- rescale(battlesQ121_ppp_com, 1000, \"km\") \n\n\nbattlesQ221_ppp_com&lt;- battlesQ221_ppp[boundary_owin]\nbattlesQ221_ppp_com&lt;- rescale(battlesQ221_ppp_com, 1000, \"km\") \n\n\nbattlesQ321_ppp_com&lt;- battlesQ321_ppp[boundary_owin]\nbattlesQ321_ppp_com&lt;- rescale(battlesQ321_ppp_com, 1000, \"km\") \n\nbattlesQ421_ppp_com&lt;- battlesQ421_ppp[boundary_owin]\nbattlesQ421_ppp_com&lt;- rescale(battlesQ421_ppp_com, 1000, \"km\")\n\n#2022\n \nbattlesQ122_ppp_com&lt;- battlesQ122_ppp[boundary_owin]\nbattlesQ122_ppp_com&lt;- rescale(battlesQ122_ppp_com, 1000, \"km\")\n\nbattlesQ222_ppp_com&lt;- battlesQ222_ppp[boundary_owin]\nbattlesQ222_ppp_com&lt;- rescale(battlesQ222_ppp_com, 1000, \"km\")\n\nbattlesQ322_ppp_com&lt;- battlesQ322_ppp[boundary_owin]\nbattlesQ322_ppp_com&lt;- rescale(battlesQ322_ppp_com, 1000, \"km\")\n\nbattlesQ422_ppp_com&lt;- battlesQ422_ppp[boundary_owin]\nbattlesQ422_ppp_com&lt;- rescale(battlesQ422_ppp_com, 1000, \"km\")                                                                                \n#2023\n                                      \nbattlesQ123_ppp_com&lt;- battlesQ123_ppp[boundary_owin]\nbattlesQ123_ppp_com&lt;- rescale(battlesQ123_ppp_com, 1000, \"km\")\n\nbattlesQ223_ppp_com&lt;- battlesQ223_ppp[boundary_owin]\nbattlesQ223_ppp_com&lt;- rescale(battlesQ223_ppp_com, 1000, \"km\")\n\nbattlesQ323_ppp_com&lt;- battlesQ323_ppp[boundary_owin]\nbattlesQ323_ppp_com&lt;- rescale(battlesQ323_ppp_com, 1000, \"km\")\n\nbattlesQ423_ppp_com&lt;- battlesQ423_ppp[boundary_owin]\nbattlesQ423_ppp_com&lt;- rescale(battlesQ423_ppp_com, 1000, \"km\")\n\n#2024\n\nbattlesQ124_ppp_com&lt;- battlesQ124_ppp[boundary_owin]\nbattlesQ124_ppp&lt;- rescale(battlesQ124_ppp_com, 1000, \"km\")\n\nbattlesQ224_ppp_com&lt;- battlesQ224_ppp[boundary_owin]\nbattlesQ224_ppp_com&lt;- rescale(battlesQ224_ppp_com, 1000, \"km\")\n\n\n\n\nexpQ121_ppp_com&lt;- expQ121_ppp[boundary_owin]\nexpQ121_ppp_com&lt;- rescale(expQ121_ppp_com, 1000, \"km\")\n\nexpQ221_ppp_com&lt;- expQ221_ppp[boundary_owin]\nexpQ221_ppp_com&lt;- rescale(expQ221_ppp_com, 1000, \"km\")\n\nexpQ321_ppp_com&lt;- expQ321_ppp[boundary_owin]\nexpQ321_ppp_com&lt;- rescale(expQ321_ppp_com, 1000, \"km\") \n\nexpQ421_ppp_com&lt;- expQ421_ppp[boundary_owin]\nexpQ421_ppp_com&lt;- rescale(expQ421_ppp_com, 1000, \"km\")\n\n#2022\n \nexpQ122_ppp_com&lt;- expQ122_ppp[boundary_owin]\nexpQ122_ppp_com&lt;- rescale(expQ122_ppp_com, 1000, \"km\")\n\nexpQ222_ppp_com&lt;- expQ222_ppp[boundary_owin]\nexpQ222_ppp_com&lt;- rescale(expQ222_ppp_com, 1000, \"km\")\n\nexpQ322_ppp_com&lt;- expQ322_ppp[boundary_owin]\nexpQ322_ppp_com&lt;- rescale(expQ322_ppp_com, 1000, \"km\")\n\nexpQ422_ppp_com&lt;- expQ422_ppp[boundary_owin]\nexpQ422_ppp_com&lt;- rescale(expQ422_ppp_com, 1000, \"km\") \n\n#2023\n                                      \n \nexpQ123_ppp_com&lt;- expQ123_ppp[boundary_owin]\nexpQ123_ppp&lt;- rescale(expQ123_ppp_com, 1000, \"km\")\n\n \nexpQ223_ppp_com&lt;- expQ223_ppp[boundary_owin]\nexpQ223_ppp_com&lt;- rescale(expQ223_ppp_com, 1000, \"km\")\n\n \nexpQ323_ppp_com&lt;- expQ323_ppp[boundary_owin]\nexpQ323_ppp_com&lt;- rescale(expQ323_ppp_com, 1000, \"km\")\n\n \nexpQ423_ppp_com&lt;- expQ423_ppp[boundary_owin]\nexpQ423_ppp_com&lt;- rescale(expQ423_ppp_com, 1000, \"km\")\n\n#2024\n\nexpQ124_ppp_com&lt;- expQ124_ppp[boundary_owin]\nexpQ124_ppp_com&lt;- rescale(expQ124_ppp_com, 1000, \"km\")\n\nexpQ224_ppp_com&lt;-expQ224_ppp[boundary_owin]\nexpQ224_ppp_com&lt;- rescale(expQ224_ppp_com, 1000, \"km\")\n\n\n\n\nstrat_devQ121_ppp_com&lt;- strat_devQ121_ppp[boundary_owin]\nstrat_devQ121_ppp_com&lt;- rescale(strat_devQ121_ppp_com, 1000, \"km\")\n\nstrat_devQ221_ppp_com&lt;- strat_devQ221_ppp[boundary_owin]\nstrat_devQ221_ppp_com&lt;- rescale(strat_devQ221_ppp_com, 1000, \"km\")\n\nstrat_devQ321_ppp_com&lt;- strat_devQ321_ppp[boundary_owin]\nstrat_devQ321_ppp_com&lt;- rescale(strat_devQ321_ppp_com, 1000, \"km\")\n\nstrat_devQ421_ppp_com&lt;- strat_devQ421_ppp[boundary_owin]\nstrat_devQ421_ppp_com&lt;- rescale(strat_devQ421_ppp_com, 1000, \"km\")\n\n#2022\n\nstrat_devQ122_ppp_com&lt;- strat_devQ122_ppp[boundary_owin]\nstrat_devQ122_ppp_com&lt;- rescale(strat_devQ122_ppp_com, 1000, \"km\")\n\nstrat_devQ222_ppp_com&lt;- strat_devQ222_ppp[boundary_owin]\nstrat_devQ222_ppp_com&lt;- rescale(strat_devQ222_ppp_com, 1000, \"km\")\n\nstrat_devQ322_ppp_com&lt;- strat_devQ322_ppp[boundary_owin]\nstrat_devQ322_ppp_com&lt;- rescale(strat_devQ322_ppp_com, 1000, \"km\")\n\nstrat_devQ422_ppp_com&lt;- strat_devQ422_ppp[boundary_owin]\nstrat_devQ422_ppp_com&lt;- rescale(strat_devQ422_ppp_com, 1000, \"km\")\n\n#2023\n                                      \n \nstrat_devQ123_ppp_com&lt;- strat_devQ123_ppp[boundary_owin]\nstrat_devQ123_ppp_com&lt;- rescale(strat_devQ123_ppp_com, 1000, \"km\")\n \nstrat_devQ223_ppp_com&lt;- strat_devQ223_ppp[boundary_owin]\nstrat_devQ223_ppp_com&lt;- rescale(strat_devQ223_ppp_com, 1000, \"km\")\n\nstrat_devQ323_ppp_com&lt;- strat_devQ323_ppp[boundary_owin]\nstrat_devQ323_ppp_com&lt;- rescale(strat_devQ323_ppp_com, 1000, \"km\")\n\nstrat_devQ423_ppp_com&lt;- strat_devQ423_ppp[boundary_owin]\nstrat_devQ423_ppp_com&lt;- rescale(strat_devQ423_ppp_com, 1000, \"km\")\n\n#2024\n\nstrat_devQ124_ppp_com&lt;- strat_devQ124_ppp[boundary_owin]\nstrat_devQ124_ppp_com&lt;- rescale(strat_devQ124_ppp_com, 1000, \"km\")\n\nstrat_devQ224_ppp_com&lt;-strat_devQ224_ppp[boundary_owin]\nstrat_devQ224_ppp_com&lt;- rescale(strat_devQ224_ppp_com, 1000, \"km\")\n\n\n\n\ncivViolenceQ121_ppp_com&lt;- civViolenceQ121_ppp[boundary_owin]\ncivViolenceQ121_ppp_com&lt;- rescale(civViolenceQ121_ppp_com, 1000, \"km\")\n\ncivViolenceQ221_ppp_com&lt;- civViolenceQ221_ppp[boundary_owin]\ncivViolenceQ221_ppp_com&lt;- rescale(civViolenceQ221_ppp_com, 1000, \"km\")\n \ncivViolenceQ321_ppp_com&lt;- civViolenceQ321_ppp[boundary_owin]\ncivViolenceQ321_ppp_com&lt;- rescale(civViolenceQ321_ppp_com, 1000, \"km\")\n\ncivViolenceQ421_ppp_com&lt;- civViolenceQ421_ppp[boundary_owin]\ncivViolenceQ421_ppp_com&lt;- rescale(civViolenceQ421_ppp_com, 1000, \"km\")\n\n#2022\n\ncivViolenceQ122_ppp_com&lt;- civViolenceQ122_ppp[boundary_owin]\ncivViolenceQ122_ppp_com&lt;- rescale(civViolenceQ122_ppp_com, 1000, \"km\")\n\ncivViolenceQ222_ppp_com&lt;- civViolenceQ222_ppp[boundary_owin]\ncivViolenceQ222_ppp_com&lt;- rescale(civViolenceQ222_ppp_com, 1000, \"km\")\n\ncivViolenceQ322_ppp_com&lt;- civViolenceQ322_ppp[boundary_owin]\ncivViolenceQ322_ppp_com&lt;- rescale(civViolenceQ322_ppp_com, 1000, \"km\")\n\ncivViolenceQ422_ppp_com&lt;- civViolenceQ422_ppp[boundary_owin]\ncivViolenceQ422_ppp_com&lt;- rescale(civViolenceQ422_ppp_com, 1000, \"km\")\n\n#2023\n                                      \ncivViolenceQ123_ppp_com&lt;- civViolenceQ123_ppp[boundary_owin]\ncivViolenceQ123_ppp_com&lt;- rescale(civViolenceQ123_ppp_com, 1000, \"km\")\n\ncivViolenceQ223_ppp_com&lt;- civViolenceQ223_ppp[boundary_owin]\ncivViolenceQ223_ppp_com&lt;- rescale(civViolenceQ223_ppp_com, 1000, \"km\")\n\ncivViolenceQ323_ppp_com&lt;- civViolenceQ323_ppp[boundary_owin]\ncivViolenceQ323_ppp_com&lt;- rescale(civViolenceQ323_ppp_com, 1000, \"km\")\n\ncivViolenceQ423_ppp_com&lt;- civViolenceQ423_ppp[boundary_owin]\ncivViolenceQ423_ppp_com&lt;- rescale(civViolenceQ423_ppp_com, 1000, \"km\")\n\n#2024\n\ncivViolenceQ124_ppp_com&lt;- civViolenceQ124_ppp[boundary_owin]\ncivViolenceQ124_ppp_com&lt;- rescale(civViolenceQ124_ppp_com, 1000, \"km\")\n\ncivViolenceQ224_ppp_com&lt;- civViolenceQ224_ppp[boundary_owin]\ncivViolenceQ224_ppp_com&lt;- rescale(civViolenceQ224_ppp_com, 1000, \"km\")"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#computing-the-quarterly-kde-layers",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#computing-the-quarterly-kde-layers",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.3 Computing the quarterly KDE Layers",
    "text": "1.3 Computing the quarterly KDE Layers\nI will now use the combined ppp object to derive the quarterly KDE layers, sorted by the different conflict types. To find the optimal method for calculation of sigma, I did a couple of test plots. I first plotted the KDE layer with the bw.diggle() method of computing the sigma value:\n\nbat_q121_kde&lt;- density(battlesQ121_ppp_com, sigma=bw.diggle(battlesQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \nplot(bat_q121_kde, main=\"Battles in 1st Quarter of 2021\")\n\n\n\n\n\n\n\n\nHowever, as seen above, the map barely showed any patterns or colouring. This was probably due to the fact that the bw.diggle() was more aptly suited for datasets that leaned towards more uniform distributions. From our base plots earlier, the points had significant clustering in some areas, which was probably why this map did not reflect anything. Next, I tried the bw.ppl() method. This method is preferred for datasets where the distribution of spatial points are less homogenous, as is the case with ours.\n\nbat_q121_kde&lt;- density(battlesQ121_ppp_com, sigma=bw.ppl(battlesQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \nplot(bat_q121_kde, main=\"Battles in 1st Quarter of 2021\")\n\n\n\n\n\n\n\n\nThe result was good and enabled me to identify where a cluster of points can be seen. I decided that the bw.ppl() method was better than the bw.diggle() method to calculate sigma for our particular dataset. However, when I began plotting the quarterly layers, I quickly realised that some of the plots were once again, appearing blank. I figured this could be due to the bandwidth set by the function being too small for the quarterly data.\n\nbat_q121_kde&lt;- density(battlesQ121_ppp_com, sigma=bw.ppl(battlesQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nbat_q221_kde&lt;-density(battlesQ221_ppp_com, sigma=bw.ppl(battlesQ221_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q321_kde&lt;-density(battlesQ321_ppp_com, sigma=bw.ppl(battlesQ321_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q421_kde&lt;-density(battlesQ421_ppp_com, sigma=bw.ppl(battlesQ421_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(bat_q121_kde, main=\"Battles in 1st Quarter of 2021\")\nplot(bat_q221_kde, main=\"Battles in 2nd Quarter of 2021\")\nplot(bat_q321_kde, main=\"Battles in 3rd Quarter of 2021\")\nplot(bat_q421_kde, main=\"Battles in 4th Quarter of 2021\")\n\n\n\n\n\n\n\n\nHence, I decided to try the bw.CvL() method, as it is similar to the bw.ppl() method, just with a minimised prediction error. When I plotted the maps, I was satisified with the result, and chose this as the method to go with.\n\nBattlesExplosionsStrategic DevelopmentsViolence against Civilians\n\n\n\n2021202220232024\n\n\n\nbat_q121_kde&lt;- density(battlesQ121_ppp_com, sigma=bw.CvL(battlesQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nbat_q221_kde&lt;-density(battlesQ221_ppp_com, sigma=bw.CvL(battlesQ221_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q321_kde&lt;-density(battlesQ321_ppp_com, sigma=bw.CvL(battlesQ321_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q421_kde&lt;-density(battlesQ421_ppp_com, sigma=bw.CvL(battlesQ421_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(bat_q121_kde, main=\"Battles in 1st Quarter of 2021\")\nplot(bat_q221_kde, main=\"Battles in 2nd Quarter of 2021\")\nplot(bat_q321_kde, main=\"Battles in 3rd Quarter of 2021\")\nplot(bat_q421_kde, main=\"Battles in 4th Quarter of 2021\")\n\n\n\n\n\n\n\n\n\n\n\nbat_q122_kde&lt;- density(battlesQ122_ppp_com, sigma=bw.CvL(battlesQ122_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nbat_q222_kde&lt;-density(battlesQ222_ppp_com, sigma=bw.CvL(battlesQ222_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q322_kde&lt;-density(battlesQ322_ppp_com, sigma=bw.CvL(battlesQ322_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q422_kde&lt;-density(battlesQ422_ppp_com, sigma=bw.CvL(battlesQ422_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(bat_q122_kde, main=\"Battles in 1st Quarter of 2022\")\nplot(bat_q222_kde, main=\"Battles in 2nd Quarter of 2022\")\nplot(bat_q322_kde, main=\"Battles in 3rd Quarter of 2022\")\nplot(bat_q422_kde, main=\"Battles in 4th Quarter of 2022\")\n\n\n\n\n\n\n\n\n\n\n\nbat_q123_kde&lt;- density(battlesQ123_ppp_com, sigma=bw.CvL(battlesQ123_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nbat_q223_kde&lt;-density(battlesQ223_ppp_com, sigma=bw.CvL(battlesQ223_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q323_kde&lt;-density(battlesQ323_ppp_com, sigma=bw.CvL(battlesQ323_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nbat_q423_kde&lt;-density(battlesQ423_ppp_com, sigma=bw.CvL(battlesQ423_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(bat_q123_kde, main=\"Battles in 1st Quarter of 2023\")\nplot(bat_q223_kde, main=\"Battles in 2nd Quarter of 2023\")\nplot(bat_q323_kde, main=\"Battles in 3rd Quarter of 2023\")\nplot(bat_q423_kde, main=\"Battles in 4th Quarter of 2023\")\n\n\n\n\n\n\n\n\n\n\n\nbat_q124_kde&lt;- density(battlesQ124_ppp_com, sigma=bw.CvL(battlesQ124_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nbat_q224_kde&lt;-density(battlesQ224_ppp_com, sigma=bw.CvL(battlesQ224_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(1,2))\nplot(bat_q124_kde, main=\"Battles in 1st Quarter of 2024\")\nplot(bat_q224_kde, main=\"Battles in 2nd Quarter of 2024\")\n\n\n\n\n\n\n\n\n\n\n\nFor Battles, we see that the conflicts have slowly travelled to the center (Mandalay, Magwe Divisions) from the North-East (Kachin and Shan states) throughout the years 2021-2023. It also spread southward (Mon and Tenesserium States). This is due to the onset of a Military coup in Myanmar, resulting in violence in various parts of the land, including the central regions of Mandalay and Yangon (Maizland, 2022). Intensity of Battles saw a sharp decline from the last quarter of 2023 to the first two quarters of 2024.\n\n\n\n2021202220232024\n\n\n\nexp_q121_kde&lt;- density(expQ121_ppp_com, sigma=bw.CvL(expQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nexp_q221_kde&lt;-density(expQ221_ppp_com, sigma=bw.CvL(expQ221_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nexp_q321_kde&lt;-density(expQ321_ppp_com, sigma=bw.CvL(expQ321_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nexp_q421_kde&lt;-density(expQ421_ppp_com, sigma=bw.CvL(expQ421_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(exp_q121_kde, main=\"Explosions in 1st Quarter of 2021\")\nplot(exp_q221_kde, main=\"Explosions in 2nd Quarter of 2021\")\nplot(exp_q321_kde, main=\"Explosions in 3rd Quarter of 2021\")\nplot(exp_q421_kde, main=\"Explosions in 4th Quarter of 2021\")\n\n\n\n\n\n\n\n\n\n\n\nexp_q122_kde&lt;- density(expQ122_ppp_com, sigma=bw.CvL(expQ122_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nexp_q222_kde&lt;-density(expQ222_ppp_com, sigma=bw.CvL(expQ222_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nexp_q322_kde&lt;-density(expQ322_ppp_com, sigma=bw.CvL(expQ322_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nexp_q422_kde&lt;-density(expQ422_ppp_com, sigma=bw.CvL(expQ422_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(exp_q122_kde, main=\"Explosions in 1st Quarter of 2022\")\nplot(exp_q222_kde, main=\"Explosions in 2nd Quarter of 2022\")\nplot(exp_q322_kde, main=\"Explosions in 3rd Quarter of 2022\")\nplot(exp_q422_kde, main=\"Explosions in 4th Quarter of 2022\")\n\n\n\n\n\n\n\n\n\n\n\nexp_q123_kde&lt;- density(expQ123_ppp_com, sigma=bw.CvL(expQ123_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nexp_q223_kde&lt;-density(expQ223_ppp_com, sigma=bw.CvL(expQ223_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nexp_q323_kde&lt;-density(expQ323_ppp_com, sigma=bw.CvL(expQ323_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nexp_q423_kde&lt;-density(expQ423_ppp_com, sigma=bw.CvL(expQ423_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(exp_q123_kde, main=\"Explosions in 1st Quarter of 2023\")\nplot(exp_q223_kde, main=\"Explosions in 2nd Quarter of 2023\")\nplot(exp_q323_kde, main=\"Explosions in 3rd Quarter of 2023\")\nplot(exp_q423_kde, main=\"Explosions in 4th Quarter of 2023\")\n\n\n\n\n\n\n\n\n\n\n\nexp_q124_kde&lt;- density(expQ124_ppp_com, sigma=bw.CvL(expQ124_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nexp_q224_kde&lt;-density(expQ224_ppp_com, sigma=bw.CvL(expQ224_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\n\npar(mfrow=c(1,2))\nplot(exp_q124_kde, main=\"Explosions in 1st Quarter of 2024\")\nplot(exp_q224_kde, main=\"Explosions in 2nd Quarter of 2024\")\n\n\n\n\n\n\n\n\n\n\n\nAs for Explosions, we see that it peaked in intensity in 2022-2023, and was also concentrated in the central regions of Myanmar.\n\n\n\n2021202220232024\n\n\n\nstrat_dev_q121_kde&lt;- density(strat_devQ121_ppp_com, sigma=bw.CvL(strat_devQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nstrat_dev_q221_kde&lt;-density(strat_devQ221_ppp_com, sigma=bw.CvL(strat_devQ221_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nstrat_dev_q321_kde&lt;-density(strat_devQ321_ppp_com, sigma=bw.CvL(strat_devQ321_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nstrat_dev_q421_kde&lt;-density(strat_devQ421_ppp_com, sigma=bw.CvL(strat_devQ421_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(strat_dev_q121_kde, main=\"Strategic Developments in 1st Quarter of 2021\")\nplot(strat_dev_q221_kde, main=\"Strategic Developments in 2nd Quarter of 2021\")\nplot(strat_dev_q321_kde, main=\"Strategic Developments in 3rd Quarter of 2021\")\nplot(strat_dev_q421_kde, main=\"Strategic Developments in 4th Quarter of 2021\")\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_q122_kde&lt;- density(strat_devQ122_ppp_com, sigma=bw.CvL(strat_devQ122_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nstrat_dev_q222_kde&lt;-density(strat_devQ222_ppp_com, sigma=bw.CvL(strat_devQ222_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nstrat_dev_q322_kde&lt;-density(strat_devQ322_ppp_com, sigma=bw.CvL(strat_devQ322_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nstrat_dev_q422_kde&lt;-density(strat_devQ422_ppp_com, sigma=bw.CvL(strat_devQ422_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(strat_dev_q122_kde, main=\"Strategic Developments in 1st Quarter of 2022\")\nplot(strat_dev_q222_kde, main=\"Strategic Developments in 2nd Quarter of 2022\")\nplot(strat_dev_q322_kde, main=\"Strategic Developments in 3rd Quarter of 2022\")\nplot(strat_dev_q422_kde, main=\"Strategic Developments in 4th Quarter of 2022\")\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_q123_kde&lt;- density(strat_devQ123_ppp_com, sigma=bw.CvL(strat_devQ123_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nstrat_dev_q223_kde&lt;-density(strat_devQ223_ppp_com, sigma=bw.CvL(strat_devQ223_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nstrat_dev_q323_kde&lt;-density(strat_devQ323_ppp_com, sigma=bw.CvL(strat_devQ323_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\nstrat_dev_q423_kde&lt;-density(strat_devQ423_ppp_com, sigma=bw.CvL(strat_devQ423_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(strat_dev_q123_kde, main=\"Strategic Developments in 1st Quarter of 2023\")\nplot(strat_dev_q223_kde, main=\"Strategic Developments in 2nd Quarter of 2023\")\nplot(strat_dev_q323_kde, main=\"Strategic Developments in 3rd Quarter of 2023\")\nplot(strat_dev_q423_kde, main=\"Strategic Developments in 4th Quarter of 2023\")\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_q124_kde&lt;- density(strat_devQ124_ppp_com, sigma=bw.CvL(strat_devQ124_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\nstrat_dev_q224_kde&lt;-density(strat_devQ224_ppp_com, sigma=bw.CvL(strat_devQ224_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\n\npar(mfrow=c(1,2))\nplot(strat_dev_q124_kde, main=\"Strategic Developments in 1st Quarter of 2024\")\nplot(strat_dev_q224_kde, main=\"Strategic Developments in 2nd Quarter of 2024\")\n\n\n\n\n\n\n\n\n\n\n\nStrategic Developments seem to still be ongoing even as late as the 2nd quarter of this year, after having increased in 2022. It is also to be noted that as for Strategic Developments, it is only concentrated in the central regions of Myanmar and not so much on the outskirts.\n\n\n\n2021202220232024\n\n\n\ncivViolence_q121_kde&lt;- density(civViolenceQ121_ppp_com, sigma=bw.CvL(civViolenceQ121_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\ncivViolence_q221_kde&lt;-density(civViolenceQ221_ppp_com, sigma=bw.CvL(civViolenceQ221_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\ncivViolence_q321_kde&lt;-density(civViolenceQ321_ppp_com, sigma=bw.CvL(civViolenceQ321_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\ncivViolence_q421_kde&lt;-density(civViolenceQ421_ppp_com, sigma=bw.CvL(civViolenceQ421_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(civViolence_q121_kde, main=\"Violence Against Civilians in 1st Quarter of 2021\")\nplot(civViolence_q221_kde, main=\"Violence Against Civilians in 2nd Quarter of 2021\")\nplot(civViolence_q321_kde, main=\"Violence Against Civilians in 3rd Quarter of 2021\")\nplot(civViolence_q421_kde, main=\"Violence Against Civilians in 4th Quarter of 2021\")\n\n\n\n\n\n\n\n\n\n\n\ncivViolence_q122_kde&lt;- density(civViolenceQ122_ppp_com, sigma=bw.CvL(civViolenceQ122_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\ncivViolence_q222_kde&lt;-density(civViolenceQ222_ppp_com, sigma=bw.CvL(civViolenceQ222_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\ncivViolence_q322_kde&lt;-density(civViolenceQ322_ppp_com, sigma=bw.CvL(civViolenceQ322_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\ncivViolence_q422_kde&lt;-density(civViolenceQ422_ppp_com, sigma=bw.CvL(civViolenceQ422_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(civViolence_q122_kde, main=\"Violence Against Civilians in 1st Quarter of 2022\")\nplot(civViolence_q222_kde, main=\"Violence Against Civilians in 2nd Quarter of 2022\")\nplot(civViolence_q322_kde, main=\"Violence Against Civilians in 3rd Quarter of 2022\")\nplot(civViolence_q422_kde, main=\"Violence Against Civilians in 4th Quarter of 2022\")\n\n\n\n\n\n\n\n\n\n\n\ncivViolence_q123_kde&lt;- density(civViolenceQ123_ppp_com, sigma=bw.CvL(civViolenceQ123_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\ncivViolence_q223_kde&lt;-density(civViolenceQ223_ppp_com, sigma=bw.CvL(civViolenceQ223_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\ncivViolence_q323_kde&lt;-density(civViolenceQ323_ppp_com, sigma=bw.CvL(civViolenceQ323_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\ncivViolence_q423_kde&lt;-density(civViolenceQ423_ppp_com, sigma=bw.CvL(civViolenceQ423_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\npar(mfrow=c(2,2))\nplot(civViolence_q123_kde, main=\"Violence Against Civilians in 1st Quarter of 2023\")\nplot(civViolence_q223_kde, main=\"Violence Against Civilians in 2nd Quarter of 2023\")\nplot(civViolence_q323_kde, main=\"Violence Against Civilians in 3rd Quarter of 2023\")\nplot(civViolence_q423_kde, main=\"Violence Against Civilians in 4th Quarter of 2023\")\n\n\n\n\n\n\n\n\n\n\n\ncivViolence_q124_kde&lt;- density(civViolenceQ124_ppp_com, sigma=bw.CvL(civViolenceQ124_ppp_com), edge=TRUE, kernel=\"gaussian\") \n\ncivViolence_q224_kde&lt;-density(civViolenceQ224_ppp_com, sigma=bw.CvL(civViolenceQ224_ppp_com), edge=TRUE, kernel=\"gaussian\")\n\n\n\npar(mfrow=c(1,2))\nplot(civViolence_q124_kde, main=\"Violence Against Civilians in 1st Quarter of 2024\")\nplot(civViolence_q224_kde, main=\"Violence Against Civilians in 2nd Quarter of 2024\")\n\n\n\n\n\n\n\n\n\n\n\nViolence Against the civilians can be observed in the central and southern regions of Myanmar througout all the quarters, with the concentration once again, being at the central region. There appears to be a brief reduction in the intensity of the attacks in the 3rd quarter of 2022."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#computing-second-order-spatial-point-process-analysis",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#computing-second-order-spatial-point-process-analysis",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.4 Computing Second Order Spatial point Process analysis",
    "text": "1.4 Computing Second Order Spatial point Process analysis\nIn this section, I will be computing the quarterly second order spatial point process analysis for each of the conflict types. I will be using the K- function to compute the analysis. This is because as seen from our KDE layers, density of points are on different scales for the different quarters and the K-function will allow us to analyse the spatial point with different scales.\n\nBattlesExplosions\n\n\n\n\n\n\n\n\n\n\n\nexp_ppp&lt;- as.ppp(st_coordinates(exp_sf), st_bbox(exp_sf))\n\nWarning: data contain duplicated points\n\nexp_ppp_com&lt;- exp_ppp[boundary_owin]\nexp_ppp_com&lt;-rescale(exp_ppp_com, 1000, 'km')\n\n\nexp_g = Gest(exp_ppp_com) \nexp_g.csr &lt;- envelope(exp_ppp_com, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, \n[14:11 remaining, estimate finish 2024-09-22 19:00:58]\n3, \n[14:43 remaining, estimate finish 2024-09-22 19:01:40]\n4, \n[14:26 remaining, estimate finish 2024-09-22 19:01:32]\n5, \n[14:18 remaining, estimate finish 2024-09-22 19:01:33]\n6, \n[13:59 remaining, estimate finish 2024-09-22 19:01:23]\n7, \n[13:43 remaining, estimate finish 2024-09-22 19:01:16]\n8, \n[13:30 remaining, estimate finish 2024-09-22 19:01:11]\n9, \n[13:17 remaining, estimate finish 2024-09-22 19:01:07]\n10, \n[13:06 remaining, estimate finish 2024-09-22 19:01:04]\n11, \n[12:55 remaining, estimate finish 2024-09-22 19:01:01]\n12, \n[12:46 remaining, estimate finish 2024-09-22 19:01:02]\n13, \n[12:37 remaining, estimate finish 2024-09-22 19:01:02]\n14, \n[12:27 remaining, estimate finish 2024-09-22 19:01:00]\n15, \n[12:19 remaining, estimate finish 2024-09-22 19:01:01]\n16, \n[12:11 remaining, estimate finish 2024-09-22 19:01:01]\n17, \n[12:01 remaining, estimate finish 2024-09-22 19:01:00]\n18, \n[11:52 remaining, estimate finish 2024-09-22 19:01:00]\n19, \n[11:42 remaining, estimate finish 2024-09-22 19:00:59]\n20, \n[11:33 remaining, estimate finish 2024-09-22 19:00:59]\n21, \n[11:25 remaining, estimate finish 2024-09-22 19:00:59]\n22, \n[11:16 remaining, estimate finish 2024-09-22 19:00:59]\n23, \n[11:08 remaining, estimate finish 2024-09-22 19:01:00]\n24, \n[10:59 remaining, estimate finish 2024-09-22 19:01:00]\n25, \n[10:50 remaining, estimate finish 2024-09-22 19:01:00]\n26, \n[11:09 remaining, estimate finish 2024-09-22 19:01:37]\n27, \n[11:34 remaining, estimate finish 2024-09-22 19:02:23]\n28, \n[11:31 remaining, estimate finish 2024-09-22 19:02:32]\n29, \n[11:54 remaining, estimate finish 2024-09-22 19:03:18]\n30, \n[12:12 remaining, estimate finish 2024-09-22 19:03:59]\n31, \n[12:31 remaining, estimate finish 2024-09-22 19:04:42]\n32, \n[12:29 remaining, estimate finish 2024-09-22 19:04:54]\n33, \n[12:14 remaining, estimate finish 2024-09-22 19:04:49]\n34, \n[12:00 remaining, estimate finish 2024-09-22 19:04:44]\n35, \n[11:54 remaining, estimate finish 2024-09-22 19:04:53]\n36, \n[11:47 remaining, estimate finish 2024-09-22 19:04:58]\n37, \n[11:47 remaining, estimate finish 2024-09-22 19:05:17]\n38, \n[11:48 remaining, estimate finish 2024-09-22 19:05:36]\n39, \n[11:50 remaining, estimate finish 2024-09-22 19:05:58]\n40, \n[11:36 remaining, estimate finish 2024-09-22 19:05:55]\n41, \n[11:21 remaining, estimate finish 2024-09-22 19:05:49]\n42, \n[11:06 remaining, estimate finish 2024-09-22 19:05:43]\n43, \n[10:51 remaining, estimate finish 2024-09-22 19:05:37]\n44, \n[10:35 remaining, estimate finish 2024-09-22 19:05:30]\n45, \n[10:20 remaining, estimate finish 2024-09-22 19:05:24]\n46, \n[10:07 remaining, estimate finish 2024-09-22 19:05:21]\n47, \n[10:07 remaining, estimate finish 2024-09-22 19:05:43]\n48, \n[10:07 remaining, estimate finish 2024-09-22 19:06:05]\n49, \n[10:07 remaining, estimate finish 2024-09-22 19:06:28]\n50, \n[10:05 remaining, estimate finish 2024-09-22 19:06:49]\n51,  [9:51 remaining] 52,  [9:41 remaining] 53,  [9:37 remaining] 54,  [9:33 remaining] 55,  [9:23 remaining] 56,  [9:07 remaining] 57,  [8:51 remaining] 58,  [8:41 remaining] 59,  [8:35 remaining] 60,  [8:27 remaining] 61,  [8:11 remaining] 62,  [7:55 remaining] 63,  [7:40 remaining] 64,  [7:24 remaining] 65,  [7:09 remaining] 66,  [6:55 remaining] 67,  [6:40 remaining] 68,  [6:26 remaining] 69,  [6:12 remaining] 70,\n [6:01 remaining] 71,  [5:52 remaining] 72,  [5:43 remaining] 73,  [5:35 remaining] 74,  [5:21 remaining] 75,  [5:06 remaining] 76,  [4:52 remaining] 77,  [4:39 remaining] 78,  [4:25 remaining] 79,  [4:11 remaining] 80,  [3:58 remaining] 81,  [3:45 remaining] 82,  [3:31 remaining] 83,  [3:18 remaining] 84,  [3:05 remaining] 85,  [2:52 remaining] 86,  [2:39 remaining] 87,  [2:28 remaining] 88,  [2:16 remaining] 89,  [2:03 remaining] 90,\n [1:50 remaining] 91,  [1:38 remaining] 92,  [1:25 remaining] 93,  [1:13 remaining] 94,  [1:01 remaining] 95,  [49 sec remaining] 96,  [37 sec remaining] 97,  [25 sec remaining] 98,  [13 sec remaining] \n99.\n\nDone.\n\nplot(exp_g.csr)\n\n\n\n\n\n\n\n\n\nStrategic Developments\n\nstrat_dev_ppp&lt;- as.ppp(st_coordinates(strat_dev_sf), st_bbox(strat_dev_sf))\n\nWarning: data contain duplicated points\n\nstrat_dev_ppp_com&lt;- strat_dev_ppp[boundary_owin]\nstrat_dev_ppp_com&lt;-rescale(strat_dev_ppp_com, 1000, 'km')\n\n\nstrat_dev_g = Gest(strat_dev_ppp_com) \nstrat_dev_g.csr &lt;- envelope(strat_dev_ppp_com, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, \n[35:55 remaining, estimate finish 2024-09-22 19:44:36]\n3, \n[38:36 remaining, estimate finish 2024-09-22 19:47:42]\n4, \n[38:31 remaining, estimate finish 2024-09-22 19:48:02]\n5, \n[38:42 remaining, estimate finish 2024-09-22 19:48:39]\n6, \n[38:18 remaining, estimate finish 2024-09-22 19:48:40]\n7, \n[38:07 remaining, estimate finish 2024-09-22 19:48:55]\n8, \n[37:14 remaining, estimate finish 2024-09-22 19:48:24]\n9, \n[37:07 remaining, estimate finish 2024-09-22 19:48:43]\n10, \n[36:50 remaining, estimate finish 2024-09-22 19:48:51]\n11, \n[36:34 remaining, estimate finish 2024-09-22 19:49:01]\n12, \n[36:16 remaining, estimate finish 2024-09-22 19:49:10]\n13, \n[35:18 remaining, estimate finish 2024-09-22 19:48:32]\n14, \n[33:10 remaining, estimate finish 2024-09-22 19:46:33]\n15, \n[31:22 remaining, estimate finish 2024-09-22 19:44:54]\n16, \n[29:48 remaining, estimate finish 2024-09-22 19:43:29]\n17, \n[28:24 remaining, estimate finish 2024-09-22 19:42:15]\n18, \n[27:06 remaining, estimate finish 2024-09-22 19:41:06]\n19, \n[25:56 remaining, estimate finish 2024-09-22 19:40:04]\n20, \n[24:52 remaining, estimate finish 2024-09-22 19:39:10]\n21, \n[23:55 remaining, estimate finish 2024-09-22 19:38:22]\n22, \n[23:02 remaining, estimate finish 2024-09-22 19:37:37]\n23, \n[22:12 remaining, estimate finish 2024-09-22 19:36:56]\n24, \n[21:27 remaining, estimate finish 2024-09-22 19:36:19]\n25, \n[20:43 remaining, estimate finish 2024-09-22 19:35:45]\n26, \n[20:03 remaining, estimate finish 2024-09-22 19:35:13]\n27, \n[19:26 remaining, estimate finish 2024-09-22 19:34:45]\n28, \n[18:51 remaining, estimate finish 2024-09-22 19:34:19]\n29, \n[18:17 remaining, estimate finish 2024-09-22 19:33:54]\n30, \n[17:44 remaining, estimate finish 2024-09-22 19:33:30]\n31, \n[17:14 remaining, estimate finish 2024-09-22 19:33:08]\n32, \n[16:45 remaining, estimate finish 2024-09-22 19:32:49]\n33, \n[16:18 remaining, estimate finish 2024-09-22 19:32:30]\n34, \n[15:53 remaining, estimate finish 2024-09-22 19:32:15]\n35, \n[15:31 remaining, estimate finish 2024-09-22 19:32:03]\n36, \n[15:08 remaining, estimate finish 2024-09-22 19:31:51]\n37, \n[14:45 remaining, estimate finish 2024-09-22 19:31:37]\n38, \n[14:23 remaining, estimate finish 2024-09-22 19:31:24]\n39, \n[14:25 remaining, estimate finish 2024-09-22 19:31:51]\n40, \n[14:27 remaining, estimate finish 2024-09-22 19:32:19]\n41, \n[14:24 remaining, estimate finish 2024-09-22 19:32:39]\n42, \n[14:23 remaining, estimate finish 2024-09-22 19:33:01]\n43, \n[14:12 remaining, estimate finish 2024-09-22 19:33:09]\n44, \n[14:00 remaining, estimate finish 2024-09-22 19:33:15]\n45, \n[13:57 remaining, estimate finish 2024-09-22 19:33:37]\n46, \n[13:53 remaining, estimate finish 2024-09-22 19:33:58]\n47, \n[13:44 remaining, estimate finish 2024-09-22 19:34:11]\n48, \n[13:21 remaining, estimate finish 2024-09-22 19:33:57]\n49, \n[13:00 remaining, estimate finish 2024-09-22 19:33:47]\n50, \n[12:55 remaining, estimate finish 2024-09-22 19:34:07]\n51, \n[12:46 remaining, estimate finish 2024-09-22 19:34:22]\n52, \n[12:37 remaining, estimate finish 2024-09-22 19:34:38]\n53, \n[12:28 remaining, estimate finish 2024-09-22 19:34:52]\n54, \n[12:13 remaining, estimate finish 2024-09-22 19:34:55]\n55, \n[11:51 remaining, estimate finish 2024-09-22 19:34:42]\n56, \n[11:29 remaining, estimate finish 2024-09-22 19:34:29]\n57, \n[11:08 remaining, estimate finish 2024-09-22 19:34:16]\n58, \n[10:47 remaining, estimate finish 2024-09-22 19:34:04]\n59, \n[10:26 remaining, estimate finish 2024-09-22 19:33:53]\n60, \n[10:06 remaining, estimate finish 2024-09-22 19:33:41]\n61,  [9:46 remaining] 62,  [9:32 remaining] 63,  [9:22 remaining] 64,  [9:06 remaining] 65,  [8:54 remaining] 66,  [8:44 remaining] 67,  [8:32 remaining] 68,  [8:18 remaining] 69,  [7:59 remaining] 70,  [7:40 remaining] 71,  [7:21 remaining] 72,  [7:09 remaining] 73,  [6:56 remaining] 74,  [6:43 remaining] 75,  [6:29 remaining] 76,  [6:16 remaining] 77,  [6:02 remaining] 78,  [5:48 remaining] 79,  [5:29 remaining] 80,\n [5:11 remaining] 81,  [4:53 remaining] 82,  [4:35 remaining] 83,  [4:17 remaining] 84,  [4:00 remaining] 85,  [3:43 remaining] 86,  [3:28 remaining] 87,  [3:13 remaining] 88,  [2:56 remaining] 89,  [2:40 remaining] 90,  [2:25 remaining] 91,  [2:09 remaining] 92,  [1:52 remaining] 93,  [1:35 remaining] 94,  [1:19 remaining] 95,  [1:03 remaining] 96,  [47 sec remaining] 97,  [31 sec remaining] 98,  [16 sec remaining] \n99.\n\nDone.\n\nplot(strat_dev_g.csr)\n\n\n\n\n\n\n\n\n\n\nCivilian Violence\n\ncivViolence_ppp&lt;- as.ppp(st_coordinates(civViolence_sf), st_bbox(civViolence_sf))\n\nWarning: data contain duplicated points\n\ncivViolence_ppp_com&lt;- civViolence_ppp[boundary_owin]\ncivViolence_ppp_com&lt;-rescale(civViolence_ppp_com, 1000, 'km')\n\n\ncivViolence_g.csr &lt;- envelope(civViolence_ppp_com, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [7:54 remaining] 3,\n [7:52 remaining] 4,  [7:39 remaining] 5,  [7:34 remaining] 6,\n [7:21 remaining] 7,  [7:16 remaining] 8,  [7:55 remaining] 9,\n [7:58 remaining] 10,  [8:45 remaining] 11,  [9:46 remaining] 12,\n\n[10:28 remaining, estimate finish 2024-09-22 19:45:33]\n13, \n[10:48 remaining, estimate finish 2024-09-22 19:46:05]\n14, \n[11:21 remaining, estimate finish 2024-09-22 19:46:51]\n15, \n[10:52 remaining, estimate finish 2024-09-22 19:46:27]\n16, \n[10:26 remaining, estimate finish 2024-09-22 19:46:06]\n17, \n[10:04 remaining, estimate finish 2024-09-22 19:45:49]\n18,  [9:46 remaining] 19,  [9:27 remaining] 20,\n [9:10 remaining] 21,  [8:56 remaining] 22,  [8:42 remaining] 23,\n [8:45 remaining] 24,  [9:00 remaining] 25,  [9:08 remaining] 26,\n [8:52 remaining] 27,  [8:58 remaining] 28,  [9:06 remaining] 29,\n [9:09 remaining] 30,  [9:13 remaining] 31,  [9:16 remaining] 32,\n [9:18 remaining] 33,  [9:21 remaining] 34,  [9:21 remaining] 35,\n [9:12 remaining] 36,  [8:56 remaining] 37,  [8:41 remaining] 38,\n [8:27 remaining] 39,  [8:13 remaining] 40,  [8:00 remaining] 41,\n [7:47 remaining] 42,  [7:34 remaining] 43,  [7:22 remaining] 44,\n [7:10 remaining] 45,  [6:58 remaining] 46,  [6:47 remaining] 47,\n [6:42 remaining] 48,  [6:41 remaining] 49,  [6:39 remaining] 50,\n [6:36 remaining] 51,  [6:33 remaining] 52,  [6:30 remaining] 53,\n [6:27 remaining] 54,  [6:23 remaining] 55,  [6:18 remaining] 56,\n [6:13 remaining] 57,  [6:08 remaining] 58,  [6:03 remaining] 59,\n [5:57 remaining] 60,  [5:51 remaining] 61,  [5:45 remaining] 62,\n [5:38 remaining] 63,  [5:32 remaining] 64,  [5:25 remaining] 65,\n [5:17 remaining] 66,  [5:10 remaining] 67,  [5:03 remaining] 68,\n [4:55 remaining] 69,  [4:43 remaining] 70,  [4:32 remaining] 71,\n [4:21 remaining] 72,  [4:10 remaining] 73,  [3:59 remaining] 74,\n [3:48 remaining] 75,  [3:37 remaining] 76,  [3:27 remaining] 77,\n [3:17 remaining] 78,  [3:06 remaining] 79,  [2:56 remaining] 80,\n [2:47 remaining] 81,  [2:37 remaining] 82,  [2:27 remaining] 83,\n [2:18 remaining] 84,  [2:08 remaining] 85,  [1:59 remaining] 86,\n [1:50 remaining] 87,  [1:41 remaining] 88,  [1:32 remaining] 89,\n [1:24 remaining] 90,  [1:15 remaining] 91,  [1:06 remaining] 92,\n [58 sec remaining] 93,  [50 sec remaining] 94,  [42 sec remaining] 95,\n [33 sec remaining] 96,  [25 sec remaining] 97,  [17 sec remaining] 98,\n [9 sec remaining] \n99.\n\nDone.\n\nplot(civViolence_g.csr)\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the plots above, we can further confirm that there is significant clustering of the spatial points for all four conflict types. This is because the black line (the observed G-function of our data) is well above the red dashed line (which indicates G function under Complete Spatial Randomness). This means that the pattern observed in the dataset differs significantly from the pattern of randomly spaced points, indicating the presence of clusters."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#computing-spatio-temporal-kde-layers",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#computing-spatio-temporal-kde-layers",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.5 Computing Spatio-Temporal KDE Layers",
    "text": "1.5 Computing Spatio-Temporal KDE Layers\n\nBattlesExplosionsStrategic DevelopmentsViolence Against Civilians\n\n\n\n2021202220232024\n\n\n\nbattle_st_21&lt;- quart_geo_bat %&gt;% \n  filter(year==\"2021\") %&gt;% \n  select(2,3)\n\nbattle_21_ppp&lt;- as.ppp(battle_st_21, coordinates=battle_st_21)\nbattle_21_owin&lt;- battle_21_ppp[boundary_owin]\n\nbattles_st_21_kde&lt;- spattemp.density(battle_21_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(battle_st_21$num_quarters)\n\n\nfor (i in tims2){\n  plot(battles_st_21_kde, i,\n  main = paste('STKDE of Q', i, \" 2021\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbattle_st_22&lt;- quart_geo_bat %&gt;% \n  filter(year==\"2022\") %&gt;% \n  select(2,3)\n\nbattle_22_ppp&lt;- as.ppp(battle_st_22, coordinates=battle_st_22)\nbattle_22_owin&lt;- battle_22_ppp[boundary_owin]\n\nbattles_st_22_kde&lt;- spattemp.density(battle_22_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nfor (i in tims2){\n  plot(battles_st_22_kde, i,\n  main = paste('STKDE of Q', i, \" 2022\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbattle_st_23&lt;- quart_geo_bat %&gt;% \n  filter(year==\"2023\") %&gt;% \n  select(2,3)\n\nbattle_23_ppp&lt;- as.ppp(battle_st_23, coordinates=battle_st_23)\nbattle_23_owin&lt;- battle_23_ppp[boundary_owin]\n\nbattles_st_23_kde&lt;- spattemp.density(battle_23_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nfor (i in tims2){\n  plot(battles_st_23_kde, i,\n  main = paste('STKDE of Q', i, \" 2023\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbattle_st_24&lt;- quart_geo_bat %&gt;% \n  filter(year==\"2024\") %&gt;% \n  select(2,3)\n\nbattle_24_ppp&lt;- as.ppp(battle_st_24, coordinates=battle_st_24)\nbattle_24_owin&lt;- battle_24_ppp[boundary_owin]\n\nbattles_st_24_kde&lt;- spattemp.density(battle_24_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(battle_st_24$num_quarters)\n\nfor (i in tims2){\n  plot(battles_st_24_kde, i,\n  main = paste('STKDE of Q', i, \" 2024\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021202220232024\n\n\n\nExp_st_21&lt;- quart_geo_exp %&gt;% \n  filter(year==\"2021\") %&gt;% \n  select(2,3)\n\nExp_21_ppp&lt;- as.ppp(Exp_st_21, coordinates=Exp_st_21)\nExp_21_owin&lt;- Exp_21_ppp[boundary_owin]\n\nExp_st_21_kde&lt;- spattemp.density(Exp_21_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(Exp_st_21$num_quarters)\n\n\nfor (i in tims2){\n  plot(Exp_st_21_kde, i,\n  main = paste('STKDE of Q', i, \" 2021\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExp_st_22&lt;- quart_geo_exp %&gt;% \n  filter(year==\"2022\") %&gt;% \n  select(2,3)\n\nExp_22_ppp&lt;- as.ppp(Exp_st_22, coordinates=Exp_st_22)\nExp_22_owin&lt;- Exp_22_ppp[boundary_owin]\n\nExp_st_22_kde&lt;- spattemp.density(Exp_22_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(Exp_st_22$num_quarters)\n\n\nfor (i in tims2){\n  plot(Exp_st_22_kde, i,\n  main = paste('STKDE of Q', i, \" 2022\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExp_st_23&lt;- quart_geo_exp %&gt;% \n  filter(year==\"2023\") %&gt;% \n  select(2,3)\n\nExp_23_ppp&lt;- as.ppp(Exp_st_23, coordinates=Exp_st_23)\nExp_23_owin&lt;- Exp_23_ppp[boundary_owin]\n\nExp_st_23_kde&lt;- spattemp.density(Exp_23_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(Exp_st_23$num_quarters)\n\n\nfor (i in tims2){\n  plot(Exp_st_23_kde, i,\n  main = paste('STKDE of Q', i, \" 2023\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExp_st_24&lt;- quart_geo_exp %&gt;% \n  filter(year==\"2024\") %&gt;% \n  select(2,3)\n\nExp_24_ppp&lt;- as.ppp(Exp_st_24, coordinates=Exp_st_24)\nExp_24_owin&lt;- Exp_24_ppp[boundary_owin]\n\nExp_st_24_kde&lt;- spattemp.density(Exp_24_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(Exp_st_24$num_quarters)\n\nfor (i in tims2){\n  plot(Exp_st_24_kde, i,\n  main = paste('STKDE of Q', i, \" 2024\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021202220232024\n\n\n\nstrat_dev_st_21&lt;- quart_geo_strat %&gt;% \n  filter(year==\"2021\") %&gt;% \n  select(2,3)\n\nstrat_dev_21_ppp&lt;- as.ppp(strat_dev_st_21, coordinates=strat_dev_st_21)\nstrat_dev_21_owin&lt;- strat_dev_21_ppp[boundary_owin]\n\nstrat_dev_st_21_kde&lt;- spattemp.density(strat_dev_21_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(strat_dev_st_21$num_quarters)\n\n\nfor (i in tims2){\n  plot(strat_dev_st_21_kde, i,\n  main = paste('STKDE of Q', i, \" 2021\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_st_22&lt;- quart_geo_strat %&gt;% \n  filter(year==\"2022\") %&gt;% \n  select(2,3)\n\nstrat_dev_22_ppp&lt;- as.ppp(strat_dev_st_22, coordinates=strat_dev_st_22)\nstrat_dev_22_owin&lt;- strat_dev_22_ppp[boundary_owin]\n\nstrat_dev_st_22_kde&lt;- spattemp.density(strat_dev_22_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(strat_dev_st_22$num_quarters)\n\n\nfor (i in tims2){\n  plot(strat_dev_st_22_kde, i,\n  main = paste('STKDE of Q', i, \" 2022\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_st_23&lt;- quart_geo_strat %&gt;% \n  filter(year==\"2023\") %&gt;% \n  select(2,3)\n\nstrat_dev_23_ppp&lt;- as.ppp(strat_dev_st_23, coordinates=strat_dev_st_23)\nstrat_dev_23_owin&lt;- strat_dev_23_ppp[boundary_owin]\n\nstrat_dev_st_23_kde&lt;- spattemp.density(strat_dev_23_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(strat_dev_st_23$num_quarters)\n\n\nfor (i in tims2){\n  plot(strat_dev_st_23_kde, i,\n  main = paste('STKDE of Q', i, \" 2023\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_st_24&lt;- quart_geo_strat %&gt;% \n  filter(year==\"2024\") %&gt;% \n  select(2,3)\n\nstrat_dev_24_ppp&lt;- as.ppp(strat_dev_st_24, coordinates=strat_dev_st_24)\nstrat_dev_24_owin&lt;- strat_dev_24_ppp[boundary_owin]\n\nstrat_dev_st_24_kde&lt;- spattemp.density(strat_dev_24_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(strat_dev_st_24$num_quarters)\n\nfor (i in tims2){\n  plot(strat_dev_st_24_kde, i,\n  main = paste('STKDE of Q', i, \" 2024\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021202220232024\n\n\n\nciv_st_21&lt;- quart_geo_civ %&gt;% \n  filter(year==\"2021\") %&gt;% \n  select(2,3)\n\nciv_21_ppp&lt;- as.ppp(civ_st_21, coordinates=civ_st_21)\nciv_21_owin&lt;- civ_21_ppp[boundary_owin]\n\nciv_st_21_kde&lt;- spattemp.density(civ_21_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(civ_st_21$num_quarters)\n\n\nfor (i in tims2){\n  plot(civ_st_21_kde, i,\n  main = paste('STKDE of Q', i, \" 2021\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nciv_st_22&lt;- quart_geo_civ %&gt;% \n  filter(year==\"2022\") %&gt;% \n  select(2,3)\nciv_22_ppp&lt;- as.ppp(civ_st_22, coordinates=civ_st_22)\nciv_22_owin&lt;- civ_22_ppp[boundary_owin]\n\nciv_st_22_kde&lt;- spattemp.density(civ_22_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(civ_st_22$num_quarters)\n\n\nfor (i in tims2){\n  plot(civ_st_22_kde, i,\n  main = paste('STKDE of Q', i, \" 2022\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nciv_st_23&lt;- quart_geo_civ %&gt;% \n  filter(year==\"2023\") %&gt;% \n  select(2,3)\n\nciv_23_ppp&lt;- as.ppp(civ_st_23, coordinates=civ_st_23)\nciv_23_owin&lt;- civ_23_ppp[boundary_owin]\n\nciv_st_23_kde&lt;- spattemp.density(civ_23_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(civ_st_23$num_quarters)\n\n\nfor (i in tims2){\n  plot(civ_st_23_kde, i,\n  main = paste('STKDE of Q', i, \" 2023\", sep=\"\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nciv_st_24&lt;- quart_geo_civ %&gt;% \n  filter(year==\"2024\") %&gt;% \n  select(2,3)\n\nciv_24_ppp&lt;- as.ppp(civ_st_24, coordinates=civ_st_24)\nciv_24_owin&lt;- civ_24_ppp[boundary_owin]\n\nciv_st_24_kde&lt;- spattemp.density(civ_24_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\ntims2&lt;-unique(civ_st_24$num_quarters)\n\n\nfor (i in tims2){\n  plot(civ_st_24_kde, i,\n  main = paste('STKDE of Q', i, \" 2024\", sep=\"\"))\n}"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#second-order-spatio-temporal-kde",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#second-order-spatio-temporal-kde",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.6 Second-Order Spatio-Temporal KDE",
    "text": "1.6 Second-Order Spatio-Temporal KDE\nIn this section, I will be computing the Second Order Spatio Temporal KDE Layers.\n\nBattlesExplosionsStrategic DevelopmentsViolence Against Civilians\n\n\n\nbattles_sost&lt;- quart_geo_bat %&gt;% \n  select(2,3)\nbattles_sost_ppp&lt;- as.ppp(battles_sost, coordinates= battles_sost)\nbattles_sost_owin&lt;- battles_sost_ppp[boundary_owin]\nbattles_sost.csr &lt;- envelope(battles_sost_owin, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, \n[14:26 remaining, estimate finish 2024-09-22 20:05:10]\n3, \n[18:01 remaining, estimate finish 2024-09-22 20:08:58]\n4, \n[21:35 remaining, estimate finish 2024-09-22 20:12:51]\n5, \n[19:57 remaining, estimate finish 2024-09-22 20:11:23]\n6, \n[18:49 remaining, estimate finish 2024-09-22 20:10:25]\n7, \n[18:08 remaining, estimate finish 2024-09-22 20:09:54]\n8, \n[17:37 remaining, estimate finish 2024-09-22 20:09:33]\n9, \n[17:06 remaining, estimate finish 2024-09-22 20:09:12]\n10, \n[16:39 remaining, estimate finish 2024-09-22 20:08:55]\n11, \n[16:21 remaining, estimate finish 2024-09-22 20:08:47]\n12, \n[15:58 remaining, estimate finish 2024-09-22 20:08:34]\n13, \n[15:43 remaining, estimate finish 2024-09-22 20:08:29]\n14, \n[15:27 remaining, estimate finish 2024-09-22 20:08:24]\n15, \n[15:12 remaining, estimate finish 2024-09-22 20:08:19]\n16, \n[16:06 remaining, estimate finish 2024-09-22 20:09:35]\n17, \n[17:13 remaining, estimate finish 2024-09-22 20:11:09]\n18, \n[17:59 remaining, estimate finish 2024-09-22 20:12:20]\n19, \n[18:48 remaining, estimate finish 2024-09-22 20:13:37]\n20, \n[19:21 remaining, estimate finish 2024-09-22 20:14:35]\n21, \n[19:51 remaining, estimate finish 2024-09-22 20:15:31]\n22, \n[20:05 remaining, estimate finish 2024-09-22 20:16:09]\n23, \n[20:23 remaining, estimate finish 2024-09-22 20:16:51]\n24, \n[20:37 remaining, estimate finish 2024-09-22 20:17:31]\n25, \n[20:45 remaining, estimate finish 2024-09-22 20:18:03]\n26, \n[20:55 remaining, estimate finish 2024-09-22 20:18:39]\n27, \n[20:58 remaining, estimate finish 2024-09-22 20:19:08]\n28, \n[20:49 remaining, estimate finish 2024-09-22 20:19:19]\n29, \n[20:09 remaining, estimate finish 2024-09-22 20:18:48]\n30, \n[19:43 remaining, estimate finish 2024-09-22 20:18:35]\n31, \n[19:43 remaining, estimate finish 2024-09-22 20:19:00]\n32, \n[19:40 remaining, estimate finish 2024-09-22 20:19:20]\n33, \n[19:33 remaining, estimate finish 2024-09-22 20:19:37]\n34, \n[19:28 remaining, estimate finish 2024-09-22 20:19:56]\n35, \n[19:23 remaining, estimate finish 2024-09-22 20:20:16]\n36, \n[19:12 remaining, estimate finish 2024-09-22 20:20:27]\n37, \n[18:58 remaining, estimate finish 2024-09-22 20:20:34]\n38, \n[18:24 remaining, estimate finish 2024-09-22 20:20:08]\n39, \n[17:58 remaining, estimate finish 2024-09-22 20:19:56]\n40, \n[17:50 remaining, estimate finish 2024-09-22 20:20:12]\n41, \n[17:31 remaining, estimate finish 2024-09-22 20:20:10]\n42, \n[16:59 remaining, estimate finish 2024-09-22 20:19:47]\n43, \n[16:29 remaining, estimate finish 2024-09-22 20:19:26]\n44, \n[16:01 remaining, estimate finish 2024-09-22 20:19:07]\n45, \n[15:33 remaining, estimate finish 2024-09-22 20:18:47]\n46, \n[15:05 remaining, estimate finish 2024-09-22 20:18:29]\n47, \n[14:39 remaining, estimate finish 2024-09-22 20:18:12]\n48, \n[14:14 remaining, estimate finish 2024-09-22 20:17:55]\n49, \n[13:48 remaining, estimate finish 2024-09-22 20:17:37]\n50, \n[13:23 remaining, estimate finish 2024-09-22 20:17:22]\n51, \n[12:59 remaining, estimate finish 2024-09-22 20:17:06]\n52, \n[12:36 remaining, estimate finish 2024-09-22 20:16:51]\n53, \n[12:13 remaining, estimate finish 2024-09-22 20:16:36]\n54, \n[11:50 remaining, estimate finish 2024-09-22 20:16:22]\n55, \n[11:28 remaining, estimate finish 2024-09-22 20:16:08]\n56, \n[11:07 remaining, estimate finish 2024-09-22 20:15:56]\n57, \n[10:47 remaining, estimate finish 2024-09-22 20:15:45]\n58, \n[10:28 remaining, estimate finish 2024-09-22 20:15:36]\n59, \n[10:09 remaining, estimate finish 2024-09-22 20:15:26]\n60,  [9:50 remaining] 61,  [9:31 remaining] 62,  [9:12 remaining] 63,  [8:54 remaining] 64,  [8:36 remaining] 65,  [8:19 remaining] 66,  [8:01 remaining] 67,  [7:44 remaining] 68,  [7:26 remaining] 69,  [7:09 remaining] 70,  [6:53 remaining] 71,  [6:36 remaining] 72,  [6:20 remaining] 73,  [6:04 remaining] 74,  [5:48 remaining] 75,  [5:32 remaining] 76,  [5:17 remaining] 77,  [5:01 remaining] 78,  [4:46 remaining] 79,\n [4:31 remaining] 80,  [4:16 remaining] 81,  [4:02 remaining] 82,  [3:48 remaining] 83,  [3:33 remaining] 84,  [3:19 remaining] 85,  [3:05 remaining] 86,  [2:51 remaining] 87,  [2:38 remaining] 88,  [2:24 remaining] 89,  [2:11 remaining] 90,  [1:57 remaining] 91,  [1:44 remaining] 92,  [1:30 remaining] 93,  [1:17 remaining] 94,  [1:04 remaining] 95,  [51 sec remaining] 96,  [38 sec remaining] 97,  [25 sec remaining] 98,  [13 sec remaining] \n99.\n\nDone.\n\nplot(battles_sost.csr)\n\n\n\n\n\n\n\n\n\n\n\nexp_sost&lt;- quart_geo_exp %&gt;% \n  select(2,3)\nexp_sost_ppp&lt;- as.ppp(exp_sost, coordinates= exp_sost)\nexp_sost_owin&lt;- exp_sost_ppp[boundary_owin]\nexp_sost.csr &lt;- envelope(exp_sost_owin, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, \n[13:57 remaining, estimate finish 2024-09-22 20:25:37]\n3, \n[14:02 remaining, estimate finish 2024-09-22 20:25:52]\n4, \n[14:14 remaining, estimate finish 2024-09-22 20:26:12]\n5, \n[14:03 remaining, estimate finish 2024-09-22 20:26:11]\n6, \n[13:48 remaining, estimate finish 2024-09-22 20:26:05]\n7, \n[13:44 remaining, estimate finish 2024-09-22 20:26:09]\n8, \n[13:39 remaining, estimate finish 2024-09-22 20:26:14]\n9, \n[13:39 remaining, estimate finish 2024-09-22 20:26:24]\n10, \n[13:37 remaining, estimate finish 2024-09-22 20:26:31]\n11, \n[13:41 remaining, estimate finish 2024-09-22 20:26:46]\n12, \n[13:43 remaining, estimate finish 2024-09-22 20:26:59]\n13, \n[13:33 remaining, estimate finish 2024-09-22 20:26:59]\n14, \n[13:27 remaining, estimate finish 2024-09-22 20:27:02]\n15, \n[13:16 remaining, estimate finish 2024-09-22 20:27:00]\n16, \n[13:07 remaining, estimate finish 2024-09-22 20:27:01]\n17, \n[12:58 remaining, estimate finish 2024-09-22 20:27:02]\n18, \n[12:48 remaining, estimate finish 2024-09-22 20:27:01]\n19, \n[12:35 remaining, estimate finish 2024-09-22 20:26:57]\n20, \n[12:25 remaining, estimate finish 2024-09-22 20:26:56]\n21, \n[12:14 remaining, estimate finish 2024-09-22 20:26:54]\n22, \n[12:06 remaining, estimate finish 2024-09-22 20:26:56]\n23, \n[11:55 remaining, estimate finish 2024-09-22 20:26:54]\n24, \n[11:46 remaining, estimate finish 2024-09-22 20:26:54]\n25, \n[11:36 remaining, estimate finish 2024-09-22 20:26:53]\n26, \n[11:27 remaining, estimate finish 2024-09-22 20:26:55]\n27, \n[11:21 remaining, estimate finish 2024-09-22 20:26:58]\n28, \n[11:13 remaining, estimate finish 2024-09-22 20:27:01]\n29, \n[11:06 remaining, estimate finish 2024-09-22 20:27:04]\n30, \n[10:58 remaining, estimate finish 2024-09-22 20:27:06]\n31, \n[10:50 remaining, estimate finish 2024-09-22 20:27:09]\n32, \n[10:40 remaining, estimate finish 2024-09-22 20:27:08]\n33, \n[10:30 remaining, estimate finish 2024-09-22 20:27:07]\n34, \n[10:21 remaining, estimate finish 2024-09-22 20:27:07]\n35, \n[10:11 remaining, estimate finish 2024-09-22 20:27:07]\n36, \n[10:30 remaining, estimate finish 2024-09-22 20:27:52]\n37, \n[10:46 remaining, estimate finish 2024-09-22 20:28:33]\n38, \n[10:37 remaining, estimate finish 2024-09-22 20:28:35]\n39, \n[10:34 remaining, estimate finish 2024-09-22 20:28:48]\n40, \n[10:21 remaining, estimate finish 2024-09-22 20:28:44]\n41, \n[10:08 remaining, estimate finish 2024-09-22 20:28:39]\n42,  [9:55 remaining] 43,  [9:55 remaining] 44, \n[10:01 remaining, estimate finish 2024-09-22 20:29:23]\n45, \n[10:04 remaining, estimate finish 2024-09-22 20:29:48]\n46,  [9:54 remaining] 47,  [9:58 remaining] 48,  [10:00 remaining] 49, \n[10:02 remaining, estimate finish 2024-09-22 20:31:11]\n50,  [9:49 remaining] 51,  [9:33 remaining] 52,  [9:21 remaining] 53,  [9:21 remaining] 54,  [9:18 remaining] 55,  [9:15 remaining] 56,  [9:10 remaining] 57,  [9:04 remaining] 58,  [8:58 remaining] 59,  [8:51 remaining] 60,  [8:44 remaining] 61,  [8:37 remaining] 62,  [8:29 remaining] 63,  [8:20 remaining] 64,  [8:11 remaining] 65,  [8:02 remaining] 66,  [7:52 remaining] 67,  [7:41 remaining] 68,  [7:29 remaining] 69,\n [7:12 remaining] 70,  [6:59 remaining] 71,  [6:49 remaining] 72,  [6:38 remaining] 73,  [6:22 remaining] 74,  [6:05 remaining] 75,  [5:48 remaining] 76,  [5:32 remaining] 77,  [5:16 remaining] 78,  [5:00 remaining] 79,  [4:44 remaining] 80,  [4:28 remaining] 81,  [4:13 remaining] 82,  [3:58 remaining] 83,  [3:43 remaining] 84,  [3:28 remaining] 85,  [3:13 remaining] 86,  [2:58 remaining] 87,  [2:44 remaining] 88,  [2:29 remaining] 89,\n [2:15 remaining] 90,  [2:01 remaining] 91,  [1:47 remaining] 92,  [1:34 remaining] 93,  [1:20 remaining] 94,  [1:06 remaining] 95,  [53 sec remaining] 96,  [39 sec remaining] 97,  [26 sec remaining] 98,  [13 sec remaining] \n99.\n\nDone.\n\nplot(exp_sost.csr)\n\n\n\n\n\n\n\n\n\n\n\nstrat_dev_sost&lt;- quart_geo_strat %&gt;% \n  select(2,3)\nstrat_dev_sost_ppp&lt;- as.ppp(strat_dev_sost, coordinates= strat_dev_sost)\nstrat_dev_sost_owin&lt;- strat_dev_sost_ppp[boundary_owin]\nstrat_dev_sost.csr &lt;- envelope(strat_dev_sost_owin, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, \n[14:24 remaining, estimate finish 2024-09-22 20:47:41]\n3, \n[13:53 remaining, estimate finish 2024-09-22 20:47:18]\n4, \n[13:46 remaining, estimate finish 2024-09-22 20:47:20]\n5, \n[13:33 remaining, estimate finish 2024-09-22 20:47:15]\n6, \n[13:26 remaining, estimate finish 2024-09-22 20:47:17]\n7, \n[13:13 remaining, estimate finish 2024-09-22 20:47:12]\n8, \n[13:04 remaining, estimate finish 2024-09-22 20:47:12]\n9, \n[12:53 remaining, estimate finish 2024-09-22 20:47:10]\n10, \n[12:45 remaining, estimate finish 2024-09-22 20:47:10]\n11, \n[12:36 remaining, estimate finish 2024-09-22 20:47:10]\n12, \n[12:30 remaining, estimate finish 2024-09-22 20:47:13]\n13, \n[13:42 remaining, estimate finish 2024-09-22 20:48:45]\n14, \n[15:12 remaining, estimate finish 2024-09-22 20:50:39]\n15, \n[16:15 remaining, estimate finish 2024-09-22 20:52:05]\n16, \n[17:06 remaining, estimate finish 2024-09-22 20:53:19]\n17, \n[17:48 remaining, estimate finish 2024-09-22 20:54:24]\n18, \n[18:20 remaining, estimate finish 2024-09-22 20:55:18]\n19, \n[18:50 remaining, estimate finish 2024-09-22 20:56:12]\n20, \n[19:22 remaining, estimate finish 2024-09-22 20:57:09]\n21, \n[19:50 remaining, estimate finish 2024-09-22 20:58:02]\n22, \n[20:09 remaining, estimate finish 2024-09-22 20:58:46]\n23, \n[19:40 remaining, estimate finish 2024-09-22 20:58:29]\n24, \n[19:52 remaining, estimate finish 2024-09-22 20:59:05]\n25, \n[20:00 remaining, estimate finish 2024-09-22 20:59:37]\n26, \n[20:07 remaining, estimate finish 2024-09-22 21:00:08]\n27, \n[20:09 remaining, estimate finish 2024-09-22 21:00:33]\n28, \n[20:01 remaining, estimate finish 2024-09-22 21:00:46]\n29, \n[19:36 remaining, estimate finish 2024-09-22 21:00:34]\n30, \n[19:34 remaining, estimate finish 2024-09-22 21:00:54]\n31, \n[19:28 remaining, estimate finish 2024-09-22 21:01:10]\n32, \n[19:27 remaining, estimate finish 2024-09-22 21:01:35]\n33, \n[19:17 remaining, estimate finish 2024-09-22 21:01:46]\n34, \n[18:42 remaining, estimate finish 2024-09-22 21:01:20]\n35, \n[18:09 remaining, estimate finish 2024-09-22 21:00:56]\n36, \n[17:38 remaining, estimate finish 2024-09-22 21:00:33]\n37, \n[17:07 remaining, estimate finish 2024-09-22 21:00:11]\n38, \n[16:37 remaining, estimate finish 2024-09-22 20:59:50]\n39, \n[16:08 remaining, estimate finish 2024-09-22 20:59:30]\n40, \n[15:41 remaining, estimate finish 2024-09-22 20:59:11]\n41, \n[15:15 remaining, estimate finish 2024-09-22 20:58:53]\n42, \n[14:50 remaining, estimate finish 2024-09-22 20:58:37]\n43, \n[14:37 remaining, estimate finish 2024-09-22 20:58:43]\n44, \n[14:31 remaining, estimate finish 2024-09-22 20:59:00]\n45, \n[14:26 remaining, estimate finish 2024-09-22 20:59:19]\n46, \n[14:14 remaining, estimate finish 2024-09-22 20:59:27]\n47, \n[13:49 remaining, estimate finish 2024-09-22 20:59:10]\n48, \n[13:25 remaining, estimate finish 2024-09-22 20:58:55]\n49, \n[13:03 remaining, estimate finish 2024-09-22 20:58:42]\n50, \n[12:55 remaining, estimate finish 2024-09-22 20:58:57]\n51, \n[12:45 remaining, estimate finish 2024-09-22 20:59:09]\n52, \n[12:35 remaining, estimate finish 2024-09-22 20:59:21]\n53, \n[12:25 remaining, estimate finish 2024-09-22 20:59:36]\n54, \n[12:16 remaining, estimate finish 2024-09-22 20:59:50]\n55, \n[12:05 remaining, estimate finish 2024-09-22 21:00:01]\n56, \n[11:53 remaining, estimate finish 2024-09-22 21:00:13]\n57, \n[11:41 remaining, estimate finish 2024-09-22 21:00:23]\n58, \n[11:28 remaining, estimate finish 2024-09-22 21:00:32]\n59, \n[11:15 remaining, estimate finish 2024-09-22 21:00:41]\n60, \n[11:03 remaining, estimate finish 2024-09-22 21:00:53]\n61, \n[10:49 remaining, estimate finish 2024-09-22 21:01:01]\n62, \n[10:35 remaining, estimate finish 2024-09-22 21:01:10]\n63, \n[10:16 remaining, estimate finish 2024-09-22 21:01:05]\n64,  [9:55 remaining] 65,  [9:34 remaining] 66,  [9:13 remaining] 67,  [8:52 remaining] 68,  [8:32 remaining] 69,  [8:12 remaining] 70,  [7:52 remaining] 71,  [7:33 remaining] 72,  [7:14 remaining] 73,  [6:55 remaining] 74,  [6:36 remaining] 75,  [6:18 remaining] 76,  [6:00 remaining] 77,  [5:42 remaining] 78,  [5:25 remaining] 79,  [5:08 remaining] 80,  [4:51 remaining] 81,  [4:34 remaining] 82,  [4:17 remaining] 83,\n [4:01 remaining] 84,  [3:45 remaining] 85,  [3:29 remaining] 86,  [3:13 remaining] 87,  [2:57 remaining] 88,  [2:42 remaining] 89,  [2:26 remaining] 90,  [2:11 remaining] 91,  [1:56 remaining] 92,  [1:41 remaining] 93,  [1:26 remaining] 94,  [1:11 remaining] 95,  [57 sec remaining] 96,  [43 sec remaining] 97,  [28 sec remaining] 98,  [14 sec remaining] \n99.\n\nDone.\n\nplot(strat_dev_sost.csr)\n\n\n\n\n\n\n\n\n\n\n\ncivViolence_sost&lt;- quart_geo_civ %&gt;% \n  select(2,3)\ncivViolence_sost_ppp&lt;- as.ppp(civViolence_sost, coordinates= civViolence_sost)\ncivViolence_sost_owin&lt;- civViolence_sost_ppp[boundary_owin]\ncivViolence_sost.csr &lt;- envelope(civViolence_sost_owin, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [7:15 remaining] 3,\n [7:10 remaining] 4,  [7:02 remaining] 5,  [7:01 remaining] 6,\n [6:57 remaining] 7,  [6:53 remaining] 8,  [6:47 remaining] 9,\n [6:44 remaining] 10,  [6:39 remaining] 11,  [6:34 remaining] 12,\n [6:30 remaining] 13,  [6:28 remaining] 14,  [6:24 remaining] 15,\n [6:19 remaining] 16,  [6:15 remaining] 17,  [6:12 remaining] 18,\n [6:07 remaining] 19,  [6:03 remaining] 20,  [5:58 remaining] 21,\n [5:54 remaining] 22,  [5:50 remaining] 23,  [5:45 remaining] 24,\n [5:41 remaining] 25,  [5:37 remaining] 26,  [5:32 remaining] 27,\n [5:27 remaining] 28,  [5:23 remaining] 29,  [5:19 remaining] 30,\n [5:14 remaining] 31,  [5:10 remaining] 32,  [5:05 remaining] 33,\n [5:01 remaining] 34,  [4:56 remaining] 35,  [4:51 remaining] 36,\n [4:47 remaining] 37,  [4:43 remaining] 38,  [4:38 remaining] 39,\n [4:33 remaining] 40,  [4:28 remaining] 41,  [4:24 remaining] 42,\n [4:21 remaining] 43,  [4:19 remaining] 44,  [4:23 remaining] 45,\n [4:18 remaining] 46,  [4:13 remaining] 47,  [4:08 remaining] 48,\n [4:03 remaining] 49,  [3:58 remaining] 50,  [3:53 remaining] 51,\n [3:49 remaining] 52,  [3:44 remaining] 53,  [3:39 remaining] 54,\n [3:35 remaining] 55,  [3:30 remaining] 56,  [3:25 remaining] 57,\n [3:20 remaining] 58,  [3:15 remaining] 59,  [3:10 remaining] 60,\n [3:06 remaining] 61,  [3:01 remaining] 62,  [2:59 remaining] 63,\n [2:59 remaining] 64,  [2:58 remaining] 65,  [2:57 remaining] 66,\n [2:56 remaining] 67,  [2:54 remaining] 68,  [2:51 remaining] 69,\n [2:49 remaining] 70,  [2:43 remaining] 71,  [2:40 remaining] 72,\n [2:37 remaining] 73,  [2:34 remaining] 74,  [2:31 remaining] 75,\n [2:27 remaining] 76,  [2:20 remaining] 77,  [2:14 remaining] 78,\n [2:07 remaining] 79,  [2:01 remaining] 80,  [1:55 remaining] 81,\n [1:48 remaining] 82,  [1:42 remaining] 83,  [1:36 remaining] 84,\n [1:30 remaining] 85,  [1:23 remaining] 86,  [1:17 remaining] 87,\n [1:11 remaining] 88,  [1:05 remaining] 89,  [59 sec remaining] 90,\n [53 sec remaining] 91,  [47 sec remaining] 92,  [41 sec remaining] 93,\n [35 sec remaining] 94,  [29 sec remaining] 95,  [23 sec remaining] 96,\n [17 sec remaining] 97,  [12 sec remaining] 98,  [6 sec remaining] \n99.\n\nDone.\n\nplot(civViolence_sost.csr)\n\n\n\n\n\n\n\n\n\n\n\nThe plots above further proves that the spatial points across the quarters reflect a clustered pattern."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "",
    "text": "In this Hands-on, I will be exploring how to compute Global Measures of Spatial Autocorrelation (GMSA) using the spdep package.\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\nFirst and foremost, I will download the necessary packages, mainly sf, tidyverse, spdep and tmap.\n\npacman:: p_load(sf, spdep, tidyverse, tmap )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "",
    "text": "In this Hands-on, I will be exploring how to compute Global Measures of Spatial Autocorrelation (GMSA) using the spdep package.\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\nFirst and foremost, I will download the necessary packages, mainly sf, tidyverse, spdep and tmap.\n\npacman:: p_load(sf, spdep, tidyverse, tmap )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#study-area-and-data",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.2 Study Area and Data",
    "text": "6.2 Study Area and Data\nFor this exercise, I will use 2 data sets:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n6.2.1 Importing the data\nFirst, I will use the st_read() function of the sf package to import the shapefiles into our R environment.\n\nhunan3 &lt;- st_read(dsn=\"data/geospatial\",\n                  layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\santhyats\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nI will also read the csv file into our environment using the read_csv() function.\n\nhunan2012_3&lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLastly, I will perform a relational join to join the attributes from the hunan2012_3 dataframe to the hunan3 dataframe. This is done by using the left_join() function of the dplyr package.\n\nhunan3 &lt;- left_join(hunan3,hunan2012_3) %&gt;% \n select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n6.2.2 Visualising Regional Development Indicators\nIn this section, we will plot a chloropeth map that will show us the distribution of GDPPC 2012. This will be done using the qtm() function of the tmap package.\n\nequal &lt;- tm_shape(hunan3) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan3) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.3 Global Measures of Spatial Autocorrelation",
    "text": "6.3 Global Measures of Spatial Autocorrelation\n\n6.3.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation, we would first need to derive the spatial weights of the study area. Spatial weights are the neighbourhood relationships between the spatial units.\nWe will derive the contiguity neighbours list using the poly2nb() function of the spdep package. By default, this function returns a matrice of neighbours of the spatial untis, derived by the Queen’s method.\n\nwm_q3 &lt;- poly2nb(hunan3, \n                queen=TRUE)\nsummary(wm_q3)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nFrom the summary above, we see that there are a total of 88 spatial regions in hunan and the most connected region has 11 links. There are also 2 least connected regions with only one neighbour each.\n\n\n6.3.2 Row-standardized Weights Matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q3 &lt;- nb2listw(wm_q3, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q3\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation--morans-test",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation--morans-test",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.4 Global Measures of Spatial Autocorrelation- Moran’s Test",
    "text": "6.4 Global Measures of Spatial Autocorrelation- Moran’s Test\n\n6.4.1 Moran’s I Test\nIn this section, we will be performing the Maron’s I statistics test using the moran.test() function of the spdep package.\n\nmoran.test(hunan3$GDPPC, \n           listw=rswm_q3, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan3$GDPPC  \nweights: rswm_q3    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nFrom the statistics derived above, we see that the p-value is extremely small and that the alternate hypothesis is greater, enabling us to reject the null hypothesis (which states that there is no correlation between the weighted spatial units) and conclude that there is significant spatial autocorrelation between the weighted spatial units. This is further corroborated by the positive value of the Moran I Statistic.\nIn context, this means that counties with similar GDPPC Values are more close to one another spatially as compared to counties that have varying levels.\n\n\n6.4.2 Computing Monte Carlo Moran’s I Statistic\nWe will now perform the Monte Carlo Simulation for the Moran’s I Statistic using the moran.mc() function, also from the spdep package.\n\nset.seed(1234)\nbperm= moran.mc(hunan3$GDPPC, \n                listw=rswm_q3, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan3$GDPPC \nweights: rswm_q3  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nFrom the statistics above, we once again see that the p-value is lower than 0.05, and we can reject the null hypothesis and accept the claim that the weighted spatial units are positively autocorrelated.\n\n\n6.4.3 Visualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\",)\nabline(v=0, \n       col=\"purple\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation--gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation--gearys-c",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.5 Global Measures of Spatial Autocorrelation- Geary’s C",
    "text": "6.5 Global Measures of Spatial Autocorrelation- Geary’s C\n\n6.5.1 Geary’s C Test\nIn this section, I will be performing the Geary’s C test using the geary.test() function, also from the spdep package.\n\ngeary.test(hunan3$GDPPC, listw=rswm_q3)\n\n\n    Geary C test under randomisation\n\ndata:  hunan3$GDPPC \nweights: rswm_q3   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nFrom the statistics above, I see that the Geary C statistic has a postivie value and the p-value is very small. This indicates that the null hypothesis (which states that the weighted spatial units are randomly distributed) is rejected and the weighted spatial units are concluded to be spatially correlated.\n\n\n6.5.2 Computing Monte Carlo Geary’s C\nWe will perform the permutations of the Monte Carlo simulation using the geary.mc() function of the spdep package.\n\nset.seed(1234)\nbperm=geary.mc(hunan3$GDPPC, \n               listw=rswm_q3, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan3$GDPPC \nweights: rswm_q3  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n6.5.3 Visualising the Monte Carlo Geary’s C\nWe will once again plot a histogram to reveal the distribution of the values in the Monte Carlo simulation.\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.6 Spatial Correlogram",
    "text": "6.6 Spatial Correlogram\nSpatial Correlograms are plots that show how correlated pairs of spatial observations are when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance. In this section, we will be plotting the coreelograms for the two tests that we have explored so far.\n\n6.6.1 Compute Moran I’s Correlogram\nTo achieve this, we will be using the sp.correlogram() function of the spdep package.\n\nMI_corr &lt;- sp.correlogram(wm_q3, \n                          hunan3$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nFrom the plot above, we see that as the distance increases, the distribution of the values of the Moran I’s test becomes more negative, indicating that with larger distances, the spatial autocorrelation of the weighted spatial units decrease.\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan3$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n6.6.2 Computing Geary C’s Correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q3, \n                          hunan3$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nSimilarly, we will derive the analysis report\n\nprint(GC_corr)\n\nSpatial correlogram for hunan3$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-measures-of-spatial-autocorrelation",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.7 Local Measures of Spatial Autocorrelation",
    "text": "6.7 Local Measures of Spatial Autocorrelation\n\n6.7.1 Computing Local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan3$County)\nlocalMI &lt;- localmoran(hunan3$GDPPC, rswm_q3)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nWe can make use of the printCoefmat() to list the contents of the local Moran matrix.\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan3$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\n6.7.2 Mapping the Local Moran’s I map\nBefore we map the Local Moran I map, we will first append the Moran I dataframe to the hunan dataframe.\n\nhunan.localMI &lt;- cbind(hunan3,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nWe will now plot the chloropeth map of local Moran I’s values\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n6.7.3 Mapping Local Moran I’s p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values. The code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Purples\", \n          title = \"Local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n6.7.4 Mapping both Moran’s I- and p- values\nFor more effective interpretation, we can plot both maps side-by-side.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.8 Creating a LISA Cluster Map",
    "text": "6.8 Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\n6.8.1 Plotting the Moran Scatter Plot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nWe will use the moran.plot() function of the spdep package to plot the scatterplot.\n\nnci &lt;- moran.plot(hunan3$GDPPC, rswm_q3,\n                  labels=as.character(hunan3$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\nThe top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. \n\n\n6.8.2 Plotting Moran Scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations. as.vector() function at the end ensures that the output will be in a vector format.\n\nhunan3$Z.GDPPC &lt;- scale(hunan3$GDPPC) %&gt;% \n  as.vector \n\nWe will now once again plot the scatterplot.\n\nnci2 &lt;- moran.plot(hunan3$Z.GDPPC, rswm_q3,\n                   labels=as.character(hunan3$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n6.8.3 Preparing LISA map classes\nBelow are the steps to prepare a LISA cluster map\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, we derive the spatially lagged variable of interest (i.e. GDPPC) and center it around its mean.\n\nhunan3$lag_GDPPC &lt;- lag.listw(rswm_q3, hunan3$GDPPC)\nDV &lt;- hunan3$lag_GDPPC - mean(hunan3$lag_GDPPC)     \n\nThis is followed by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05       \n\nThese four command lines below define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 1\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 2\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nLastly, place non-significant Moran in the category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-a-lisa-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-a-lisa-map",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "6.9 Plotting a LISA map",
    "text": "6.9 Plotting a LISA map\nNow, we can plot a LISA map using the code chunk below.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nWe can also plot the local Moran’s value and it’s corresponding p-values beside each other.\n\ngdppc &lt;- qtm(hunan3, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "7.0 Hot Spot and Cold Spot Area Analysis",
    "text": "7.0 Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\n\n7.0.1 Getis and Ord’s G statistic\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\n7.0.2 Deriving Distance-based Weights Matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n7.0.2.1 Deriving the centroid\nFirst, we will derive the centroid of each of the polygons found in the hunan3 dataframe so that we can construct a connectivity graph.\n\nlongitude &lt;- map_dbl(hunan3$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan3$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n7.0.2.2 Determining the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\n7.0.2.3 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the output to a spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\n7.0.3 Computing Adaptive Distance Weights Matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nWe once again convert the output to a spatial weights object\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "title": "6 Global and Local measures of Spatial Association",
    "section": "7.1 Computing Gi statistics",
    "text": "7.1 Computing Gi statistics\n\n7.1.1 Gi Statistics using fixed distance\n\nfips &lt;- order(hunan3$County)\ngi.fixed &lt;- localG(hunan3$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan3$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan3, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nIn fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\n7.1.2 Mapping Gi values with fixed distance weights\n\ngdppc &lt;- qtm(hunan3, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n7.1.3 Gi Statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips &lt;- order(hunan3$County)\ngi.adaptive &lt;- localG(hunan3$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan3, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n7.1.4 Mapping Gi statistics with adaptive distance weights\nIt is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc&lt;- qtm(hunan3, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#overall-learnings",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#overall-learnings",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.7 Overall Learnings",
    "text": "1.7 Overall Learnings\nThis exercise has allowed me to revisit and revise the various different concepts and functions that we had learnt in class and in the past Hands-on Exercises. Being completely on my own, it has forced me to move out of my comfort zone and learn concepts in my own way. To summarise, I would say my main takeaways are:\n\nAcquiring real-world data and being able to observe it in order to identify what needs to be handled and processed for our analytical needs (formatting of date columns, dropping of columns etc.)\nImporting datasets of different types (shapefiles, csv files) into r for analysis\nHandling real-world data and being able to convert it to desirable formats\nIdentifying the suitable formats that the input data needs to be in, in order to perform the different analysis methods (ppp and owin objects etc.)\nFiguring out the most suitable methods to derive KDE layers on a real-word dataset according to the characteristics of the dataset\nBeing able to understand and somewhat explain the first order and second-order analysis plots\n\nAnd some further non-technical learnings:\n\nNeat and efficient ways to present the data and the plots."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#references",
    "href": "Take-Home_Exercises/Take-Home_Ex01/Take-Home_Ex01.html#references",
    "title": "Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.8 References",
    "text": "1.8 References\n\nMaizland, L. (2022, January 31). Myanmar’s troubled history: coups, military rule, and ethnic conflict. Council on Foreign Relations. https://www.cfr.org/backgrounder/myanmar-history-coup-military-rule-ethnic-conflict-rohingya"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415: Geospatial Analytics and Applications",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics Homepage! In this website, you will find all the coursework prepared by me in this course :) :&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "In this exercise, we will be exploring a new package, sfdep.\n\npacman::p_load(sf, tidyverse, tmap, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#loading-in-the-necessary-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#loading-in-the-necessary-packages",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "In this exercise, we will be exploring a new package, sfdep.\n\npacman::p_load(sf, tidyverse, tmap, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-the-data",
    "title": "In-class Exercise 6",
    "section": "2.1 importing the data",
    "text": "2.1 importing the data\n\n2.1.1 Importing the Hunan shapefiles\n\nhunan4&lt;-st_read(dsn=\"data/geospatial\", \n                layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\santhyats\\IS415-GAA\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n2.1.2 importing the csv file\n\nhunan4_2012&lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n2.1.3 Performing a left join of the sf dataframes\n\nhunan4_GDPPC&lt;- left_join(hunan4, hunan4_2012) %&gt;% \n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#global-measures-of-spatial-association",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#global-measures-of-spatial-association",
    "title": "In-class Exercise 6",
    "section": "2.2 Global measures of spatial association",
    "text": "2.2 Global measures of spatial association\n\n2.2.1 Deriving queen contiguity weights sfdep methods\n\nwm_q4&lt;- hunan4_GDPPC %&gt;% \n  mutate(nb=st_contiguity(geometry),\n         wt= st_weights(nb, \n                        style='W'),\n         .before=1)\n\nThe st_contiguity() function of the sfdep package helps to add the neighbours to a dataframe instead of printing out the matrix. The .before attribute adds the new columns to the front of the sf table instead of the default back of the sf.\n\n\n2.2.2 Computing Global Moran’s I\n\nmoranI&lt;- global_moran(wm_q4$GDPPC,\n                      wm_q4$nb,\n                      wm_q4$wt)\n\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\n2.2.3 Performing the Global Moran’s I Test\n\nglobal_moran_test(wm_q4$GDPPC,\n                  wm_q4$nb,\n                  wm_q4$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nThe p-value is incredibly small, indictaing that we reject the null hypothesis and conclude that the relationship between the neighbours differ significantly from the values as observed under a randomly spatially distributed neighbours. Next, looking at the Moran I statistic value of 0.3007, we can see that there is clustering present among the spatial units.\n\n\n2.2.4 Performing Global Moran I’s permutation Test\n\nset.seed(1234)\nglobal_moran_perm(wm_q4$GDPPC,\n                  wm_q4$nb,\n                  wm_q4$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nSetting the seed allows us to ensure that our computations are reproducible. This allows us to get the same value every time we run the code chunk or render the document.\nFrom the results, we see that the p-value is once again really small, confirming that we will reject the null hypothesis…."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-local-morans-i",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-local-morans-i",
    "title": "In-class Exercise 6",
    "section": "2.3 Computing Local Moran’s I",
    "text": "2.3 Computing Local Moran’s I\n\nlisa&lt;- wm_q4 %&gt;% \n  mutate(local_moran = local_moran(GDPPC, nb, wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran)\n\nunnest() expands a column-list of dataframes to rows and columns.\n2.3.1 Visualising Local Moran’s I\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) + \n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I\",\n            main.title.size= 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n2.3.2 Visualising LISA map\nLISA Map helps us to visualise outliers and clusters. High-Low and Low-High categories are considered as outliers whereas High-High and Low-Low categories are considered the clusters. The LISA map is an in interpreted map by combining the local Moran I’s statistic of geographical areas and their respective p-values.\n\nlisa_sig&lt;- lisa %&gt;% \n  filter(p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-local-g-statistics",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-local-g-statistics",
    "title": "In-class Exercise 6",
    "section": "2.4 Computing Local G-statistics",
    "text": "2.4 Computing Local G-statistics\nG-statistics allow us to observe for hot and cold spots\n\nwm_idw&lt;- hunan4_GDPPC %&gt;% \n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry, scale=1, alpha=1),\n         .before=1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\nHCSA&lt;- wm_idw %&gt;% \n  mutate(local_GI = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99), \n    .before = 1) %&gt;% \n  unnest(local_GI)\n\n\n2.4.1 Visualising the Gi* statistics\n\nHCSA_sig &lt;- HCSA %&gt;% \n  filter(p_sim &lt;0.05)\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(HCSA)+\n  tm_polygons() +\n  tm_borders(alpha=0.5) +\n  tm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "",
    "text": "Drug use in Thailand is a prevalent problem and has been on the rise in recent years. Being in the drug trafficking routes from the Golden Triangle, the major source of methamphetamine in Southeast Asia, it has naturally faced an increased frequency of this crisis. In this exercise, I will be analysing the distribution of drug-related offences in Thailand at the provincial level and observing for any spatial patterns in them. I will also be performing deploying appropriate analysis methods to observe for presence of hot and cold spots."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#overview",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#overview",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "",
    "text": "Drug use in Thailand is a prevalent problem and has been on the rise in recent years. Being in the drug trafficking routes from the Golden Triangle, the major source of methamphetamine in Southeast Asia, it has naturally faced an increased frequency of this crisis. In this exercise, I will be analysing the distribution of drug-related offences in Thailand at the provincial level and observing for any spatial patterns in them. I will also be performing deploying appropriate analysis methods to observe for presence of hot and cold spots."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#getting-started",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#getting-started",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.1 Getting Started",
    "text": "2.1 Getting Started\n\n2.1.1 Loading the necessary packages\nFirst and foremost, I will load the packages that we will be using in this exercise using the p_load() function of pacman. The packages we will use in this exercise are the following:\nsf: Used in spatial data wrangling\ntidyverse: Used in data wrangling for non-spatial data\ntmap: For functions relating to mapping point patterns\nsfdep: Functions that support Exploratory Data Analysis and is compatible with the sf and tidyverse packages\n\npacman::p_load(sf, tidyverse, tmap, sfdep)\n\n\n\n2.1.2 Loading in the Datasets\nThese are the datafiles I will be using for this exercise:\n\nThai_Drug_Offences_2017-2022.csv is a csv file containing the data about the locations of drug offences in Thailand.\nThai_Admin1_2022 is a shapefile that contains the provincial boundaries of Thailand.\n\nI will first load in the csv file using the read_csv() function, and save it into the Thai_doff dataframe. After looking at the downloaded data, I will be able to select only the columns that are needed for this exercise.\nI will further group rows according to the province and total up the number of cases for each province. This is done with the help of the group_by() function to group the rows according to the province, and then using the summarise() and sum() functions to sum up the number of cases in each province and save it in a new column called ‘total_count’.\n\nThai_doff &lt;- read_csv(\"data/aspatial/Thai_Drug_Offences_2017-2022.csv\") %&gt;%\n  select(1, 2, 3, 5)\n\nRows: 7392 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): types_of_drug_offenses, province_th, province_en\ndbl (2): fiscal_year, no_cases\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nThai_doff &lt;- Thai_doff %&gt;% \n  group_by(fiscal_year, province_en) %&gt;% \n  summarise('total_count'= sum(`no_cases`))\n\n`summarise()` has grouped output by 'fiscal_year'. You can override using the\n`.groups` argument.\n\n\nNext, I will load in the shapefile and save it to Thai_bounds using the st_read() function. After observing the dataframe, I will also drop the columns that are not needed for our analysis.\n\nThai_bounds &lt;- st_read(dsn = \"data/geospatial\",\n                       layer = \"Thai_Admin1_2022\") %&gt;%\n  select(1:3, 17)\n\nReading layer `Thai_Admin1_2022' from data source \n  `C:\\santhyats\\IS415-GAA\\Take-Home_Exercises\\Take-Home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nFinally, I will perform a left join of the Thai_bounds dataframe to the Thai_doff dataframe using the province names. This will be done using the left_join() function.\n\nThai_doff&lt;- left_join(Thai_doff, Thai_bounds, by= c(\"province_en\" = \"ADM1_EN\")) %&gt;% \n  drop_na()\n\n\n\n2.1.3 Visualising the Data Over the Years\nI will now plot the layers on a chloropleth map to observe the distribution of the drug offences in Thailand. The following functions are used to achieve this:\n\ntm_shape() to plot the provincial boundaries,\ntm_fill() to map out the the variable of interest- the number of drug abuse cases\ntm_borders(), tm_layout() to format the look of the maps.\n\nBut when I tried to plot the maps, I encountered an error indicating that Thai_doff was not an sf object. I checked the type of object and found that it is a list!\n\ntypeof(Thai_doff)\n\n[1] \"list\"\n\n\nAs such, I will convert the object to a sf dataframe before continuing. To do this, I will use the data.frame() function.\n\nThai_doff &lt;- Thai_doff %&gt;% st_as_sf()\n\n\ntm_shape(Thai_doff) +\n  tm_fill(\"total_count\",\n          n = 5,\n          style = \"quantile\",\n          palette = \"Purples\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\") +\n  tm_facets(by = 'fiscal_year')\n\n\n\n\n\n\n\n\nBefore we can proceed, I will create new data frames by segmenting our Thai_doff by years. This will help us in our analysis the spatial autocorrelation over time later on.\n\nyears &lt;- list(17, 18, 19, 20, 21, 22)\n\nfor (i in years) {\n  \n  vars &lt;- paste('Thai_doff_', i, sep = '') \n  assign(vars, \n         Thai_doff %&gt;% \n           filter(fiscal_year == paste('20', i, sep = '')))\n         \n}"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#computing-weights-of-the-study-area",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#computing-weights-of-the-study-area",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.2 Computing Weights of the Study Area",
    "text": "2.2 Computing Weights of the Study Area\nThe first step in our analysis will be to come up with the spatial weights for our study area. Since our study area is constant over the time period and there was no change in the provincial boundaries of Thailand during the years 2017-2022, we can compute the spatial weights just once at the start of our analysis and use it for our yearly calculations.\n\n2.2.1 Computing the Contiguity Spatial Weights\nI will use the st_contiguity() method from the sfdep package to derive the spatial neighbours of the spatial units and st_weights() is used to compute their respective weights and save it as a new variable.\n\n  Thai_doff_wm&lt;- Thai_doff_17 %&gt;% \n  mutate(nb = st_contiguity(geometry),\n         wt= st_weights(nb, \n                        style='W'),\n         .before=1)\n\nWhen I tried this, I encountered an error indicating the presence of units with no neighbours. Hence, I computed the neighbours list of the spatial units by themselves to identify the exact units causing the errors.\n\nThai_doff_wm&lt;- st_contiguity(Thai_doff_17$geometry)\n\nThai_doff_wm\n\nNeighbour list object:\nNumber of regions: 75 \nNumber of nonzero links: 330 \nPercentage nonzero weights: 5.866667 \nAverage number of links: 4.4 \n1 region with no links:\n46\n2 disjoint connected subgraphs\n\n\nFrom the results above, we see that region 46 is the spatial unit with no neighbours, and that there are 2 disjoint clusters of spatial units-likely due to this unlinked region. Referring to the corresponding province name of the 46th spatial region in the geometry column of the Thai_doff_17 dataframe:\n\nThai_doff_17$province_en[46]\n\n[1] \"Phuket\"\n\n\nWe see that the region is Phuket. This corroborates with the fact that Phuket is an island off of the coast of mainland Thailand, thus falling out of the connected administrative boundaries. Since I do want to keep Phuket in the analysis, I will handle this issue by manually setting the neighbour of Phuket. I will set it to be region 37, Phang Nga, since it is geographically closest to Phuket. I will include an extra codeline to capture this, while keeping the rest of the code from earlier.\n\nThai_doff_wm &lt;- Thai_doff_17 %&gt;% \n  mutate(nb = st_contiguity(geometry), .before=1)\n\nThai_doff_wm$nb[[46]] &lt;- as.integer(37)\n\nThai_doff_wm &lt;- Thai_doff_wm %&gt;%\n  mutate(wt = st_weights(nb, style = 'W'), \n         .before = 1) %&gt;% \n  select(1,2)"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.3 Global Measures of Spatial Autocorrelation",
    "text": "2.3 Global Measures of Spatial Autocorrelation\n\n2.2.3 Performing the Moran I’s Test by Year\nFor this section, I will be conducting the Moran I’s Test and the Moran I’s Permutations test for the dataset according to each year.\n\n201720182019202020212022\n\n\n\nGlobal Moran’s I TestMoran I’s Permutation Test\n\n\n\nglobal_moran_test(Thai_doff_17$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.2891, p-value = 0.01104\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.127509970      -0.013513514       0.003795253 \n\n\n\n\n\nset.seed(982)\nglobal_moran_perm(Thai_doff_17$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.12751, observed rank = 96, p-value = 0.08\nalternative hypothesis: two.sided\n\n\nFrom the results above, we see that the Global Moran I’s statistic is 0.128. This indicates that the spatial units with drug abuse cases were mildly positively correlated to one another in 2017. In simple terms, the spatial areas displayed clusters that had mild similarities to one another.\n\n\n\n\n\n\nGlobal Moran I’s TestMoran I’s Permutation Test\n\n\n\nglobal_moran_test(Thai_doff_18$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.0134, p-value = 0.02203\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.111791008      -0.013513514       0.003873097 \n\n\n\n\n\nset.seed(1235)\nglobal_moran_perm(Thai_doff_18$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.11179, observed rank = 94, p-value = 0.12\nalternative hypothesis: two.sided\n\n\nFrom the results, a p-value of 0.02203 is observed. With a p-value that is lower than the level of significance of 0.05, we can reject the null hypothesis and conclude that the spatial units are positively autocorrelated and hence display clustering. Moran I’s statistic of 0.112 indicates a mild positive relationship between the units.\n\n\n\n\n\n\nGlobal Moran I’s TestMoran I’s Permutation Test\n\n\n\nglobal_moran_test(Thai_doff_19$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.3502, p-value = 0.009381\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n       0.15065681       -0.01351351        0.00487949 \n\n\n\n\n\nset.seed(1236)\nglobal_moran_perm(Thai_doff_19$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.15066, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe small p-value indicates that the results differ significantly than what would be observed under randomisation. The results for the Moran I’s statistics once again reflect the presence of mild clustering among the spatial units with the positive value of 0.151.\n\n\n\n\n\n\nGlobal Moran I’s TestMoran I’s Permutation’s Test\n\n\n\nglobal_moran_test(Thai_doff_20$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 1.8872, p-value = 0.02957\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.125756486      -0.013513514       0.005446309 \n\n\n\n\n\nset.seed(1237)\nglobal_moran_perm(Thai_doff_20$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.12576, observed rank = 99, p-value = 0.02\nalternative hypothesis: two.sided\n\n\nThe results observed in 2020 is similar to the previous years.\n\n\n\n\n\n\nGlobal Moran I’s TestMoran I’s Permutations Test\n\n\n\nglobal_moran_test(Thai_doff_21$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.7545, p-value = 0.002939\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.200458201      -0.013513514       0.006034402 \n\n\n\n\n\nset.seed(1238)\nglobal_moran_perm(Thai_doff_21$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.20046, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nGlobal Moran I’s TestMoran I’s Permutations Test\n\n\n\nglobal_moran_test(Thai_doff_22$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.922, p-value = 0.001739\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.216964758      -0.013513514       0.006221729 \n\n\n\n\n\nset.seed(1238)\nglobal_moran_perm(Thai_doff_20$total_count,\n                  Thai_doff_wm$nb,\n                  Thai_doff_wm$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.12576, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#local-measures-of-spatial-autocorrelation",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#local-measures-of-spatial-autocorrelation",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.4 Local Measures of Spatial Autocorrelation",
    "text": "2.4 Local Measures of Spatial Autocorrelation\n\n2.4.1 Local Moran’s I\nIn this section, I will be computing the Local Moran’s I statistics for the drug related offences and visualising them on maps. To achieve this, I will be using the local_moran() function of the sfdep package.\n\nlocal_moran17 &lt;- Thai_doff_17 %&gt;% \n mutate(local_moran = local_moran(total_count, Thai_doff_wm$nb, Thai_doff_wm$wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran, names_sep = \"_\")\n\nlocal_moran18 &lt;- Thai_doff_18 %&gt;% \n mutate(local_moran = local_moran(total_count, Thai_doff_wm$nb, Thai_doff_wm$wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran, names_sep = \"_\")\n\nlocal_moran19 &lt;- Thai_doff_19 %&gt;% \n mutate(local_moran = local_moran(total_count, Thai_doff_wm$nb, Thai_doff_wm$wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran, names_sep = \"_\")\n\nlocal_moran20 &lt;- Thai_doff_20 %&gt;% \n mutate(local_moran = local_moran(total_count, Thai_doff_wm$nb, Thai_doff_wm$wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran, names_sep = \"_\")\n\nlocal_moran21 &lt;- Thai_doff_21 %&gt;% \n mutate(local_moran = local_moran(total_count, Thai_doff_wm$nb, Thai_doff_wm$wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran, names_sep = \"_\")\n\nlocal_moran22 &lt;- Thai_doff_22 %&gt;% \n mutate(local_moran = local_moran(total_count, Thai_doff_wm$nb, Thai_doff_wm$wt, nsim=99),\n         .before=1) %&gt;% \n  unnest(local_moran, names_sep = \"_\")\n\nWe will now plot these statistics on maps using functions of the tmap package.\n\n201720182019202020212022\n\n\n\ntmap_mode(\"plot\") +\ntm_shape(local_moran17) + \n  tm_fill(\"local_moran_ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"2017\",\n            main.title.size= 1)\n\ntmap mode set to plotting\n\n\nVariable(s) \"local_moran_ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")  +\ntm_shape(local_moran18) + \n  tm_fill(\"local_moran_ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"2018\",\n            main.title.size= 1)\n\ntmap mode set to plotting\n\n\nVariable(s) \"local_moran_ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\") +\ntm_shape(local_moran19) + \n  tm_fill(\"local_moran_ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"2019\",\n            main.title.size= 1)\n\ntmap mode set to plotting\n\n\nVariable(s) \"local_moran_ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\") +\ntm_shape(local_moran20) + \n  tm_fill(\"local_moran_ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"2020\",\n            main.title.size= 1)\n\ntmap mode set to plotting\n\n\nVariable(s) \"local_moran_ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\") +\ntm_shape(local_moran21) + \n  tm_fill(\"local_moran_ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"2021\",\n            main.title.size= 1)\n\ntmap mode set to plotting\n\n\nVariable(s) \"local_moran_ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\") +\ntm_shape(local_moran22) + \n  tm_fill(\"local_moran_ii\") +\n  tm_borders(alpha = 0.5) + \ntm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"2022\",\n            main.title.size= 1)\n\ntmap mode set to plotting\n\n\nVariable(s) \"local_moran_ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\nI see that throughout the years, more regions become positively autocorrelated, reflected by the darker orange areas in 2018 becoming green over the years. This indicates that areas with drastically different drug abuse cases in the earlier years, became more positively correlated with their neighbours as the years progressed. This may indicate that the drug abuse practices might have influenced neighbouring areas.\n\n\n2.4.2 Visualising the LISA maps by Year\nI will now plot the LISA maps by year. To do this, I will first filter out the values that are significantly smaller than the significance level of 0.05. I will then plot it with the Local Moran I’s statistic.\n\n201720182019202020212022\n\n\n\nlisa_sig17&lt;- local_moran17 %&gt;% \n  filter(local_moran_p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(Thai_doff_17) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig17) +\n  tm_fill(\"local_moran_mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig18&lt;- local_moran18 %&gt;% \n  filter(local_moran_p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(local_moran18) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig18) +\n  tm_fill(\"local_moran_mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig19&lt;- local_moran19 %&gt;% \n  filter(local_moran_p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(local_moran19) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig19) +\n  tm_fill(\"local_moran_mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig20&lt;- local_moran20 %&gt;% \n  filter(local_moran_p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(local_moran20) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig20) +\n  tm_fill(\"local_moran_mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig21&lt;- local_moran21 %&gt;% \n  filter(local_moran_p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(local_moran21) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig21) +\n  tm_fill(\"local_moran_mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig22&lt;- local_moran22 %&gt;% \n  filter(local_moran_p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(local_moran22) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  \n  tm_shape(lisa_sig22) +\n  tm_fill(\"local_moran_mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the LISA maps, I observe a dip in the number of clusters of drug abuse cases from 2017 to 2018, and there seems to be minimal change in the years 2018 and 2019. However, from 2019-2020, I see more clusters of spatial units with similar number of drug abuse cases forming. In 2021, there appears to be a cold spot for drug-related offences in the western provinces. In the following year, while the cluster of cold spots have decreased, a new cluster of hotspots is observed in the North Eastern provinces."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#hotcold-spot-analysis",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#hotcold-spot-analysis",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.5 Hot/Cold Spot Analysis",
    "text": "2.5 Hot/Cold Spot Analysis\nWe will first come up with a new weights matrix using the inverse distance method. To do this, we will follow our previous method, but instead of using st_weights() to come up with the weights, we will be using st_inverse_distance().\n\nThai_doff_wm_idw&lt;- Thai_doff_17 %&gt;% \n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry, scale=1, alpha=1),\n         .before=1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nℹ In group 1: `fiscal_year = 2017`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\nOnce we have our new dataframe containing the inverse distance weights matrix of the spatial units, we can go on to calculate the Gi* statistic for the drug abuse cases for each of the years. Following that, we will map them on different plots.\n\n2.5.1 Computing the Gi* Statistics\n\n201720182019202020212022\n\n\n\nhcsa17&lt;- Thai_doff_17%&gt;% \n  mutate(local_GI = local_gstar_perm(\n    total_count, Thai_doff_wm_idw$nb, Thai_doff_wm_idw$wt, nsim = 99), \n    .before = 1) %&gt;% \n  unnest(local_GI)\n\n\n\n\nhcsa18&lt;- Thai_doff_18%&gt;% \n  mutate(local_GI = local_gstar_perm(\n    total_count, Thai_doff_wm_idw$nb, Thai_doff_wm_idw$wt, nsim = 99), \n    .before = 1) %&gt;% \n  unnest(local_GI)\n\n\n\n\nhcsa19&lt;- Thai_doff_19%&gt;% \n  mutate(local_GI = local_gstar_perm(\n    total_count, Thai_doff_wm_idw$nb, Thai_doff_wm_idw$wt, nsim = 99), \n    .before = 1) %&gt;% \n  unnest(local_GI)\n\n\n\n\nhcsa20&lt;- Thai_doff_20%&gt;% \n  mutate(local_GI = local_gstar_perm(\n    total_count, Thai_doff_wm_idw$nb, Thai_doff_wm_idw$wt, nsim = 99), \n    .before = 1) %&gt;% \n  unnest(local_GI)\n\n\n\n\nhcsa21&lt;- Thai_doff_21%&gt;% \n  mutate(local_GI = local_gstar_perm(\n    total_count, Thai_doff_wm_idw$nb, Thai_doff_wm_idw$wt, nsim = 99), \n    .before = 1) %&gt;% \n  unnest(local_GI)\n\n\n\n\nhcsa22&lt;- Thai_doff_22%&gt;% \n  mutate(local_GI = local_gstar_perm(\n    total_count, Thai_doff_wm_idw$nb, Thai_doff_wm_idw$wt, nsim = 99), \n    .before = 1) %&gt;% \n  unnest(local_GI)\n\n\n\n\n\n\n2.5.2 Visualising the Gi* Statistic\nI will now be plotting the Gi* Statistic on maps so we can better visualise the hot spot and cold spot areas of drug abuse cases in Thailand over the 6 years.\n\n201720182019202020212022\n\n\n\nHCSA_sig17 &lt;- hcsa17 %&gt;% \n  filter(p_sim &lt;0.05)\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(hcsa17)+\n  tm_polygons() +\n  tm_borders(alpha=0.5) +\n  tm_shape(HCSA_sig17) +\n  tm_fill(\"gi_star\",\n          palette = \"-RdYlGn\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\nHCSA_sig18 &lt;- hcsa18 %&gt;% \n  filter(p_sim &lt;0.05)\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(hcsa18)+\n  tm_polygons() +\n  tm_borders(alpha=0.5) +\n  tm_shape(HCSA_sig18) +\n  tm_fill(\"gi_star\",\n          palette = \"-RdYlGn\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\nHCSA_sig19 &lt;- hcsa19 %&gt;% \n  filter(p_sim &lt;0.05)\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(hcsa19)+\n  tm_polygons() +\n  tm_borders(alpha=0.5) +\n  tm_shape(HCSA_sig19) +\n  tm_fill(\"gi_star\",\n          palette = \"-RdYlGn\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\nHCSA_sig20 &lt;- hcsa20 %&gt;% \n  filter(p_sim &lt;0.05)\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(hcsa20)+\n  tm_polygons() +\n  tm_borders(alpha=0.5) +\n  tm_shape(HCSA_sig20) +\n  tm_fill(\"gi_star\",\n          palette = \"-RdYlGn\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\nHCSA_sig21 &lt;- hcsa21 %&gt;% \n  filter(p_sim &lt;0.05)\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(hcsa21)+\n  tm_polygons() +\n  tm_borders(alpha=0.5) +\n  tm_shape(HCSA_sig21) +\n  tm_fill(\"gi_star\",\n          palette = \"-RdYlGn\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\nHCSA_sig22 &lt;- hcsa22 %&gt;% \n  filter(p_sim &lt;0.05)\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(hcsa22)+\n  tm_polygons() +\n  tm_borders(alpha=0.5) +\n  tm_shape(HCSA_sig22) +\n  tm_fill(\"gi_star\",\n          palette = \"-RdYlGn\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\nThe Gi* statistics plot once again confirm the cold and hotspots observed by the LISA plots earlier. However, it further reveals a cold spot in the Northern Central provinces in 2017. These cold spots drop drastically in the years 2018-2019, further corroborating the pattern revealed by the Local Moran I plots regarding the increase in the drug abuse cases in the neighbouring spatial units.\nI also observe that the capital city of Bangkok had been a hotspot for drug abuse in the years 2017-2020, but not in 2021-2022."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "7 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this hands-on exercise, I will be exploring two different analysis methods:\n\nhierarchical cluster analysis; and\nspatially constrained cluster analysis.\n\nThese methods are mainly used to help achieve Geographical Segmentaion. Geographical segmentation is the process of splitting a region into geographical units based on certain factors or variables. Thus, in this exercise, I will be using geographically referenced multivariate data to split a region into different homogeneous segments.\n\n\nIn this exercise, the region of interest will be Shan State in Myanmar. I will be splitting this region into homogeneous segments on the basis of different means of Communication Technology: Radio, Television, Land Line Phone, Mobile Phone, Computer and Internet at home.\n\n\n\nTwo data sets will be used in this study. They are:\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\n\n\n\nFirstly, we will install the necessary packages needed for this exercise. The R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\n\npacman::p_load(sf, rgdal, sfdep, tidyverse, tmap, corrplot, ggpubr, heatmaply, cluster, ClustGeo, psych,factoextra)\n\nWarning: package 'rgdal' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4/PACKAGES'\n\n\nWarning: 'BiocManager' not available.  Could not check Bioconductor.\n\nPlease use `install.packages('BiocManager')` and then retry.\n\n\nWarning in p_install(package, character.only = TRUE, ...):\n\n\nWarning in library(package, lib.loc = lib.loc, character.only = TRUE,\nlogical.return = TRUE, : there is no package called 'rgdal'\n\n\nWarning in pacman::p_load(sf, rgdal, sfdep, tidyverse, tmap, corrplot, ggpubr, : Failed to install/load:\nrgdal\n\n\n\n\n\nFirst, I will be importing the geospatial data (Township Boundaries Shapefile) and saving it into our R environment. st_read() function of the sf package is used to do this.\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"myanmar_township_boundaries\") %&gt;% \n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\santhyats\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nNext, we will import the aspatial data and save it in our R environment. I will use the read_csv() function of the readr package to do this.\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*100) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*100) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*100) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*100) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*100) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*100) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nWe can now view the summary statistics of the newly derived dataframe/\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 2.105  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:13.895  \n Median : 3559   Median : 244.0   Median : 316.0   Median :21.095  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :21.568  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:26.807  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :48.452  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :11.60   Min.   : 0.278   Min.   : 3.642   Min.   :0.3278  \n 1st Qu.:45.02   1st Qu.: 2.284   1st Qu.:19.014   1st Qu.:1.1832  \n Median :51.72   Median : 3.759   Median :30.527   Median :1.8970  \n Mean   :50.95   Mean   : 5.109   Mean   :31.405   Mean   :2.4393  \n 3rd Qu.:60.64   3rd Qu.: 6.972   3rd Qu.:42.843   3rd Qu.:2.9897  \n Max.   :84.25   Max.   :18.149   Max.   :73.543   Max.   :9.2402  \n  INTERNET_PR     \n Min.   : 0.1041  \n 1st Qu.: 0.8617  \n Median : 2.2829  \n Mean   : 3.0644  \n 3rd Qu.: 4.1281  \n Max.   :11.7985"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#overview",
    "title": "7 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this hands-on exercise, I will be exploring two different analysis methods:\n\nhierarchical cluster analysis; and\nspatially constrained cluster analysis.\n\nThese methods are mainly used to help achieve Geographical Segmentaion. Geographical segmentation is the process of splitting a region into geographical units based on certain factors or variables. Thus, in this exercise, I will be using geographically referenced multivariate data to split a region into different homogeneous segments.\n\n\nIn this exercise, the region of interest will be Shan State in Myanmar. I will be splitting this region into homogeneous segments on the basis of different means of Communication Technology: Radio, Television, Land Line Phone, Mobile Phone, Computer and Internet at home.\n\n\n\nTwo data sets will be used in this study. They are:\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\n\n\n\nFirstly, we will install the necessary packages needed for this exercise. The R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\n\npacman::p_load(sf, rgdal, sfdep, tidyverse, tmap, corrplot, ggpubr, heatmaply, cluster, ClustGeo, psych,factoextra)\n\nWarning: package 'rgdal' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4/PACKAGES'\n\n\nWarning: 'BiocManager' not available.  Could not check Bioconductor.\n\nPlease use `install.packages('BiocManager')` and then retry.\n\n\nWarning in p_install(package, character.only = TRUE, ...):\n\n\nWarning in library(package, lib.loc = lib.loc, character.only = TRUE,\nlogical.return = TRUE, : there is no package called 'rgdal'\n\n\nWarning in pacman::p_load(sf, rgdal, sfdep, tidyverse, tmap, corrplot, ggpubr, : Failed to install/load:\nrgdal\n\n\n\n\n\nFirst, I will be importing the geospatial data (Township Boundaries Shapefile) and saving it into our R environment. st_read() function of the sf package is used to do this.\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"myanmar_township_boundaries\") %&gt;% \n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\santhyats\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nNext, we will import the aspatial data and save it in our R environment. I will use the read_csv() function of the readr package to do this.\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*100) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*100) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*100) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*100) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*100) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*100) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nWe can now view the summary statistics of the newly derived dataframe/\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 2.105  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:13.895  \n Median : 3559   Median : 244.0   Median : 316.0   Median :21.095  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :21.568  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:26.807  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :48.452  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :11.60   Min.   : 0.278   Min.   : 3.642   Min.   :0.3278  \n 1st Qu.:45.02   1st Qu.: 2.284   1st Qu.:19.014   1st Qu.:1.1832  \n Median :51.72   Median : 3.759   Median :30.527   Median :1.8970  \n Mean   :50.95   Mean   : 5.109   Mean   :31.405   Mean   :2.4393  \n 3rd Qu.:60.64   3rd Qu.: 6.972   3rd Qu.:42.843   3rd Qu.:2.9897  \n Max.   :84.25   Max.   :18.149   Max.   :73.543   Max.   :9.2402  \n  INTERNET_PR     \n Min.   : 0.1041  \n 1st Qu.: 0.8617  \n Median : 2.2829  \n Mean   : 3.0644  \n 3rd Qu.: 4.1281  \n Max.   :11.7985"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#exploratory-data-analysis-eda",
    "title": "7 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.1 Exploratory Data Analysis (EDA)",
    "text": "7.1 Exploratory Data Analysis (EDA)\n\n7.1.1 Statistical Graphs\nWe can plot the distribution of the variables (i.e. Number of households with radio) by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution). Here, I have used one of our newly derived columns, RADIO_PR, as an example.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"lavender\")\n\n\n\n\n\n\n\n\nWe can also make use of Boxplots to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"navy\")\n\n\n\n\n\n\n\n\nFrom these plots, we can observe that the distribution of the penetration rates by Radio is slightly right-skewed and there is one value that is observed to be an outlier.\nI will now plot the histograms for the rest of the derived values by using the code chunk below. ggarrange() of the ggplot package is used to control the layout of the output plots.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"lavender\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"lavender\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"lavender\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"lavender\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"lavender\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"lavender\")\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\n\n\n\n\nWe can observe that the distribution of penetration rates of computers, internet and landline phones are very much right skewed. That of radio and mobile phone penetration rates are slightly right skewed while the distribution of penetration rates of TV appear to be more normally distributed.\n\n\n7.1.2 Chloropeth Maps\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\nIn order to reveal the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the dsitribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\n\n\n\n\nWe can now observe that they are not completely positively correlated. Areas with larger number of households do not necessarily have larger penetration rates."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#correlation-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#correlation-analysis",
    "title": "7 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.2 Correlation Analysis",
    "text": "7.2 Correlation Analysis\nBefore we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.\nIn this section, you will learn how to use corrplot.mixed() function of corrplot package to visualise and analyse the correlation of the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis instead of both."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#hierarchy-cluster-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#hierarchy-cluster-analysis",
    "title": "7 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.3 Hierarchy Cluster Analysis",
    "text": "7.3 Hierarchy Cluster Analysis\n\n7.3.1 Extracting Clustering Variables\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 28.61852 55.41313   3.530618  26.06944    1.215939\n2    Pindaya 41.74647 50.51300   1.983584  16.23917    1.288190\n3    Ywangan 48.45215 26.05734   1.193591  12.02856    0.441465\n4   Pinlaung 23.16499 54.17189   2.854454  24.94903    1.376255\n5     Mabein 44.94903 70.86423   7.275255  39.26089    1.645042\n6      Kalaw 28.07624 61.16204   4.206478  40.87951    2.963160\n7      Pekon 31.86118 53.58494   3.983270  21.48476    1.897032\n8   Lawksawk 38.71017 63.00035   3.151366  32.05686    2.176677\n9  Nawnghkio 34.93359 54.79456   3.844960  32.30201    1.576465\n10   Kyaukme 21.09548 60.11773   3.958267  37.24930    3.094709\n\n\nThe final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR. Next, we will change the rows by township name instead of row number by using the code chunk below.\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 28.61852 55.41313   3.530618  26.06944    1.215939\nPindaya     Pindaya 41.74647 50.51300   1.983584  16.23917    1.288190\nYwangan     Ywangan 48.45215 26.05734   1.193591  12.02856    0.441465\nPinlaung   Pinlaung 23.16499 54.17189   2.854454  24.94903    1.376255\nMabein       Mabein 44.94903 70.86423   7.275255  39.26089    1.645042\nKalaw         Kalaw 28.07624 61.16204   4.206478  40.87951    2.963160\nPekon         Pekon 31.86118 53.58494   3.983270  21.48476    1.897032\nLawksawk   Lawksawk 38.71017 63.00035   3.151366  32.05686    2.176677\nNawnghkio Nawnghkio 34.93359 54.79456   3.844960  32.30201    1.576465\nKyaukme     Kyaukme 21.09548 60.11773   3.958267  37.24930    3.094709\n\n\nWe will now delete the TS.x field since it is redundant.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   28.61852 55.41313   3.530618  26.06944    1.215939\nPindaya   41.74647 50.51300   1.983584  16.23917    1.288190\nYwangan   48.45215 26.05734   1.193591  12.02856    0.441465\nPinlaung  23.16499 54.17189   2.854454  24.94903    1.376255\nMabein    44.94903 70.86423   7.275255  39.26089    1.645042\nKalaw     28.07624 61.16204   4.206478  40.87951    2.963160\nPekon     31.86118 53.58494   3.983270  21.48476    1.897032\nLawksawk  38.71017 63.00035   3.151366  32.05686    2.176677\nNawnghkio 34.93359 54.79456   3.844960  32.30201    1.576465\nKyaukme   21.09548 60.11773   3.958267  37.24930    3.094709\n\nwrite_rds(shan_ict, \"data/rds/shan_ict.rds\")\n\n\n\n7.3.2 Data Standardisation\nIn general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid the cluster analysis result being baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n7.3.2.1 Min-Max Standardisation\nIn the code chunk below, normalize() of heatmaply package is used to stadardise the clustering variables by using Min-Max method. The summary()  function is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nThe value ranges of the clustering variables are now 0-1.\n\n\n7.3.2.2 Z-score Standardisation\nZ-score standardisation can be performed easily by using scale() of Base R. The code chunk below will be used to stadardisE the clustering variables by using Z-score method. describe() of the psych package is used instead of summary().\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\n** It is important to note that Z-score standardisation method should only be used if all variables are assumed to be normally distributed.\n\n\n\n7.3.3 Visualising the standardised clustering variables\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphically. The code chunk below plot the scaled Radio_PR field.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"lavender\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"lavender\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"lavender\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\nBoth methods of standardisation work well if the distribution of the original variable is similar/close to a normal distribution, and would give similar results after standardising.\nWe can also plot density maps to visualise the distribution.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"lavender\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"lavender\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"lavender\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n7.3.4 Computing Proximity Matrix\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R. dist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    17.186828                                                  \nYwangan    38.188259 25.731610                                        \nPinlaung    5.746286 20.863519 40.005492                              \nMabein     26.337099 31.345776 52.914689 31.266966                    \nKalaw      16.005997 30.251785 49.953297 18.196406 19.814085          \nPekon       5.961977 11.791580 33.650410  9.461225 28.226877 21.191531\nLawksawk   14.011550 20.432952 43.216535 19.257320 13.036525 14.001101\nNawnghkio   8.907103 18.064047 37.787702 13.927495 20.463154 12.774787\nKyaukme    14.402475 31.101487 50.589191 13.967966 26.488283  7.942225\nMuse       56.301629 70.411252 89.944137 57.158335 45.327410 41.246033\nLaihka     14.187227 29.861288 49.183321 10.110150 34.500222 19.734633\nMongnai    11.586190 25.849346 42.271934  6.452387 35.886053 20.034668\nMawkmai    43.492968 43.799577 39.703752 39.811227 69.324602 56.259200\nKutkai      9.761092 21.281775 36.011861  7.807733 34.055064 20.493018\nMongton    19.267961 28.335574 36.123257 16.342143 42.516902 26.787522\nMongyai    25.672744 28.741816 33.312853 22.056339 51.640426 38.674701\nMongkaing  50.361965 48.171125 36.498429 47.629056 74.717454 62.524500\nLashio     25.129457 39.898167 60.217475 26.251735 23.128227 10.669059\nMongpan    19.332063 33.572896 48.368125 19.278316 30.152942 11.469105\nMatman     40.125041 35.439039 25.522031 38.240610 63.753975 53.763884\nTachileik  52.963213 63.551774 80.744220 55.501039 36.532538 37.364459\nNarphan    40.615714 47.450209 45.295769 37.126895 63.034312 46.353759\nMongkhet   34.945980 39.174783 40.897731 30.586058 61.030557 46.552013\nHsipaw     11.818050 24.598884 38.863147  7.655260 36.642787 21.236711\nMonghsat   21.420854 31.471506 43.298028 16.044703 47.048135 31.796188\nMongmao    24.254541 40.221719 54.285957 21.758854 38.491867 19.518913\nNansang    10.491839 27.544246 47.277637  8.549572 28.792364 12.430500\nLaukkaing  56.827732 72.685355 90.882520 56.381750 52.067373 42.777791\nPangsang   27.267383 42.824958 55.682263 24.447146 41.854016 22.403998\nNamtu      17.962251 22.540822 44.466868 17.004533 36.616094 30.727427\nMonghpyak  17.776325 22.130579 36.744835 22.220020 21.269450 16.708436\nKonkyan    40.339082 50.086933 52.812533 36.544693 61.351206 44.475859\nMongping   26.512574 31.064850 33.794020 22.975261 51.816310 37.564739\nHopong     13.693111 22.306050 35.285844  9.814855 39.800917 26.416294\nNyaungshwe  9.938590 21.652463 40.711649 13.812050 21.021337  9.566782\nHsihseng   13.149728 17.200796 34.291035 11.161846 38.120187 28.711074\nMongla     38.430076 54.942389 72.816301 37.259678 40.609124 26.026411\nHseni      18.937188 33.798982 53.444679 20.447572 21.361240  3.852842\nKunlong    22.412169 35.547066 53.163089 19.476257 39.661508 27.301375\nHopang     28.105362 44.326362 59.619312 26.596924 36.855167 18.514704\nNamhkan    38.602794 54.381859 71.443173 38.278835 37.956035 24.639577\nKengtung   24.645691 38.568322 57.323173 26.348638 21.947071  8.829335\nLangkho    16.426299 32.328133 50.778892 16.844228 25.384371  6.719580\nMonghsu    10.915790 19.835391 34.042789  8.086834 36.719820 23.734578\nTaunggyi   39.984278 50.375471 69.798323 42.954386 22.624011 25.226066\nPangwaun   38.151246 51.213162 58.013146 35.637963 52.344632 33.835194\nKyethi     20.292551 17.554012 28.729358 18.947065 44.207679 36.017247\nLoilen     14.548666 29.361143 46.951621  9.156527 37.506406 21.719877\nManton     43.064070 40.242888 30.616379 40.583081 67.401120 56.016577\nMongyang   30.951302 47.593982 63.071590 28.603834 41.188352 23.356349\nKunhing    17.350424 31.823811 44.967218 14.158836 37.582140 19.763683\nMongyawng  21.421738 33.292193 57.056521 23.555497 19.349994 17.343078\nTangyan    19.592520 20.843740 32.477002 16.950567 44.859948 34.806617\nNamhsan    23.778494 22.841073 28.616305 21.433352 48.833873 38.588676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   15.751129                                                  \nNawnghkio  11.315370  9.082891                                        \nKyaukme    20.212206 18.629066 15.704230                              \nMuse       61.456144 51.013288 53.368806 43.475768                    \nLaihka     18.223667 24.674469 21.188187 12.824979 52.665211          \nMongnai    15.160031 24.171260 18.221245 14.245669 57.197975 10.053457\nMawkmai    41.600669 56.752693 49.515047 51.202846 92.693007 42.996554\nKutkai     11.498048 22.464646 14.744053 17.093318 59.290743 14.467198\nMongton    20.814888 31.107742 22.581118 22.928509 63.471074 21.207320\nMongyai    24.252301 39.126989 31.957938 33.927780 76.391399 26.413364\nMongkaing  48.023965 62.518712 54.669447 58.605094 99.566496 52.296309\nLashio     30.380011 22.075270 23.055346 12.995255 31.315288 23.864533\nMongpan    24.330037 22.854223 17.284425 11.037831 44.749969 21.076951\nMatman     36.825761 51.539711 44.405061 50.552285 92.911283 44.325453\nTachileik  57.339528 44.182621 47.045533 42.915493 22.119950 54.908985\nNarphan    41.684901 52.369580 43.559661 42.030003 77.040234 39.232592\nMongkhet   34.208722 48.741102 41.410280 40.903553 81.644931 32.497428\nHsipaw     14.537542 24.935081 17.609570 16.395741 59.103355 12.842987\nMonghsat   22.564279 35.231496 28.983220 25.325370 66.376026 15.893517\nMongmao    29.370625 31.464777 25.776465 14.609228 45.182530 18.599082\nNansang    16.037607 18.878869 15.113185  6.032773 48.935308  7.878999\nLaukkaing  62.482399 54.883928 55.265554 42.874978 14.926996 50.739700\nPangsang   32.181214 34.591486 28.710769 17.535273 46.024292 21.419291\nNamtu      16.502707 26.095300 25.752713 27.087277 65.916927 18.586794\nMonghpyak  19.093173 14.231691  9.303711 21.764419 53.943485 29.322640\nKonkyan    42.148797 52.031264 43.934272 39.379911 70.486973 35.175354\nMongping   25.968288 39.647081 31.614719 33.028984 74.444948 27.282761\nHopong     13.886577 27.491604 20.488286 21.884211 64.868011 15.748857\nNyaungshwe 13.931874 10.417830  4.326545 12.650414 50.588581 20.171653\nHsihseng   10.530573 25.711202 20.988026 25.027059 67.766886 17.589761\nMongla     44.120998 39.318472 38.140808 24.158966 25.680556 31.593218\nHseni      24.398001 17.150398 16.405304  8.120593 38.130567 20.449010\nKunlong    24.936301 31.830406 28.504608 21.563037 54.724297 12.268682\nHopang     33.638582 32.116462 27.984188 15.491633 37.744407 23.078652\nNamhkan    44.277120 37.941126 36.733575 24.781990 23.867060 34.243665\nKengtung   29.767761 20.938215 20.829647 13.623356 33.008211 25.823950\nLangkho    21.921623 19.030257 15.651662  5.167279 41.364173 16.094435\nMonghsu    11.384636 24.204063 17.009168 20.077712 63.321624 16.328926\nTaunggyi   44.066133 30.496838 34.479200 31.260547 25.081471 42.536916\nPangwaun   42.381347 45.302765 38.167478 30.831407 54.197887 35.178203\nKyethi     16.243575 31.774604 26.721607 32.814177 75.716745 25.583275\nLoilen     18.194596 26.529318 21.926405 14.692675 56.043400  5.969478\nManton     40.382131 55.113000 47.577296 52.286003 94.149778 45.830232\nMongyang   36.358788 36.337684 32.332123 18.859489 38.959919 22.971502\nKunhing    21.346379 27.868953 20.615773 14.500266 53.300162 14.203682\nMongyawng  24.843910 17.907229 22.061209 18.155295 42.237358 21.199976\nTangyan    16.779937 32.314701 26.907880 30.678359 73.693741 22.429176\nNamhsan    20.716559 36.284062 29.974967 34.785944 77.852971 27.379672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    37.450873                                                  \nKutkai      9.115307 36.495519                                        \nMongton    13.167061 31.335220 10.706341                              \nMongyai    20.323607 17.870499 18.894166 15.979790                    \nMongkaing  45.600842 13.329995 42.896133 36.550032 26.284016          \nLashio     27.086983 63.860773 28.982513 34.711584 46.636472 70.865819\nMongpan    17.809554 50.999632 18.518173 20.031803 34.639710 56.356780\nMatman     37.633870 14.783545 34.086349 30.304574 18.695158 13.551424\nTachileik  56.395232 91.938755 56.899109 60.876740 75.029555 96.714087\nNarphan    32.931700 27.375350 31.427683 21.597925 24.882845 28.565085\nMongkhet   27.576855 11.558388 27.391673 22.322828 10.498924 22.260577\nHsipaw      5.268195 35.134601  5.146282  9.069766 17.733790 42.377868\nMonghsat   12.525968 27.509705 15.432012 15.098053 12.735225 37.560376\nMongmao    18.829603 48.552853 20.469232 20.657001 33.561300 55.231959\nNansang     9.279567 46.241938 13.004549 19.958124 28.855962 54.216609\nLaukkaing  55.156800 88.251110 58.038112 60.466190 73.268347 95.411795\nPangsang   20.425746 48.414757 22.833583 21.077938 34.330638 54.840662\nNamtu      20.935473 42.795451 22.528268 30.871751 27.802761 52.504057\nMonghpyak  25.326470 53.671695 20.661627 25.804282 37.001575 56.821089\nKonkyan    32.882831 33.901411 31.060810 24.825265 28.787384 38.092091\nMongping   20.299615 19.431049 18.275266 11.986993  6.538727 25.718572\nHopong      9.153795 30.284362  7.345899 10.621031 12.462791 37.937916\nNyaungshwe 16.963695 50.299026 15.215482 21.972196 32.713541 55.732112\nHsihseng   14.236728 32.929477 12.821054 19.464317 16.227126 41.159788\nMongla     35.410985 68.688950 38.840984 41.106668 53.528615 76.148327\nHseni      21.681639 58.253670 22.937894 28.675945 40.823212 64.804408\nKunlong    20.292529 44.653763 20.454010 27.002165 29.936066 53.991284\nHopang     24.300945 56.124281 26.331986 27.350305 40.873288 62.617673\nNamhkan    37.005669 70.647792 39.248568 41.453594 55.062819 77.139688\nKengtung   27.228711 63.254638 27.919573 32.938387 46.039706 69.274693\nLangkho    17.467678 53.108019 18.051419 23.670878 35.895672 59.742714\nMonghsu     8.411238 33.207962  6.260859 10.704894 15.486049 40.071816\nTaunggyi   44.855282 81.074692 45.033382 50.840925 63.594105 86.621117\nPangwaun   31.213429 50.068857 32.180465 25.750434 39.407696 53.695736\nKyethi     21.050453 27.885535 18.423422 22.252947 13.779420 35.206533\nLoilen      5.841263 38.873386 13.156529 17.616001 22.479239 48.218190\nManton     39.154062 10.908779 36.182684 31.020581 19.559882  8.175337\nMongyang   26.039387 55.883162 28.533223 29.560023 41.431237 63.191325\nKunhing    11.055197 39.843973 10.884990 11.403609 23.899570 46.503971\nMongyawng  27.577546 62.004321 28.103383 37.522688 44.578964 70.098284\nTangyan    18.037471 26.266006 16.661820 19.888460 10.908506 34.856123\nNamhsan    21.810003 21.519289 19.132762 19.676188  7.735900 28.866231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    17.233279                                                  \nMatman     62.811049 49.481014                                        \nTachileik  31.195286 41.103849 89.012935                              \nNarphan    52.563854 37.113393 31.205193 76.029566                    \nMongkhet   53.444463 41.217123 20.302855 82.050164 21.728718          \nHsipaw     29.086435 17.952054 34.445451 57.618780 29.540170 25.380950\nMonghsat   37.786793 28.330992 31.359911 67.709508 27.821548 16.798445\nMongmao    21.423677 13.159966 50.159903 47.295568 33.142618 37.535820\nNansang    18.447950 14.477393 45.806573 48.677266 39.813308 36.099219\nLaukkaing  33.465738 43.558047 90.372094 32.506329 70.882887 76.906406\nPangsang   23.672516 14.023910 50.629940 48.131907 31.630314 37.558139\nNamtu      36.588437 35.291394 41.665397 65.956458 49.436143 35.599713\nMonghpyak  26.209281 18.785699 47.046845 44.404411 44.840651 46.263265\nKonkyan    48.551312 36.587588 39.240306 73.092980 15.882353 25.424424\nMongping   45.452548 31.847482 20.165224 72.708969 18.864567 11.380917\nHopong     34.531042 23.943845 29.184351 63.245718 29.440441 21.299485\nNyaungshwe 20.158191 13.729734 46.091883 44.581335 42.794086 41.708639\nHsihseng   36.900833 29.587811 30.402806 65.887060 37.752977 25.670338\nMongla     17.995877 25.320001 70.817595 34.733155 53.146949 57.440292\nHseni       7.941836 12.066550 56.464051 35.490063 47.412297 48.188406\nKunlong    29.523103 28.803320 46.827436 59.570536 41.307823 34.168641\nHopang     17.063913 13.562913 57.355355 40.382035 39.785908 45.151070\nNamhkan    17.327153 24.034131 71.542102 29.591660 53.685519 59.619944\nKengtung    5.985893 14.221554 61.301033 29.590429 50.540025 53.135998\nLangkho    11.518145  9.498486 51.886151 40.233622 42.065204 42.808061\nMonghsu    32.571557 21.625326 30.813805 60.502113 31.192379 24.773318\nTaunggyi   19.514541 31.981385 77.845810 15.084117 68.420905 71.280752\nPangwaun   36.245608 23.252209 52.343600 54.060474 26.464997 40.702947\nKyethi     44.710266 35.889620 23.383079 72.887329 37.490376 23.325039\nLoilen     26.892310 20.725000 40.656282 57.375476 35.479137 28.476895\nManton     64.666493 50.796808  5.952318 91.023039 28.026395 18.133894\nMongyang   20.933700 19.493467 58.561776 44.879027 40.139475 44.540621\nKunhing    25.510832 13.785278 40.366587 53.226397 28.162645 29.249814\nMongyawng  17.270139 27.515989 60.180824 43.210118 57.276394 52.291815\nTangyan    42.984475 34.039128 24.278233 71.984066 34.884991 20.149393\nNamhsan    47.204024 36.477086 18.009747 75.403913 31.654695 17.090848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   12.178922                                                  \nMongmao    18.599483 24.717708                                        \nNansang    12.024428 20.192690 16.499494                              \nLaukkaing  56.906099 62.644910 40.400848 48.060074                    \nPangsang   20.504337 25.637933  5.760801 19.336162 40.804016          \nNamtu      22.944658 23.178673 36.503882 21.761884 66.406286 39.297391\nMonghpyak  23.767919 35.684917 29.188846 22.752638 56.584279 31.511651\nKonkyan    29.674316 26.825060 28.187425 37.470456 63.592043 27.481900\nMongping   16.892101 14.095392 30.557166 28.736626 70.813447 30.833123\nHopong      6.286179 10.045714 24.416253 16.766291 62.848557 26.151075\nNyaungshwe 16.992664 28.637238 23.045003 13.118943 52.024345 25.777823\nHsihseng   13.654610 15.349551 31.198001 19.353779 67.074564 33.552974\nMongla     37.347509 42.900536 21.624705 28.945119 20.255831 21.788123\nHseni      23.148538 33.122632 18.467099 13.645492 39.174585 21.466375\nKunlong    20.510051 20.231862 22.443391 18.301388 52.188657 25.849342\nHopang     24.872536 31.764824  7.829342 19.647091 33.167199  9.257672\nNamhkan    38.279302 45.510875 22.332205 30.289487 19.646063 23.138484\nKengtung   28.408582 38.372138 20.758055 19.367980 35.148520 22.985484\nLangkho    18.305109 27.952329 13.450170  9.939859 41.041270 16.765920\nMonghsu     5.855724 13.724737 24.243599 15.359962 61.901766 26.052971\nTaunggyi   46.231183 56.288102 38.733906 36.504897 34.598041 40.559730\nPangwaun   29.812447 34.353898 18.740057 32.612960 47.063605 15.748757\nKyethi     19.517677 19.050609 37.789657 27.302385 74.999415 39.689963\nLoilen      9.804789 11.865144 19.026490  9.423028 53.557527 20.794433\nManton     35.960008 31.715603 50.379786 47.655544 90.738406 50.475214\nMongyang   26.710497 31.264797  9.106281 21.849285 32.619219 10.837735\nKunhing     9.077517 16.538834 10.391040 12.820940 50.041640 12.318870\nMongyawng  29.470967 36.440429 29.640789 19.111990 45.480044 33.616703\nTangyan    16.769794 14.459626 34.714183 24.970235 72.240954 36.476893\nNamhsan    19.447928 16.956962 37.171448 29.416284 76.045960 38.565526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  34.657799                                                   \nKonkyan    47.837690 46.339594                                         \nMongping   32.166441 35.476537 24.202901                               \nHopong     20.682668 26.795563 30.449287 13.400139                     \nNyaungshwe 27.141464 10.397300 43.235040 31.932583 20.932532           \nHsihseng   13.189940 28.537627 38.349700 19.964389  9.165458  22.580242\nMongla     48.349434 40.803397 46.809747 51.261580 43.231105  34.760273\nHseni      32.741448 20.026876 44.884563 39.558453 28.641193  13.086310\nKunlong    23.360474 35.744661 32.911433 30.905385 21.906817  28.513095\nHopang     40.824516 30.426577 34.818522 37.927212 30.977356  24.719891\nNamhkan    50.632466 37.950202 48.159596 52.374815 44.413246  33.332428\nKengtung   38.533554 22.147613 47.482621 44.280821 34.047382  17.775714\nLangkho    30.503473 20.027496 38.695022 34.396455 23.963685  12.826577\nMonghsu    20.964684 23.217823 33.172187 15.890478  4.340665  17.382799\nTaunggyi   51.872748 33.417439 65.056905 62.153039 51.376415  32.509619\nPangwaun   51.703554 38.195144 26.397576 34.037881 34.600673  35.292324\nKyethi     18.690932 32.816234 40.010989 18.743974 13.649038  28.806872\nLoilen     19.424075 29.699681 33.419820 23.199959 12.474445  20.640432\nManton     44.858230 50.220840 36.666876 20.048082 31.058885  48.879874\nMongyang   41.326052 35.817599 32.939338 38.780686 32.335704  29.429500\nKunhing    29.643996 25.074435 25.374202 21.259619 14.515617  18.997131\nMongyawng  26.224331 28.556475 52.238580 45.559190 32.659925  21.812104\nTangyan    17.869483 33.526416 36.746064 16.167411 10.682328  28.414692\nNamhsan    24.095555 35.270492 35.220115 13.023777 13.270541  31.591750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     47.866210                                                  \nHseni      31.274375 22.682048                                        \nKunlong    23.185967 34.646200 27.619175                              \nHopang     37.001334 14.702444 16.280878 27.134451                    \nNamhkan    49.209476  7.721355 21.211323 37.573885 14.618632          \nKengtung   37.072441 20.245004  6.612817 31.714187 16.429921 17.563015\nLangkho    27.627441 22.901675  6.666133 22.452741 13.424847 22.440029\nMonghsu     9.782470 42.451868 26.228462 23.989665 30.184458 43.132637\nTaunggyi   52.814240 29.709863 23.819389 47.129032 32.995252 25.729147\nPangwaun   43.306326 31.918643 33.070182 39.245403 20.698364 31.044067\nKyethi      8.404049 55.602500 38.833498 29.855859 44.048114 56.786202\nLoilen     15.884853 33.867408 22.710984 16.653599 24.289326 36.490647\nManton     33.487758 71.251416 58.463341 47.976855 57.752046 72.186149\nMongyang   38.259743 14.666661 21.019929 24.722785  6.925859 16.772448\nKunhing    22.015490 30.647566 20.647448 19.377551 17.296164 31.492119\nMongyawng  30.951462 31.557550 17.386004 24.039800 29.051360 32.121112\nTangyan     7.027241 52.680849 37.307575 26.807983 41.222167 54.264078\nNamhsan    12.574240 56.402740 41.196125 31.040560 44.051555 57.642717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    10.716213                                                  \nMonghsu    31.691914 22.184918                                        \nTaunggyi   18.628225 28.827478 48.691951                              \nPangwaun   33.748335 29.538434 34.338498 49.761245                    \nKyethi     44.426274 35.091512 14.661572 59.957407 47.662610          \nLoilen     28.222935 18.410672 13.155208 45.591617 33.169981 23.232965\nManton     63.199123 53.595620 33.076503 80.308034 51.079265 27.203299\nMongyang   21.708047 17.535413 32.395988 37.458247 22.525026 45.386726\nKunhing    24.595083 14.638284 14.678891 42.998509 22.909986 27.895182\nMongyawng  20.387199 18.611584 31.285089 28.773864 47.533116 38.771518\nTangyan    42.995076 33.202048 12.742203 59.265262 44.705580  4.779331\nNamhsan    46.620497 36.820978 15.322576 63.149232 44.858030  6.867929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     41.906087                                                  \nMongyang   24.676592 58.570558                                        \nKunhing    13.039336 41.049230 18.889405                              \nMongyawng  26.175211 62.943339 30.421734 29.535984                    \nTangyan    19.660826 27.182672 42.106366 24.974161 37.752279          \nNamhsan    24.215271 21.048485 45.097869 27.079121 43.002019  6.367613\n\n\n\n\n7.3.5 Computing Hierarchical Clustering\nIn R, there are several packages provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used. hclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n7.3.6 Selecting Optimal Clustering Algorithm\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n7.3.7 Determining Optimal Clusters\nAnother technical challenge faced by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n7.3.7.3 Gap Statistic Method\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 6.104544 6.378209 0.2736651 0.04460994\n [2,] 5.827444 6.048127 0.2206824 0.03880130\n [3,] 5.689680 5.899965 0.2102844 0.03362652\n [4,] 5.559639 5.778070 0.2184311 0.03784781\n [5,] 5.453876 5.675437 0.2215615 0.03897071\n [6,] 5.363009 5.585192 0.2221833 0.03973087\n [7,] 5.288334 5.503748 0.2154145 0.04054939\n [8,] 5.224095 5.429034 0.2049390 0.04198644\n [9,] 5.155439 5.358210 0.2027705 0.04421874\n[10,] 5.074827 5.291273 0.2164465 0.04540947\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examining the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\n\n\n\n7.3.8 Interpreting the Dendograms\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\n\n7.3.9 Visually-driven hierarchical clustering analysis\nIn this section, we will perform visually-driven hiearchical clustering analysis by using heatmaply package. With heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n7.3.9.1 Transforming the Dataframe into a Matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make a heatmap. The code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n7.3.9.2 Plotting interactive cluster heatmap\nWe will now plot the interactive cluster heatmap. heatmap() function of the heatmaply package will be used to achieve this.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Purples,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n7.3.10 Mapping the clusters formed\nWith close examination of the dendragram above, we have decided to retain six clusters. cutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nThe output is called groups and it is a list object. In order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nFinally, we can use qtm() to plot a chloropeth map to show the clusters formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#learning-points",
    "href": "Take-Home_Exercises/Take-Home_Ex02/Take-Home_Ex02.html#learning-points",
    "title": "Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.6 Learning Points",
    "text": "2.6 Learning Points\nFrom this Take-Home Exercise, I have learnt:\n\nUsing appropriate methods to import files of different data types\nThe importance of looking through the data once it’s been downloaded to the R environment to see what needs to be processed\nThe importance of checking if the the downloaded data has been saved in an appropriate datatype that can be used in our analysis\nThe importance of knowing the geograpahical area and its features earlier. (Accounting for disconnected boundaries and islands)\nKnowing alternate methods of handling the case where spatial units have missing neighbours\nInterpreting Global and Local Moran I’s values in specific contexts\nInterpreting Lisa Maps and understanding their link to GI* statistic analysis"
  }
]