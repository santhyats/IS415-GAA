{
  "hash": "5f25b7940f46ccef6b0020022fedc91e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In Class Exercise 5- Geographically Weighted Summary Statistics\"\nauthor: \"Santhya Selvan\"\ndate: \"September 16 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  freeze: true\n---\n\n\n## 5.0 Getting started\n\nFirstly, we will download the necessary packages into our environment\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, spdep, tmap, tidyverse, GWmodel)\n```\n:::\n\n\n#### 5.0.1 Downloading the data\n\nWe will then read the datafiles into sf objects\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_sf<- st_read(dsn='data/geospatial',\n                layer='Hunan')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan2012_sf<- read_csv(\"data/aspatial/Hunan_2012.csv\")\n```\n:::\n\n\nWe will now perform a left join of the 2 sf objects based on their common identifiers\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_sf<-left_join(hunan_sf, hunan2012_sf) %>% \n  select(1:3, 7, 15, 16, 31, 32)\n```\n:::\n\n\nIt is recommended that we check for common columns with the same values before we perform the join, so that the tables can be joined using the column. We would also perform the join first before looking at the columns that are necessary for us and selecting them accordingly.\n\nWe can save this new sf object into a new rds file, so we can keep track of our processed data that we have used for the task.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(hunan_sf, \"data/rds/hunan_sf.rds\")\n```\n:::\n\n\nIf we want to access this newly processed data, we will simply use the read_rds function and pass in the file path. We can make use of the echo: false to hide this code chunk on the render, so the data processing can be handled on the backend.\n\n\n::: {.cell}\n\n:::\n\n\n## 5.1 Visualising the prepared data\n\n### 5.1.1 Converting to SpatialPolygonDataframe\n\nGWmodel uses the sp data object to handle spatial data in r. As such, we will now convert our sf object to a spatial polygon dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_sp<- hunan_sf %>% \n  as_Spatial()\n```\n:::\n\n\n#### 5.1.2 Determine the Adaptive Bandwidth\n\nThere are 2 methods we can use to derive the adaptive bandwidth, AIC and Cross-Validation (CV). To toggle between approaches, we can just set the approach field to our required method.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_AIC<- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp, \n                approach = 'AIC',\n                adaptive= TRUE, \n                kernel = 'bisquare',\n                longlat = T\n                )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n```\n\n\n:::\n\n```{.r .cell-code}\nbw_AIC\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 22\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_CV<-bw.gwr(GDPPC ~ 1,\n                data = hunan_sp, \n                approach = 'CV',\n                adaptive= TRUE, \n                kernel = 'bisquare',\n                longlat = T\n                )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n```\n\n\n:::\n\n```{.r .cell-code}\nbw_CV\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 22\n```\n\n\n:::\n:::\n\n\n#### 5.1.3 Determining Fixed Bandwidth\n\nTo use Fixed Bandwidth, we just need to change the adaptive field to FALSE.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_CV_f<-bw.gwr(GDPPC ~ 1,\n                data = hunan_sp, \n                approach = 'CV',\n                adaptive= FALSE, \n                kernel = 'bisquare',\n                longlat = T\n                )\n\nbw_CV_f\n```\n:::\n\n\n#### 5.1.4 Computing geoghraphically weighted summary statistics \n\nTo achieve this, we will make use of the gwss() function of the GWmodel package. Take note that the kernel, adaptive, and longlat fields should follow what is stored in our adaptive bandwidth variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngwstat <- gwss(hunan_sp, \n               vars='GDPPC',\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n```\n:::\n\n\n#### 5.1.5 Preparing the output data \n\nWe will now extract the SDF portion of the gwstat_df object and convert it to a new dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngwstat_df<- as.data.frame(gwstat$SDF)\n```\n:::\n\n\nNext, cbind() used to append newly created dataframe onto the hunan_sf dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_gstat <- cbind(hunan_sf, gwstat_df)\n```\n:::\n\n\n#### 5.1.6 Plotting the geographically weighted summary mean\n\nWe can finally map the geographically weighted summary statistics\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(hunan_gstat) + \n  tm_fill('GDPPC_LM',\n          n =5,\n          style = \"quantile\") +\n  tm_borders(alpha=0.5) + \n  tm_layout(main.title=\"Distribution of Geographically Weighted Mean\",\n            main.title.position = 'center',\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height=1.50,\n            legend.width=1.50,\n            frame=TRUE)\n```\n\n::: {.cell-output-display}\n![](In-class_Ex05_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "In-class_Ex05_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}