{
  "hash": "1fdc01ab1bb3162f598675379e1aeb6d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In Class Exercise 5- Geographically Weighted Summary Statistics\"\nauthor: \"Santhya Selvan\"\ndate: \"September 16 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  freeze: true\n---\n\n\n## 5.0 Getting started\n\nFirstly, we will download the necessary packages into our environment\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, spdep, tmap, tidyverse, GWmodel)\n```\n:::\n\n\n#### 5.0.1 Downloading the data\n\nWe will then read the datafiles into sf objects\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_sf<- st_read(dsn='data/geospatial',\n                layer='Hunan')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Hunan' from data source \n  `C:\\santhyats\\IS415-GAA\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan2012_sf<- read_csv(\"data/aspatial/Hunan_2012.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\nWe will now perform a left join of the 2 sf objects based on their common identifiers\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_sf<-left_join(hunan_sf, hunan2012_sf) %>% \n  select(1:3, 7, 15, 16, 31, 32)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(County)`\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}